5:49
theres an example when it comes to eks cl8 which u v to be able to discuss with relative ease , called probes
ders 1 aspect abt k8 cl8 wich is abt probes which is generally used to manage health check in our cl8

we wil see hw probes are used n why u may deploy ur appl n choose stuffs like probe n when that shud happen

SO DATS ONE TIN U SHUD BE ABLE TO DISCUS THE USE OF PROBES WHEN IT COMES TO DEPLOYING UR CL8 

probes:  Health check   
=======
TYPES OF PROBES
Liveness Probe:
Suppose that a Pod is running our application inside a container, 
but due to some reason letâ€™s say memory leak, cpu usage, application deadlock etc the
application is not responding to our requests, and stuck in error state.
Liveness probe checks the container health as defined (we tell it do), 
and if for some reason the liveness probe fails, it restarts the container.
internally , when i deploy my appl i can check if the appl is runnin by runnin the curl command
  curl localhost:8080       ..even for normal tomcat when I DEPLOY A tomcat appl, i can check if the appl is running or nt, i can curl
  curl localhost:8080/java-web-app     ...... also, i can the path to the appl
  curl localhost:8080/maven-web-app 
  curl localhost:8080/tesla       this is an apl that we v deployed, internally this appl can mk sure that its able to start this container, it must ensure that the 
                                         path is healthy, if its nt healthy our liveness probe is goin to fail n the container wil be restarted via d kubelet service..19.00
$? = 0  exit code !=0                  if it runs this command curl n the exit code is equal to $=0, then it means that it wil be routing trafic to that particular pod bt 
  curl localhost:80/tesla                 if nt equals to 0, it can route trafic to the pod, thats hw liveness probe is expected


2)Readiness Probe:
This type of probe is used to detect if a container is ready to accept traffic.
You can use this probe to manage which pods are used as
backends for load balancing services. If a pod is not ready, 
it can then be removed from the list of load balancers.

#############EXPLANATION: 15:00
COS services act as lb, n if a pod is nt ready , it wil nt add the pod to the pool, so if a pod is ready dats the only time the job is goin to be performed, if its nt ready
then it means our health check has failed, so thats what readiness probe is going to achieve

                                            webapp001
                                         image:mavenwebapp
                                          curl localhost:8080
   (routing traffic to the pods)
      service                                 webapp003
      webappSVC                             image:mavenwebapp
                                           curl localhost:8080

                                               webapp007
                                           image:mavenwebapp
                                           curl localhost:8080

                        
  so if for e.g pod007 is nt ready, it will remove it frm our lb agorithm, it wnt be der anymore, the service wil nt be routing traffic to an unhealthy pod, until when the 
pod is active thats when it will route traffic


3)startup Probe:
This is use for slow starting containers  
60 secs  
for containers that are taking a long time to start, we deploy the container using using startup probe as the health check

18:00
WE SOME INF ONLINE THAT U CHECK ABT PROBES ASwell, hw it works, it has a gud documentaction we can look at

https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/ 
https://kubernetes.io/

https://github.com/LandmakTechnology/kubernetes-manifests/blob/main/liveness_readiness_probes_example.yml
https://github.com/LandmakTechnology/kubernetes-manifests/



*******************************************     DEPLOYING APPL INCORPORATING LIVENESS PROBES...........
               LETs deploy a replica set
in the ubuntu server he sitched to sudo - su kops
but got error when he ran
kubectl get all     ... 24:24
he was unable to access his kops cl8 so 
when that happens we nid to export the kube config file again(i guess thats 10b in the inatallation file we used in kops installation): run kops export kubecfg $NAME --admin
now run
kubectl get all and we hv our cl8 running

***********we wnt to deploy an appl that has liveness probes
we ar deploying the appl as a replicaset n we ar using the javawebapp image n web thsi appl i sinstaled for u to be sure that the appl is running the container pod for this
appl 8080, therefore for us to be sure, we hv a readiness probe ,wich is our http get REQ, am i able to access this appl on this pod number

app-probes.yml  
==============
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: javawebapprs
spec:
  replicas: 3
  selector:
    matchLabels:
       app: javawebapp
  template:
    metadata:
      name: javawebapppod
      labels:
        app: javawebapp
    spec:
      containers:
      - name: javawebappcontainer
        image: mylandmarktech/java-web-app
        ports:
        - containerPort: 8080
        readinessProbe:    **********************readiness probe
          httpGet:
            path: /java-web-app            ***********am i able to access this appl on this path number, 
            port: 8080
          initialDelaySeconds: 5           , when we create the container it will delay for 5sec, it wil be running a command in the background trying to check if our pod 
          timeoutSeconds: 1                           is ready to accept traffic, if its nt ready it will wait agin and evry 15sec , it wil tryy to repeat the process, ar u
          periodSeconds: 15                                         ready to accept trafic b4 it can add it to the lb or to the backend pod
        livenessProbe:            *******if smt is wrong it wil restart the container/pod, readiness probe wil only route traffic to the pod unles it has passed d appl
          httpGet:
            path: /java-web-app
            port: 8080
          initialDelaySeconds: 15
          timeoutSeconds: 1
          periodSeconds: 15 

---
apiVersion: v1
kind: Service
metadata:
 name: javawebappsvc
spec:
  type: NodePort             ************* nodeport service for the appl
  selector:
    app: javawebapp
  ports:
  - port: 80
    targetPort: 8080
    nodePort: 32000 

to deploy it:
vi app-probes.yml
kubectl apply -f app-probes.yml
kubectl get po
our pod is running
kubectl describe po javawebapprs-m9qwr
we see it has a liveness probe in an http get req, it wil delay for 15sec n it wil redo the process again,until the result is positive n healthy ders no way trafic wil be
routed to that pod.

************so this is what liveness n readiness probe are goin to do

http://:8080/java-web-app

 it runs the curl command in the backend ....  curl localhost:8080  

http://34.215.29.198:32000/java-web-app 

*******these are probes n vthey are very imp as far as having a gud mastery in k8, u nid to v a gud mastery when it comes to probe

###### one other aspect/thing we nid to look at carefully is metrics server ..................  32:10


******************** ************* CONGFIGUE 

Configure a Metrics Server on your kops Cluster4??
=================================================
   CLONE OUR GITHUB REPO FOR METRIC SERVER
https://github.com/LandmakTechnology/metric-server
ls
we hv the metrics server
ls metric-server/

now to deploy my metrics server 
kops@master:~$ kubectl apply -f metric-server/metrics-server-deploy.yml
serviceaccount/metrics-server created
kops@master:~$  kubectl get po -A
metrics server is running
kops@master:~$  kubectl top po
we get a response
NAME               CPU(cores)           MEMORY(bytes)

**************so we v deployed a metrics server , and all we had to do was jst to clone the repository n run kubectl apply -f metric-server/metrics-server-deploy.yml


35:34 
if we redeploy :
kops@master:~$ kubectl apply -f metric-server/metrics-server-deploy.yml
there are some resources that are being created when metrics server is deployed
the resources includes:
serviceaccount/metrics-server unchanged
clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader unchanged
clusterrole.rbac.authorization.k8s.io/system:metrics-server unchanged
rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader unchanged
clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator unchanged
clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server unchanged
service/metrics-server unchanged
deployment.apps/metrics-server configured
apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io unchanged

37:00
when u are deploying any obj in k8 part of what was deployed here gots to do with rbac ,whic got to do with k8 security n  in the rbac der are a few things to look at:
rbac:
serviceaccount:
   ServiceAccounts Subject =  Users/Groups/otherApplications  
so for e.g we can create a service account , the service account can be created for a user, grps, other appl
e.g  we created a service account for anappl called metrics server, so this is goin to act as the subject of my service account
so subject can be :Users/Groups/otherApplications
so if u create a service account the nxt thing is that we can create a role n role binding

role : we cud create a role ,this  role for example is expected to perform specific tasks, so  i create a role for my pod, deployment services, etc or 
for my objects = pods/deployments/services/rs/ds/rc [ * ] ,, n if it is * its  means its for evrytin, all k8 objects bt if its for a particular obj like pod i create a role
    verbs   = edit/delete/view/read  [*]                                                                                             for my pod 
    apiGroups = [ v1 ]  [ * ]
    namespace = role are applicable to a particular namespace

RoleBinding: 
   This is assigning/association the role to a subject 
   ServiceAccounts/Users/Groups/otherApplications\

  ClusterRole:    
    objects = pods/deployments/services/rs/ds/rc [ * ]
    verbs   = edit/delete/view/read  [*] 
    apiGroups = [ v1 ]  [ * ]
    ClusterRole are applicable to THE ENTIRE Cluster and all namespaces   
  ClusterRoleBinding: This is assigning/association the role to a subject 
    ServiceAccounts/Users/Groups/otherApplications

rolebinding.rbac
clusterrole.rbac
clusterrolebinding

