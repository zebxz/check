******** refer to boothcamp dec26 for k8 architecture summary

XPLAIN THE K8 ARCHITECTURE 

k8 is a grp of servers that are working together to be able to ochestrate containerize applications, its made up of a control plane & worker node, the control planee comes with
components line the API server which is the main adminstrative point and the entry point into the cl8 & it does generally authentication & authoriztion & it ensures that whatevr
Req GETS into the cl8 is been made by an authorized & authenticated individual, apart of the API server, we hv the etcd that persists data in the cl8, it acts as a database ,
whatevr reQ is been made by whoever engr that inf is stored and persisted in the etcd and frm there we also hv the scheduler, which is incharge of scheduling  eg if ports are
been REQuested to be scheduled the sheduler will schedule that considering the nodes that hv available resources for such a port to be hosted and if thers any other constrain
all the constraint are been factored in
we also hv the controler managers that is able to ensure that at all times we hv a  number of nodes running , pods running , deplyments are runing as expected
we also hv the worker nodes comes with the kublets which is the pry node agent, we equally hv the kube proxy, which is incharge of netwrk 
also the container run time, there are diff types of container run time that you can use, docker used to be one of them , also container-D, container runtime is any software in 
your node that is able to create and start containers bc k8 is all abt managing containerized appl n in our env we use containerD as our container run time, we cud hv as well 
choosen other run time but we are using containerD

Also the k8 architecture is such that calls are made into the cl8 and that happens using the k8 client like kubectl or k8 UI form there we can mk certain API calls either to 
create containers, namespaces, security like RBAC and for any of these to happen, authentication must happen via the kube config file

so thats the k8 architecture



EXPLAIN A PROBLEM YOU FACED IN YOUR PROJECT AND THE STEPS YOU TOOK TO RESOLVE IT 
after he answer it with problem in sonarqube, he said:
our answer cud be abt k8, which problem hv you faced in k8 and how did you fix it so pls take note, its very important



  ###########################################     START


i will practice it               1:53:53
Ticket 001:  ... remember to change token durimg practice
  Setup a multi nodes self Managed kubernetes cluster using kubeadm.
  requirements -- 


HISTORY OF KUBERNETES, K8 ARCHITECTURE , security: authen/author, controller manager, INSTALLATION, installing single or multi node cluster, types of self manged cloud 
service, rancher , steps to setup muli node self managed cluster, deploying workload in K8, deploy appl using this cluster
How to deploy run/execute tasks/workloads in kubernetes
#############################################################################################################################################


when we talk abt kub, we classify an all imp tool bc of its imp  of to me as a devops engr, its so important that one of the jobs i can do is a kubernetes administrator 


WHAT IS KUBERNEYES??????????????????????????
IT is an ochestration engine, an open source platform for managing containerized applications... kubernetes is responsible for container deployment, scaling, descaling of
containers and lB.. 
so u can deploy ur containers using kuber, u can scale, descale  and u can LB traffic 
actually, kubernetes is nt a replacement for docker bt can be considered as a replacement for docker swamp , kuber is basically more complex than swarm and REQ more work to 
deploy.. born in google written in go and go lang , it was donated to claud native computing foundation in 2014, kuber version1.o was relaesed on july 21st 2015
TK NOTE ITS imp to v that understanding or that initial discussion when it comes to kuber n some of its features
3.33
fEATURES:
1)the first feature it has is that it supports what is called automatic scheduling ie it provides advance scheduler to launch contianers on node
2) it has self hidden capabilities, rescheduling, replacinging and rescheduling containers which are dead and the bauty abt it is that if u deploy a wrong application u can 
go back to what was running before so it has automATED ROLBACKS AND rollouts 
so kuben supports rollouts and rollbacks for the desired state of containerized application therfore, if u had a version running and u v a deploy a new version n ders a 
problem, u can rollback 
3) it has horizomtal scaling and LB , kub can be scaled up and down d appl as per REQuirment
4) service discovery & LB
5)WITH kuber DERS no nid to worry about netwrkn n communicatn bc kub wil automatically assign ip address to containers n a single dns name for a set of containers that can LB
TRAFFIC inside the cluser .... 5:00
containers get their ips so u can put a set of containers behind a single L Balancer ... this is a very key aspect service discovery n LB , hw powerful is that 
6)it also supports storage ochestration, u can mount the storage system of your choice , u can either opt for local storage or choose a public cloud 



How is the kubernetes architecture like  5:50
so far we v looked at containerization, hw appl are containerized and under containerization u realise that we can use sfwares like docker so when it comes to container , we 
use docker to containerize our application, we can also use rocket, container-d 
CONTAINERIZation involves writing and modifying docker files and using those file sto create images and shipping the images to image registries n from the registries this 
images can be shippe dto any environment , now therefore all ur discussion in docker can be limited to just creating and managing docker files . we cud also use sfwares 
like docker to deploy applications , to deploy n mange containers bt is it recommanded, shud we use docker ??? we shud nt and u are going to see that shortly, we shud rather
use container managers or ochestration tools like docker swarm kub n open sheet.
when we studied dodcker, we deployed appl using docker bt what are the limitations using docker to deploy applications .,.. we ar going to look at that shortly 7: 43 
bt these ar the contarization software

################################### refer to powerpoint script#################


Kubernetes:
Containerization:
 --> Docker, Rocket(Rkt),Container-d
   Containerization involves writing/modifying Dockerfiles and using those files
   to create images and shipping the images to image registries.  
   From the registries these images can be distributed to any environment.  

  We could also use Containerization softwares like Docker to deploy 
  and manage Containers


Container Orchestration Tools --> :
   Docker Swarm,
   Kubernetes,
   OpenShift

7:58    ###########################
Kubernetes:  began in 2015 which implies that it has been around for 8yrs, so if u go to an interview u cant claim that u have 10years kuber exp
  these are things to tk note of ..... bc the way dis course is deployed by d time u go tru kub u ar like somebody with atleast 7years of kub exp
  July 2015  --- 2023  = 8years    


we also hv tools like : that began 2023 ..... so u cant go to an interview n tell dem u v 10yrs of experience in it
chartGPT started in 2023.     

*************************************    10:59 
NOW LETS LOOK AT HW POWERFUL KUB is with a diagramatic illustration:
when we did docker we realise that if u hv docker there wil be docker engine, with d help of the engine we ar abl to crtae images n run containers
now if i run my containere.g webapp der ar some problems that dodcker has : if i run my container and thers a problem with the container it goes offline, docker is nt able 
to recreate the container , so i shud nt deploy my appl using a system that will nt intervenene in a diaster wher a sys is down bt cannot be recreated,,, 
we can use docker to do 2things: e.g , we v a docker build server wer we ar executing command like docker build, so in d build server, we ar creating images , frm the build 
server we wnt to run containers in the deployment sevrer ...
with docker i cannot v more than 1 replica of webapp for e.g u are deploying ur appl n ders a spike , no i cant v multiple replicas in docker , e.g: so if u decide to run
docker run -name webapp -replicas 5 , ie trying to get the number of replicas u wnat, it wont work.. docker doesnt support it
also, if my engine goes down , my contaiiners will stop running 
also docker doesnt support a scenario wher i can v multiple serveers in a cluster  e.g docker engine1 (with container), docker engine2(with containers) such that if one 
engine is down the 2nd engine can support it ,, docker doesnt v such sys bc the docker ntwrk dose nt support multi hostng wger we can v a cluster of servers, docker 
netwrking sys doesnt support multi hosting and thats a big problem ,, the docker system doesnt v an overlay ntwrk wher u can v a cluster of server, no overlsy ntwrk support
and d worst is that when appl ar deplloyed, to expose them to endusers is very limited and we wil see hw it is diff with kub... bc in docker we do port forwarding bt we wil
see what kub brings to the table


16:00
kubernetes architecture:  why are we doing kub and why is kub imp in my devops journey , that in all thy knowings u must knw kub
                                ############  kubernetes comes with a cluster in the cluster we v :
controller noder or controlPlane/MasterNodes: this has some components to tk note of:
  apiServer  : this is the main entry point into the cluster, it performs admin task in the cluster
  etcd  : the key value store ,,, this is like a database
  scheduler  : 
  controllerManagers   : 
workerNodes:  this is wher appl are running and here we can v node1, to node9  . the components of the nodes includes:
  kubelet   : this is the main agent that runs on the worker node. its the pry node agent
  container runtime : and d container runtime we ar going to be seeing is = [Container-d] 
 kube-proxy : the netwrk agent
21:30
############### in kub if u wnt to perform any task e.g u want to deploy an appl , for that deployment to happen ther are a few things that kub uses, w ecall it d client
kub client (how u can access ur cluster)  for e.g we hv docker client , the docker cli
22:11
kubernetes-client: we also hv kub cli , command line interface ,, command line interface here is kubectl
  kubectl  : if u are authorized, u can run 
     kubectl create/delete/get/describe/apply/run/expose 
  so we v the cli which we can use to make some api calls and we also v other APIs 
  ui- DASHBOARD  
  api  ,, others APIs
Or it has a UI wich is called  a dashboard ,, since we started this programe wher v we see any dashboard , to deploy in jenkins we were able to go to the browser,  der was 
a nice dashboard wher we cud create and run jobs
Now in kub, to perform any task in ur cluster,  for docker we cud do stuff like docker build, docer run n our docker client was docker bc all the commands started wit docker
our kub cli is kubectl ... this is our kub server, u want to run a job in kub , u run commands like kubectl run to deploy an appl, what happens is that kubctl is like a msg
that is sent into ur cluster , dis msg comes to ur cluster, u wnt to deploy an appli, so it cud either b frm ur dashboard, or  ur cli. then regrdless of wher the msg is 
coming from, d API server receives the msg on behalf of our cluster,d API sevrer performs admin task n when u execute dis command, this will get you tru authenticaton,so  u
nid to be authenticated n authorization,, 2things wil happen now u v executed kubctl run, wich means u wnt to deploy an appl, for dis to happen, kub nids to authenticate n
authorize u and the authentication and authorization process wil tk place using a file called .kubeconfig file . this is the file dat authenticates you

kubeconfig [.kube/config ] file will authenticate the admin    ....(ur tryn to mk an APi call, tryn to dd smt to b done) so u must be authenticated) 39:34
                               the caller admin/Developer/Engineer 
FOR autHORIZATION;
authorisation via RBAC: Roll base access control, 
this is under kub security , u hv to be authenticated n authorized to perform that task
once u are authentictaed n authorized , the task is being executed bt if u werent succesfully authorized, u wil get permission denied/ authentication failed

After sucessful auth/author, 
in docker we deploy our containers directly in containers, in kub they are deployed in what is called ports
so port is the smallest unit in kub
so u wnat to deploy an appli, dis is what happens, the API server receives this information either frm UI or kubctl, n immediately it receives it, it will persist the data 
in our key value store ie etcd,,,
now u wnat to deploy your appl which are deployed in pods .... in your cluster, der is a pry node agent, so in the node it has kubetes, kubetes is the pry node agent ,
therfore, the control plane is communicating with the worker node via this pry node agent , once it commun wit the worker node , it wil be checking for resouce availability
u wnat to deploy a pod , this is a scheduler, this pods requires abt 800mb bt when it comes to availabilty: my node1 got abt 700mb of memory, node9 got abt 8000mb of memory
we v d scheduler, hes going to schedule d pods based on resource availabilty and other factors.. all other factors ar constant .at this time the scheduler will do automatic
scheduling on node9 which has enough enough resource availability.now when the pod, lemme cal it webpod is scheduled on node9, inside the webpod containers nid to be created
now the container runtime wil create n start the container, so now i v my webcontainer inside the pod.
this is the kub architecture, very powerful 
now i v my appl scheduled on the pod, and we nid to deploy multiple replicas , in this case we v 2replicas, the scheduler has scheduled the 2replicas on the 2diff nodes.
therfore 2replicas of the pod have been deployed
inside this cluster we wnat to ensure that we can access this pod, for the pod to be made accessible we ar going to make what is called a service in kuber.
35:34
so u v a service , this service act as a LB
E.G I V A webSVC, what wil happen is that if u wnat to access this appl running in this pod in kub, it is going to be made discoverable using the service
so if u wnat to access the appl, it wil be routed via the service, we call this service discovery, u wnt to discover ur appl, the service is involve
now this entire netwroking wher appls can accessed with relative ease is been suported by a ntwrk agent kube-proxy.

###########if u can xplain dis kub architecture, u ar as good as done 37:26

====================================================================
TK NOTE OF THIS TREE
kubernetes:    kub has a cluster , 
   cluster: it is a grp of nodes
   nodes:  in the nodes ther are pods 
   pods:  in the pods ther ar containers ..  
   containers :  

therfore in kub we can say that nodes are the subset of the cluster , pods are subset of the nodes and containers are the subset of the pods
cluster ---> nodes ---> pods  ---> containers  :


WHO CAN DO WHAT, who can perform what task .. ,, THIS WILL BE SUPPOERTED BY KUB SECURITY  .. 40: 26
kubernetes security - RBAC:
  Developers [ Paul, Joyce, Chidi ] 
  Engineers  [ James, Dominion, Janet ]    .... we can assign them diff functions

authentication via kubeconfig : 
authorisation via RBAC:

42:40 .. cONTROLLER MANAGER.. >>>>>>>>>
E.G IF U deploy ur appl and you want 3pods to be deployed , lets assume 2pods shud be running, if 1pod is down, the controller manger has been instructed to create 2pods, if
one pod goes down, it will automatically create the pod, those are the function of controller mangers


Installation:
you can install a single node cluster,  bt we shudnt use a single node to creat k8 cluster to avoid the risk of failure
with single node cluster u wont optimize the functions of k8 that permits you to have multiple nodes
============
K8S=Kubernetes    ......kub is represented with k8s
Local K8s Cluster(Single Node K8s Cluster) ..  , ,,......... we can use single node for testing , e.g if u wnat to test smt, u can test it on a single node
------------------------------------------
 1)  minikube                ......................  we can install it uisng minikube
       choco install minikube  = windows   
       brew install minikube   = macOS  
       minikube start      .... once it is installed, run minikube start, u v began a cluster on ur windows or mac computer
 2)  Kind   =      ... we also hv kind , which can also be installed........
  3) Docker Desktop     ...... 
      https://docs.docker.com/desktop/kubernetes/
  POC = .............. didnt say anytin

##############********************dis is aour main interest

Multi Nodes Kubernetes Clusters:  ............ ............ .... for production great deployment, we nid multi node k8 cluster 
================================
the first of its kind which w ecan install is : 
1. Self Managed Kubernetes [k8s] Cluster = IaaS--EC2  :  thess ar infrastructure as a service , we can launch of k8 cluster on a grp of ec2 instances, using kubeadm
    kubeadm --> We can setup multi node k8's cluster using kubeadm.  ... kubeasm is a sfware that is used to launch a k8, both d control plane n worker node
    kubespray --> We can setup multi node k8s cluster using kubespray , it uses ansible playbook
     (Ansible Playbooks Used internally by kubespray).
WITH  Self Managed Kubernetes [k8s] Clusters both the    
     controlPlane: [apiServer, etcd, scheduler, Controller Managers] 
      and 
     workerNodes: [  kubelet, containerRuntime-Container-d, kube-proxy]  
  are managed by the Admin/Kubernetes/DevOps Engineers

*************** so if u have a self managed cluster u hv to ensure that the control plane wit all its components re healthy n functionin and also the components of the 
woker nodes are all running and healthy, it is ur function

we v anoda class of clusters wich are  manged by 3rd party, u will nt bother abt he mgt
2. Managed k8s Cluster  (Cloud Services) = PaaS  : 
   The controlPlane is managed by a cloud provider or third party.  
   The controlPlane and all it components are managed by the Cloud provider 
   ***************  howerever,   The workerNodes are managed by the Admins or engineers
TYPES OF CLOUD manged service:
   EKS --> Elastic Kubernetes Service(AWS)
   AKS --> Azure Kubernetes Service(Azure)
   GKE --> Google Kubernetes Engine(GCP)
   IKE --> IBM K8s Engine(IBM Cloud)
    Kubernetes Cluster = k8s  

########### so u can deploy your cluster using, either a manged or a self managed sfware
ideally, companies will prefer to go for managed bc it will give rhem more time to focus on the app , bc if u nid to focus on the architecture, it wil mean taht u wil need
to spend more time ensuring that ur cluster is running than managing containerized appl,,   ,, bt more time shud be dedicated to appl management.

*******************we also v another clas of cluster thatcan be installed 
3. KOPS: is a software use to create production GRADE/ready k8s in AWS and  
         azure for the kops beta version  
         It creates a highly available kubernetes services (he said cluster, mayb a mistake) in Cloud like AWS.
            KOPS will leverage Cloud Sevices like: .. so when u deploy wit kops, it comes along with all dis services n its very esay to craate a kops cluster 
              vpc, 
              AutoScaling Groups, 
              LoadBalancer, 
              Launch Template/configuration
              ec2-instances nodes [workerNodes and masterNodes]
              s3  

its very esay to craate a kops cluster ... bt first u must be authorized , hw is securtiy managed in the aws account.. hw do we authroize 
 kops create cluster --name mycluster --az us-east-2b nodes-4 master 3    

we authorize using IAm ... identity and access mgt
so we nid to create a roles or policies that will permit the user to vps, autoscaling grps, LB, S3 bucket etc
    iam role/user  

A TOOL WE CAN USE TO MANAGE MULTIPLE CLUSTER 
Rancher: - Using Rancher we can deploy both managed and self managed k8s CLUSTER
           Rancher serves as a glass to access and manage multiple k8s  
           from the rancher dashboard [UI]  - rancher dashboard  ,,,, frm rancher i can create a cluster in EKS/AKS/GKE/IKE 
           authentication and authorisation: EKS/AKS/GKE/IKE  ... bt u v to be authorized
         to be authorized to create an aws EKS cluster in aws, i can create an IAM Role for EKS , this wil permit us to create and manage an EKS cluster
it wil be the same thing for Azure AKS, goodle GKE and Ibm cloud

************* so if i v like 10clusters that i wnt to manage, wich i wnat to be observing hw dey are performing at all times then i need to instal the rancher sfware so i 
ca use it to access those clusters



**********************************************************************************************************************

Ticket 001:  .. always remember to use my own token ...............            53;12
  Setup a multi nodes self Managed kubernetes cluster using kubeadm.
  requirements -- 

1. check the kubernetes official documentation  :
https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/

2. check the company's documentation for kubeadm setup    : 
https://github.com/LandmakTechnology/package-management/blob/master/kubeadm/READme.md

*******************in our env, we v created github repo, n we v summarized this REQuirement there, evrytin i nid to deploy my cluster is xplained ther


57: 08
having checked the requirements in the companys documentation
in aws
1) he launched the 3ubuntu servers , he used the vps he created himself, auto assign is enabled
having checked the required ports in the power point script, he choose a security grp with the rwq ports opened (all TCP open)

2) using mobax he connected to the master node ..... we wil be deploying our cluster with the help of the master node
master publicIP= 3.128.206.139
3)then set hostname to master  and sudo i to switch to root user 
as root user i wnat to deploy my cluster , and ders a script that i can just copy and run
4)copied the script  and said he wil smake some changes . commented sethost name to node1 
in the script first, we v to 
we nid to diasable swap n kernel setting,so we wil disable swap memory so that we can enhnace performance in our k8 cluster , then nxt, we ar adding kernel details n instal
container-d, first instal container-d n its dependecies bc our runtime (to b able to start&runour conatiners) is nt docker bt it is container-d, once it is installed, we 
will proceed to start container-d  afterwhcih we wil instal kublet, kubeabm and kubectl,, after that we wil start the kublet service
i will run this as a script and i nid to be root user
vi into k8.sh and paste the script he copied    ...... 1:03:50 
then 
# Initialize Kubernetes control plane by running the below commond as root user.
sudo kubeadm init
****************** but am a root user, so i dnt nid sudo. ... just run kubeadm init 
and for us to be able to initialize this control plane the req port must be opened. 
************************** SUCCESSFUL... now i can process as a regular user
5)to continue as a regular user , i can exit or sudo su - ubuntu
6)then to start using : 
run the 3commands as stated in the success notification in my cli  (mkdir -p $HOME/.kube .......)
we can cat .kube/config  file, we can see its content n this is d file authenticatingus to acrry out tasks and d  user now is the admin , so he has adminaccess in d  cluster

we run : kubectl get node  or kubectl get pod
it shows the master node is not ready
7) so to ensure its ready we v to deploy the ntwrk plugging
kubectl apply -f https://github.com/weaveworks/weave/releases/download/v2.8.1/weave-daemonset-k8s.yaml
************now it has created certain components 
now if we execute kubectl get node .............. our master node is ready
for containers .... kubectl get pod    .. we dnt v any pod running
lets check all the pods in the cluster ..... kubectl -A 
we can see we v some pods running 
so successfully we v installed our k8 cluster 

********************* kubectl get node ,    we only have the control plane ie only the master node
we need to add worker node to the cluster 
to launch node1:

*************** to launch node1:   ***************

8)  Generate the master join token on the master node
so am going to generate the master token on the master node
kubeadm token create --print-join-command                                                                               1:14:44
once the token is created,
i)  vi node1.cst
ii) i go bk to the repo and copy all the command again to launch node1 (bc d script says copy and run in all master n worker nodes)sethost name to node1 
wasnt commented on... then at the end of the script paste 
iii) #add worker node to the cluster 
then pate the token that was generated
##### then go back to AWS 
iv)  we will launch anoda inatance .... instance name : node1 , t2 micro , the same key we choose for master ,,, they shud be in the smae vpc, the same security grp
under advance details, in user data , i paste the script and launch node1
v) i also launch node2 with the same steps except i dnt paste the user data

vi) TO CONNECT TO NODE9  ...................... 1:19:20
in mobaxterm ,, new session 
i copy the node9 publicip  
node9 publicIP = 3.148.106.135  
*********************** WE V TO RUN THE command as root user.... 
so , sudo -i

vii) i copy the entire script and vi k8-node9.sh and paste the script and change: sethost name to node1 to sethost name to node9
then sh k8-node9.sh
**************** while this is happening lets check our master node 
kubectl get node 
now i can see node1 has joined the cluster , so we used user data for node1 to join the cluster , so we can use userdata to mk our life easy
kubectl get node -w to watch how node9 will join the cluster
few moments we can see node9 has joined the cluster  and in the node9 cli we can see it says node9 has joine dthe cluster     
************* we can add one more node 
in aws in instances  .... instance name node5 and the same steps we used for node1 including the user data  bt change sethost name to node1 to node5
once i launch, it will create and add node 5 to the cluster
successfully added                                                                1:26:00
******************** ************** so we v successfully deployed a cluster using kubeabm  ... and the the cluster is having multiple nodes

1:30:30

HOW Did WE DEPLOY A WORK LOAD IN DOCKER ??
we had to use docker resources or objects to deploy applications like docker file we use it to build images n we can now deploy our appl wit the help of ntwrks, vols,
using the docker-compose file.
........docker resources/objects use to deploy applications:
  Dockerfiles/images/networks/volumes/docker-compose.yml/etc.

****************************************WE WANT TO DEPLOY WORK LOAD IN k8
***ticket002
========
************************************************************    Deploy workloads in kubernetes;
kubernetes resources/objects used to deploy application includes:
kubernetes Orchestrate and managed containerised Applications  
This applications run as containers  
These containers are housed in pods  
Pods are housed in nodes    
nodes are housed in the cluster   
********therfore if u are going to deploy any appl in k8, it is going to be deployed in a pod

now we v created our k8 cluster ,how are we able to deploy appl using this cluster ,, ????????????? dats some of the things we wil be able to look at:

kubernetes resources/objects used to deploy application include:
   Pod :
or    
 controllerManagers:
      Replication Controller
      ReplicaSet
      DaemonSet
      StatefulSets
      Deployment
      Volume
      Job       

*******************************when u deploy appl in k8, u v to make the appl accessible ie exposing appl/accessing appl
Exposing/accessing applications = Service Discovery:
    Service Types:  it will route service to our appl n their replicas ,
    ClusterIP :  it performs LB  , its used for internal communication inside the cluster.
    NodePort
    LoadBalancer
    ExternalName  
  ingress 
  networkPolicy 

1:34:30  **********************generally for this deployment to tk place even in k8, we will make use of a namespace
how DO WE ENSURE THE APPL ARE ABLE TO COMMUNICATION  & all of that , ders a concept in k8 called:
Namespace:
  It is a virtual cluster inside your cluster  ,,, we can create a name space for dev stage, uat stage , prod stage , sales ... dependn on d project u are managing
     [ dev / uat / prod ],                            if u create a namespace for e.g, u wnat a situatn wher what dev ar doin does nt affect what is runin in uat &prod
     [sales, accounts, cs, payroll]                so we can use name spaces for isolation, we'l isolate d dev env frm uat, frm prod using namespaces
  pros:
    isolation                                                                                                               1:39:36
    permissions                   also for permisions e.g for d dev namespace we assign  deveopers to mange the dev namespace for prod engineers, so developers ar permitted 
       dev  - Developers                     to run their workload in the dev namespace while engineers ar runnin ther workload in the prod namespace
       prod - Engineers
    resource utilisation                          
       dev  - cpu=5Gi mem=1000Mi      e.g we can decide that in the dev namespace we ar assigning cpu of 5G , MEM OF 1000mi
       prod - cpu=1000Gi mem=8000Mi 

  *********************    ADVANTAGES OF NAMESPACES
High  performance                
       High priority 
    RBAC - Security:           name space is also good for sevurity, with the help of namespacing, security is very strong
      NameSpace              also for role base access control wher we create roles 
      Role   = dev [list/read]        you create a namespace and in that namespace you create a role e.g i can create arole for developers whic grants them access to read
      RoleBinding                i can bind the role to a particular user or a grp of users like developers, ############ role & rolebinging is for a single namespace 
         Users  
         groups                                                                                                                     dats what d role binding is all abt
         ServiceAccounts     or i can bind it to an account, like a service account, once u bind the role its like u create a security grp &u attach that grp to a server
  ClusterRole              ########## clusterRole &clusterRolebinding is for the entire cluster 
  ClusterRoleBinding                 
  ServiceAccounts  
#####################################################################################################################

1:42:04
HOW MANY NAMESPACES DO WE HAVE IN OUR CLUSTER
ubuntu@master:~$ kubectl get ns
NAME              STATUS   AGE
default           Active   57m
kube-node-lease   Active   57m
kube-public       Active   57m
kube-system       Active   57m

Ticke3:
  Create fintech and ecommerce Namespaces   
kubernetes uses the kubectl client or the UI to run workloads.
  kubectl get namespace
  kubectl get ns 

 kubectl create namespace fintech --v=8      . V , MEANS   in verbose
 kubectl create namespace dev     
 kubectl delete namespace dev

ubuntu@master:~$ kubectl create namespace dev --v=8              **********this is verbose
I1029 01:37:06.096876   6650 loader.go:395} config loaded from file: /home/ubuntu/.kube/config     
************namespace/dev created    ,   this is verbose, i wnat to create the namespace in verbose mode, i am told that when i run this command,it gets me authenticated 
using :   config loaded from file: /home/ubuntu/.kube/config  .. so it is making that rEQ , thers a http post request to create the nameSpace , so the REQ has been created,
it has been ACCepted, which means that the user is authorized to carry out the task

ubuntu@master:~$ kubectl create ns fintech
created


ubuntu@master:~$ kubectl get nodes
NAME     STATUS   ROLES           AGE   VERSION
master   Ready    control-plane   61m   v1.28.2
node1    Ready    <none>          50m   v1.28.2
node5    Ready    <none>          42m   v1.28.2
node9    Ready    <none>          47m   v1.28.2
ubuntu@master:~$ kubectl get pod     ..************ this means it wil search for the pod in the default nameSPace
No resources found in default namespace.
ubuntu@master:~$ kubectl get pod -A
NAMESPACE     NAME                             READY   STATUS    RESTARTS      AGE
kube-system   coredns-5dd5756b68-75vwg         1/1     Running   0             61m
kube-system   coredns-5dd5756b68-qmtz8         1/1     Running   0             61m
kube-system   etcd-master                      1/1     Running   0             61m
kube-system   kube-apiserver-master            1/1     Running   0             61m
kube-system   kube-controller-manager-master   1/1     Running   0             61m
kube-system   kube-proxy-9bhvd                 1/1     Running   0             42m
kube-system   kube-proxy-cl4lt                 1/1     Running   0             47m
kube-system   kube-proxy-jbkcx                 1/1     Running   0             51m
kube-system   kube-proxy-wnf8k                 1/1     Running   0             61m
kube-system   kube-scheduler-master            1/1     Running   0             61m
kube-system   weave-net-9d22b                  2/2     Running   1 (42m ago)   42m
kube-system   weave-net-nnhrk                  2/2     Running   1 (58m ago)   58m
kube-system   weave-net-qwg7q                  2/2     Running   1 (46m ago)   47m
kube-system   weave-net-rzndz                  2/2     Running   0             51m

#####################
****************** SOMEONE ASKED how many pods can we create in one node ???????????????

lets look at k8 BEST PRACTICES FOR LARGE CLUSTERS     *********** so if u have a very large cluster you can click on this link, u wil get more info
https://kubernetes.io/docs/setup/best-practices/cluster-large/
For very large clusters NB: dnt create :
   No more than 5,000 nodes
   No more than 110 pods per node
   No more than 150,000 total pods
   No more than 300,000 total containers

1:50:00 ********************************* HOW DO WE DEPLOY WORKLOAD IN K8 ????????????????

WE DEPLOY workloads using Imperative and declarive approaches    

-#Create Name Space Using Imperative approach =  Command
   LIKE:
kubectl create namespace <nameSpaceName>
    kubectl create namespace dev  

-declarive approach =  makes use of files and less commands  
-# Using Declarative Manifest file 

Ticket4: Create prod namespace using the declarive approach.  
========
imperative:  kubectl create namespace prod    

*****************************declarative:
apiVersion: v1      (THE api version we want to create is V1)
kind: Namespace
metadata:
   name: prod     ( the namespace is prod)
================...................***********once i create dis file, i can use it to deploy my namespace with the command :
  kubectl apply -f ns.yml  

ubuntu@master:~$ kubectl apply -f ns.yml  
created

PODS:
====
POD --> Pod is the smallest building block use to deploy applications in k8s.
Pod represents running processes. Pod can contains one or more containers.
These container will share same network, storage and any other specifications.
Pod will have unique IP Address in k8s cluster. 

Pods
 SingleContainerPods --> Pod will have only one container.       98%
 
 MultiContainerPods(SideCar) --> POD with two or more containers. 2%  
e.g, we can v the  the application container and like a sidecar container
       application Container :
          e.g  webapp    , e.g u v a container running and u wnat to ensure this appl doesnt v any problem, so u attach a logmgt container so that whatsover is 
       SideCar containers:                                                                             happening in the appl, this log is reporting it
            e.g  logMgt  container   ... like a container that is collecting log from ur application
           utility Container [e.g u have a Truck that is transportin some goods n u v a car infront of that truck, d car can help wit traffic n give warning signs to oda ]
       road users to inform dem that der is a large truck on d road b careful,its like a side car ,it can also be useful to transfer fuel when the main truck run out of fuel
                    
How to deploy run/execute tasks/workloads in kubernetes??
   1. Imperative  approach 
        By using commands 

   2. Declarative approach
        By using files [manifests files]  

-# Create POD Using Command
kubectl run <podName> --image=<imageName> --port=<containerPort> -n <namespaceName>
kubectl run hello --image=mylandmarktech/hello --port=80 -n dev  

ubuntu@master:~$  kubectl get po    ...... ........ 
no resources found in default namespace 
ubuntu@master:~$ kubectl get po -n dev
no resources found in dev namespace 
ubuntu@master:~$ kubectl run hello --image=mylandmarktech/hello --port=80 -n dev  
pod/hello created
ubuntu@master:~$ kubectl get pod
no resources found in default namespace 
ubuntu@master:~$ kubectl get po -n dev
NAME    READY      STATUS       RESTARTS      AGE
hello     1/1      running         0            11s
*********************************we have been able to deploy this application
############ we use this image : -image=mylandmarktech/hello   .. to deploy the application.. the image is found in our image registry

ubuntu@master:~$ kubectl get svc -n dev      .... to check for services
no resources found in dev namespace 


in our image registry , we have applications like 
Docker images = dockerHub other registries:
-- python-web-app
   nodeweb-app 
   net-webapp 
   mylandmarktech/hello
   nginx 
   mysql  
   mongo  
   jenkins  
   sonarqube  
   nexus          ..... these are all images we can use to depploy our appli in k8

#################### Use the declarive approach to deploy workloads in kubernetes:
  Manifest files = kams       ........ we use manifest files to deploy in ddeclarative approach
  Manifest files are written in yaml/yml language 


pod.yml  : in this yml language, it deals with stuffs like :
key:value  pairs     
dictionary: number of key:value pairs 
list:

hw do we consider keyvalue pair 
**************for e.g when u want to create a manifest file, it has this acronym, comes :   where comes stands for kind, api version, metadata and spec
kind is a key value pair bc for example ; kind is pod , this is a key value pair, it has a key & a value  ,,, so key &value ,, kind:pod
for e.g , key value pair could be  name and the value is simon
key:value  pairs 
name: simon   

pod.yml template
======
apiVersion: v1       (this is also a key value pair)
kind: Pod     
metadata:          (this is a dictionary that contains a number of keyvalue pairs) wher we v name, labels and we can decide the namespace we want to create the pod in
  name: <podName>
  namespace: <namespaceName>
  lables:           (this is another dictionary)                    he didnt specify the guy
    key: <value>                               2:04:24 .. if u look at dis guy, we ar creatin this objects, the acronmy is comes...kind,apiversion,metadata &spec
    key: <value> 
spec:                                        
  containers:         ... under spec, we want to create containers, a pod can v 1 or more containers
  - name: containerName                                         container is a list
    image: imageName  
    ports:
    - containerPort: podNumber

    ############ this is the manifest file
pod.yml  
=======
kind: Pod  
apiVersion : v1   
metadata:
   name: webapp    
   labels:
     app: web  
     tier: fe  
   namespace: dev  
spec:                         we want to create containers, a pod can v 1 or more containers,, 
   containers:
   - name: web                          e.g container1 caller web
     image: mylandmarktech/hello              
     ports:                              container port is a list also bc we are tryin to list
     - containerPort: 80       ..... this container port is determined by d image bc when the imsge is being built, d keyword used to defined container port in d dockerfile

   - name: logmgt                        contianer2 , called logmgt
---                                      it can also still v container3
EXPOSE 80     


###############2:07:20
vi pod.yml and paste the mainfest file 

ubuntu@master:~$ kubectl apply -f pod.yml
pod/webap created
ubuntu@master:~$ kubectl get po -n dev
NAME      READY      STATUS       RESTARTS      AGE
hello     1/1       running         0            8m38s
webapp    1/1       running         0             12s


############################################################# we can use this template to create any pod

pod.yml template
======
apiVersion: v1       
kind: Pod     
metadata:          
  name: <podName>
  namespace: <namespaceName>
  lables:           
    key: <value>                               
    key: <value> 
spec:                                        
  containers:         ... 
  - name: containerName                                         
    image: imageName  
    ports:
    - containerPort: podNumber





