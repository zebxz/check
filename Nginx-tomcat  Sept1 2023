disable salinex but its not working
tried to setup ngnix but it says not suported

patching upgrading 

39:44
for you to explain in an interview that you have experience in ngnix webservers is also important 





                 START

i know we have seen a situation where our applications are deployed and endusers need to access the applicatio 
so we will configure an ngnix webserver
***1.27so ill launch an ngnix webserver
we will install it on a redhat




                                    WHAT IS CONTAINERIZED SERVVER 
Takes second to launch, light weight 
Virtual machines take longer to launch. They are heavy weight eg ngnix serevr 
** so any company you take containerization to it’s a big deal

                     

                        Mv tesla.wa tisla.war
In maven I renamed tesla to tisla

It is not  a good practice that when you want to access your application, you access them directly where endusers traffic goes directly to the application server.

Sow we are going to create a proxy ngnix server, so its going to be acting a sour frontend proxy such that end users cannot talk directly, they must go through webserver

Install ngnix
1)	We want to install ngnix to act as a proxy which implies that enduser traffic will be routed by the ngnix webserver so ngnix is acting as a load balancer, he receives the traffic from clients/endusers and route it to our backend application and our application will talk to our data bases
2)	We back up  the conf file by configuring the config file = sudo mv /etc/ngnix.conf  /etc/ngnix/ngnix
Vi /etc/ngnix/ngnix.conf    and copy our tomcat private ip into it. Therefor I have this for my backend server
19:45, in the backend, I have my ngnix server any traffic that comes it talks to the ngnix server and its route it to any of the tomcat servers

3)	We ensure the configuration is valid by executing;ngnix –t 
4)	Sudo ngnix –s reload but since I am already sudo ill run nginx –s 
5)	Sudo system ctl restart ngnix
6)	We check our browser if we can access ngnix server
It says 502 bad gateway, its because thers a security in linux called selinux which is enforced at this stage 
Setsebool  –P httpd
Therefore we will disable the security by running: can_netwrk_connect true

*********** we will be using other load balance like:
 ELSB: elastic load balancer


23:10
when we look at AWS web services we are going to study a very important concept called virtual private cloud where you will realise that in this architecture our frontend
load balancer will be in our public subnet while our application servers and databases will be running in the private subnet, so this is what is happening, ngnix is acting
as a load balancer


24:00
The Question is :
             HOW  DOES IT LOAD BAL OUR TRAFFIC 

The default option: t uses to bal traffic is called:
Round robin:  Request/traffic is distributed evenly accross the servers , with server weight taken into consideration, ngnix will be routing traffic to this backend servers 
depending on the load traffic will be distributed equally.



26:00
  OTHER METHODS INCLUDE

Least connections:  A request is sent to the server with the least no of active connectors , also server weight is considered
iP hash: eg, we can decide that Ip address from Africa let it go to appserver1, Ip address of America let it go to server2 etc
the server to which a request is sent is determined from the client IP address. eg it can decide that any address that has a specific octcts, that is it comes from a specific
destination should go to appserver one etc. thats is what is called ip hash.


                        
                                        HOW WE SUSTAIN THE MAINTENANCE PERIOD
26:59
if a server is down or undergoing maintenance/ upgrading it, vi the config file and write : "down" beside the server ip address
Also for the server we want to allocate more traffic we will write "weight =4", 
eg
we have 5m requests/users, we can assign  1m to the other server with 8GB  and 4M to that server with 64GB, ie 4x the number of users

load balancers helps to 
load balancers
                                                                    users >>> LB >>>> APP >>>> DB
security: Acts like a layer of security ie if anyone is trying to hack into our app it can be stopped at this stage which is very important 

health check: if its routing traffic/load balancing to about 30servers it ensures that it does not route traffic to a server that is not healthy, so it runs health check in 
the backend 

patching upgrading


52:00
IQ       WHAT HAPPENS WHEN YOU TYPE  app.com or google.com    (domain name service)
54:30
  once you type google.com it going to query global DNS searching for the webservers that are associated to this hostname and once it locates the server, immediately traffic
will be routed to that server


for example, why you type www.landmark.org, what happens is that in the backend you are going to query global DNS(global Domain name service) and there is a command is the 
backend called NS look up, it is going to be searching for the server.

53:15
eg    if i run nslookup www.landmark.org shows the address of our ngnix webserver

                                                
                                          WHAT CAN MAKE A SERVER UNHEALTHY/ TO FAIL
56:00

1) There could be a spike in the CPM, lets assume that a lot of processes are running in the server or the server is receiving a lot of traffic, it may not be haelthy to 
recieve additional traffic . and thats one of the reason that can make a server to be unhealthy

2)if for some reason the java process is not running in the tomact server, if java is not running, tomcat not to start, if you deploy appl you cant access it so if java 
process fail, it can make a server to be unhealthy and as such the webserver will not route to  traffic to an unhealthy target n thats why  when it comes to loadbalancing 
 its  very important with ngnix bc it has all this advantages


   QUESTION
1)the same way we installed ngnix on Redhat, can we do it on ubuntu

ANS: YES we can

2) why will you always prefer we install those app on Redhat, why nt using ubuntu

ANS: its justbc i wnat you guys to understand both redhat and ubuntu, when we inastlled doecker, we installed it on ubuntu and tomorrow we ill configure k8 on ubuntu
so but its good for you to have both exposure Redhat and ubuntu


********* i think this is form another video
3)if there are 2 availability zone,  will there be 2 ngnix in the 2availabilty zones?
if you have a VBC : virtual private cloud ie your private inetwrk, in this private network you can have about 6subnets depending on the region 
so now we have 3private subnets and 3public subnets

now in aws global resources you have:
   global >>> Regions >>> Availability zone 
inside AZ you ahve data centers                               ****** or 18 servers 3 in each Azs
when you create a vpc where you want to launch your resources, assuming you want to create your VBC in US East1 ie us virginia, it has 6 diff AZs meaning that i can create
my 6subnets/servers in all this availabity zones to ensure high availability
if i have my ngnix webserver running in the public subnet, can route traffic to all the servers/ec2s since all the servers are in the same vpc they are in the same netwrk,
45:39  so my ngnix can laod bal traffic to all servers or ec2s running in both private and public subnet

43:07 But if we have vpc1 and vpc2 , to ensure that connection happens we are goin to do vpc pairing so that even though they are in diff netwrk the pairing puts them  in the 
same netwrk that way you can still use a webserver to load bal traffic accross all your servers and this is the adv of using aws



                                                      QUESTION
47:00 ... if a user wants to access any of those applications, are they going to be using their individual ips or virtual ip of the ngnix 

ANS:
Before when users want to access their application they have to access individual servers ip but now we have to put all of them under one ngnix webserver, so all the traffic 
via the ngnix webserver .
they dont have to type https://3.090.240/app/ but now, mylandmark/register


48:20

A service in aws we are going to do 
Route 53 = DNS  ( Domian Name Service )
                                                                                                                                                               alias name
if u have dns, we go to our route 53 &create hosted zone, in this zone we will be routing the traffic, instaed of users to type 3.40.21, they can type www.landmark.org/app
traffic will be routed to to this backend application server bc we have configured Route53 with a public domain name or alias name for our ngnix address, so if you want to 
access this application its either you type the ngnix ip address directly or the public domain name we created




46:00
The application we deploy , we deploy them in virtual machines in vms




39:44
for you to explain in an interview that you have experience in ngnix webservers is also important 
