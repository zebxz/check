        ************ version dertermines the syntax

WE CAN CREATE MODULE FOR VPC , USING VARIABLES TO MODULELARIZE MY CODE, TYPES OF VRAIABLES ,HOW DO U ACCESS VALUES IN A LIST, HOW TO REFERENCE VALUES IN A MAP, PASSING
VARIABLES AS A FILE, terraform.tfvars, auto files, QUESTION :terfrm init -upgrade, MOVED  BLOCK


 NPSSNOV24

###in summary ill say we created a data source and then used modules to make it flexible then using variables to modulerize the code , declaring a variable of type map, and
then using a variable file, 




0.59
whenever ur installling on windows, make sure you are running it as the administrator, open powershell, whenever ur installing a package, you need to be an administrator 
otherwise it will not alllow you.




               TROUBLESHOOT INSTALLATION

Alexander was able to install it he sent the link in the chat /whenever you are installing a package, you have to make sure you an adminstrator or it wont allow you
1.50 ...youtube how to install terraform
another person said she couldnt unzip it

5.20 ... how she did her own using the link he sent , she had to closed the vscode & open it again after installing it on powershell
6.00 proff.. that is true, when you install a package on a certain terminal especially powershell, you need to close the terminal & reopen it
if u had your vscode the terminal running and you installed on powershell, u configure it so for it to be recognize on vscode u nid to open anoda terminal or close that 
terminal & reopen the terminal & once u do that it is going to pick up the path bc u already hv a terminal thats opens, so u just nid to close the terminal, close vscode & 
reopen it.


                                EMPTY DIRECTORY ISSUE
8.15    Choco wasnt recognized, install wasnt recognized
i downlaoded & extracted & create the path , but cudnt create terminal... terrafrm is still not working

  11.40 *** ALEXANDER said hes is also not working...
   i installed terrafrm on the terminal bt when i try to run terrafm init, it says the dir has no terfrm configuration files
so thats where i get stucked...

12.15 prof.. the system does nt lie if it says you dnt hv configuration files then you dnt have the file
the system is only reporting to you that in the dir there is no configuration file

 13.20 illustration:
 created a dir called project
cd ... takes us bk to the home where we see all the directories
cd/ project 
terraform init 
terrafrm initialized in a empty directory, the dir has no configuration files
the system is only reporting to you that in the dir there is no configuration file
then he created a file ... test.sh
terraform init 

                                       NOT A .tf file
   but we still got terrafrm initialized in a empty directory, the dir has no configuration files
    **** we still get error bc the file he created is nt .tf 
 he then created a file .. test.tf
terafrm read a .tf file but this file doesnt hv any content, it doeesnt hv any plugin bc terfrm doesnt knw wich puggin to download, so its just reporting that 
 its Initializing the backend
initializing provider pluggins
 terrafrm has been successfully initiated


          we will see what a backend is                   
16.40  wherever terrafrm operations is going to happen which is basically a local bc it will downlaod the terfrm file here, bt we dnt see any pluggins that hv been downloaded bc
terfrm doesnt know what pluggins/provider we need to use, so for me to do that i will pass aprovider blk and am saying i want aws as my provider

 18.20
let me initiaize terrafrm , once i do that ...
now it is finding the latest version of hershicop/aws provider bc i told it i want my aws provider ryt here & so terfm installs the provider & downloads the plugging & creates
the .terrafrm/provider bc this is where/its inside here that it downloads the provider if u go inside the dir, it has downloaded frm the registry
hashicorp aws , we see the version (5.24.0/darwin.arm64)which is compartible wth the mark 'darwin' & it downloads it and brings it to your env bc you are running terfrm on 
your local env, so this provider will act as the API that is going to interact with aws
so whatever you are doing, whenevr terfrm reports that you hv initialized a dir but it says its empty so check to mk sure that whatever you are running the dir your in check to 
mk sure that you hv configuration files, to check run ls
so just run ls
if u hv a .tf, then it means you are in the right dir but if not then it means you are in the wrong path



        ****watch this
24.00                              USING VSCODE TO CLONE THE TERFRM REPO THAT HAS A RESOURCE BLOCK FILE

  HE DECiced to create a dir or open a folder
choose to create dir
mkdir class33-terraform
git clone https://github.com/LandmakTechnology/terraform-master-class-series.git


35.30  student had to share his screen 
    i see how to open powershell & use gitbash/bash terminal


38.15 .. another student said he has to save the file
she said whener u ls  & the main.tf showed zero, which means you had nothing inside thats how she knew it wasnt saved
  ****proff .. mk sure if ur using vscode put it on auto save that way u its easy, u dnt hv to worry about saving and all that

40.10   .. another student hv an issue, says  she does -version  says has an older version which she needs to update , it upgrades but its still nt working
   prof u can uninstall & reinstall or use package manger, it will try & install the latest version
for ur case as long as you hv terrafrm running, dnt worry abt aslong as u hv terfrm running we try & see how we manage diff versions of terfrm as we go on
bc ders a tool u can use to mg8 diff version of terfrm, right now as long as u hv terfrm wotking running, that shud be fine
but if u feel that you want the the latest version then unstall what u hv & reinstall the latest version


42.32 another student hv another issue ..  shared screen 
    46.00  ..     lol, shes drama
   

           **proff will send how to use vscode video





 48.10                             CLASS STARTS

49.50 
Terrrafrm init: initializes our working dir
whenvere we are running terfrm init
   terafrm configuration file has to be present in our environment for terrafrm to be able to intialize or download the appriopriate provider
 
Terfrm APPly
** desired state is determoned by my configuration file, if in the file i hv an ec2 instance that is t2 micro, then that is my desired state
i desire to hv an ec2 instance that is t2 micro, so terafrm apply will mk changes so that reach the desired state, so that what ever u hv in the configuration file matches
what is in the real word, matches what is in aws .

51.50
terrafrm destroy
when we no longer our resources, if u want to destroy specify infrastructure
as we go on u realise that you can pass on like cli arguments, you can pass them in the command line to target specific resources that you want to destroy




                    TERRAFRM VERSION DERTERMINES/ SYNTAX OF THE CONFIGURATION FILE
          syntax of hw diff versions of terfrm configuration files were written cud be diff based on the version of terrafrm 

                                  INTERVIW QUESTION   ................. 54:44
HOW DO YOU USE terrfrm setting blocks ( U SHUD BE ABLE to discuss this things abt setting ur rEq version & REQ provider version)

52.00
We also looked at the language syntax 
we started by saying terfm has 10 top setting blks
Depending on the terrafrm version that am running in my env, when i try to run my terfrm code based on hw the configuration files hv been written, bc of the version of terfrm
am running in my env it may give me errors bc the syntax of hw diff versions of terfrm configuration files were written cud be diff based on the version of terrafrm 
so if am running the latest version, it may support passing of arguments but mayb the earlier version didnt support this 
so depending on the version am running, it determines like the syntax, though most of them hv backward compartible, it wil jst give u warning that this has been depricated,
or u nid to update oru nid to upgrade, 

                                                 IN PRODUCTION 
but when it cms to prod u nid to constrain ur versions of terfrm so ur code doesnt break
eg we hv a code/project that was written 5/6 yrs ago, when terfm was verson 0.9 
when you look at the code syntax, it will look a little diff, if the code is running in prod then i nid to constrain the version of terfrm to 0.9 so that my code will stil run
if i run terfrm init, it will downlaod the ryt version of terfrm/the pluggin bc am constraining. 
bt if i leave it open , if i dnt pass the version then init will always download the current version
n when that happens my code may nt be comparible n it wil break n give me error 
so thats how we use terfrm setting block


for eg, this illustration ;for aws
     source  = "hashicorp/aws"
        version = "~> 3.0"

am constraining it to 3.0 but the latest version is about 5.o
but bc am constraining it, it will go and look for a an aws plugging/provider that is version 3.0



56.24
                      PROVIDER Blk
    when we dnt pass credential we say its goin to use a default profile
its not necessary to pass a profile as default, if its using default profile, but if its using any other profile then u hv to pass the profile with the name
also we can pass a region for my profile, & that overrides the region that i set when i did AWS configure


RESOURCE BLK
we use a resource blk to create anytin we want to create any resource


INput VARIABLES BLK
THis is were we can pass out input into terfrm ,
so instaed of hardcording values, like this  = "ami-0e5b6b6a9f3db6db8" , which is not reuseable & especially as we will be looking at modules
hardcoding is not really reuseable bc i hv restricted you that you can only use this AMI , thefore the code is not flexible
eg, only time you can use this Ami, if i had harded coded my instance as t2 micro, then it means that i  hv restricted that the instance can only use this AMi 
with a t2 micro type
but if i mk it flexible by using variables, am giving the user an option to change the varibale, cos a var is smt that can change
if am using a variable/variable blk, then i can set it like this:
variable "instance_type" {
  default     = "t2.micro"    or medium or t3 large ...  whatevr i want , i can change it
and when we ar workin with modules, we see that we v giving users the flexibility to pass in their own values
  if i wnt to create a t3large, then i can pass it without affecting or going to modify my code bc all i need to modify is the variable which is an input variable


1.01.00
OUTPUT VALUES BLK
after our resource hs been create an d we wnt to get a n attribute out of the resource then we use an output blk
we hv to configure an output, we hv to give it d value 
and the value of our output it uses dot (.) notation
we hv to reference our (resource type.the resource name.the attribute) 
e.g aws_instance.instl.public_ip       .... so this is referencing the resource eg instance, that we interested in.
eg of attributes we could want is: Arn, public ip, id etc  therefore it will be .Arn, or .id etc


LOCAL BLK  ..........1:09 
15.00  local.name   eg as we see the example below: local.business
we use local blk if we hv long names that we dnt want to repeat writing it in the code , we can define them in my locals blk and then just reference it in my code if this
is smt that is repeatative bc i may hv concatenating variables  e.g the BD  value is the (variable "vpc_name" and variable "my_env ), so i can jst define a locals blk n just
referencd it, so that makes my codes mangeable and easy to read bc hv done all my definitions in my local blk and am just referencing local
so i can put as many values in the local as i want if they are long names i might use inside of my code and then i just reference local
this is hw we use a locals blk


                                                          CREATING A LOCAL BLK


resource "aws_vpc" "my_vpc" {
   cidr _block ="10.0.0.0/16"

   tags = {
      Name = var.vpc_name
      Env = var.my_env                                     BD is the value of var.vpc_name & var.my_env
      BD = $(Var.vpc_name)-$(var.my_env)    if i want a business division (BD).... bc this is too long , iil rather define a locals blk, declare it & reference the locals blk
1.10,40  BD = local.business  ... so am referencing this as jst a local, it is frm the locals blk but its a key called business n d value of this takes the whole value 
     }                                     of this:  "$(var.vpc_name)"-"$(var.my_env)"  , but this value is read frm these variables (variable "vpc_name and variable "my_env)
   }                                                                                 wich wil translate to "my-vpc"_"prod"

variable "vpc_name" {
    type = string
    default = "my-vpc"
}

variable "my_env" {
  type = string
  default = "prod"
}

locals {
business = "$(var.vpc_name)"-"$(var.my_env)"

bucket_business = local.business   ( i did this myself based on the github note)

*********************** bc its a long name, i declare it in a locals blk 




 DATA SOURCE
########vidoe 3   ########### 15:20 
 we use data sources to get info to return info for us frm an API, IF WE wnt 2 get info frm AWS, mayb frm a vpc, AN INSTANCE, a s3 bucket, this obj we wnt to get info abt,
first it has to exist,   so if we hv an ec2 instance tht exists we are able to get info abt the instance ,  the id , public addres, its dns 
so we can use a data source and pass in our filters and we are able to filter out all d amis that are der and we are ablle to return jst the value of what we nid
we use data source for automation bc as engr u dnt want to go to d console to manually copy an ami or any info/attribute,instaed u can automate d proces by runing a comand 
an data source wil go fast into aws , it wil get the attribute/info that u need n terrafrm gives u a way wherby u can aripolate that, u can pass d it directly to d resource 
ur creating

e.g 
if we were  creating an instance, bc we hv a data source dat we are using, we able to directly pass taht as our AMI, N what we are pasing is that attribute we wnt to get
. we knw that the AMI nids to b an id, so we ar using a data source as it reads data frm that particular AMI source, we wnt it to return an id n as it returns an id we are
directin paasing it to d resource so d data source gets the infpoo n we pass it as an input to our resource n this is how we use data source to provision our resource 
#################



VIDEo 2
1.17.00   BLK 7: DATA SOURCE
A data ssource is what can go to AWs and fetch data from you




                                              CREATING/BUILDING A DATA SOURCE TO GET An AMI 'ID'
Ticket:
i)Create data source to get an AMi id
ii) use the data source to create an instance

lets create a data source for an AMi
ill create another file &call it data.tf

     ...... 1:17:35     create a data source for an AMI , we wnt to return a certain AMI 
first create n name the file and open it and startt56
YOU start to create a data source oR using a data blk with the keyword data, n data block needs 2 labels 


 
                                        HOW TO CHECK AMI ID IN AMAZON
1.18.50***** when we go to aws, and look at amis, we are looking at the public registry/ images
we hv a lot of amis that are in the public registry, in this region , north virginia
normally, if i want to create an ec2 instance with an amazon linux, normally iil launch the instance afterwhich i hv the amazon linux ami, 
we can see the ami id, so i want to get the id
if i copy the id and go bk to the ami catalogue, & paste it in the search, i just want to search for the ami, it will show me/return tha ami
we see the name, the source, the owner, & the owner alias , its owned by aws, the platform is linux, the root device type is ebs 
if u click on the ami id, it shows the attribute of the ami


1) create the data source
1.21.00
        data "aws_ami" "amazon_linux" {   ...we want to return an amazon linux using the data so
          most_recent = true             .... we can see the date the ami was =created and req for the most recent ............1:21:01
         owners = ["amazon"]     we want the owner, its owned by amazon, its a list


                                                    APPLY OTHER FILTERS eg name
                                  we hv to put a filter name & a filter value

        filter {                  we wnt to filter the AMI bc when we are doing our search, it is goin to return all AMIs that ar owned by amazon n also d most recent
           name= "name"         we are trying to filter by the AMI name               so we ar goin to apply filters on the specific AMI that we wnt


                                     MAKING THE DATA SOURCE DYNAMIC SO THAT IT CAN GET AMIs FROM DIFF REGIONS
         values = ["al2023-ami-*-kernel-6.1-x86_64"]          ( we can remove the date n put* so it catches all the AMIs)
                                                                       ***its bc we can use this same data source to get diff AMIs  e.g wen we wnt toget AMI in a diff region
       
          filter {
             name = "root-device-type"
             values = ["ebs"]            this is also a list

Ls   .. i see data.tf file
when i run terfrm init, bc in my data source i hv referenced data_aws, therefore terfrm is sensitive enough to know that the plugging i desire to use is aws bc the data is
calling aws


                                           TROUBLESHOOTING/Wrong string syntax
and terfrm validate error  ... set of string required
that means that everything needs to be a list , ie needs to be a list, bc its values
     initially he used the name like this  "al2023-ami-*-kernel-6.1-x86_64" , then corrected it by adding the calibres ..  ["al2023-ami-*-kernel-6.1-x86_64"]
and trfrm plan , it will read the data source n return for me the AMi ID , 
it will run this filters and return an id of an AMI
  successful.
so using just the AMi name, "root-device-type", etc, the data source was able to get the ID of the AMI for us.. 



1.32.20                                      HOW DO I NOW USE THIS ID  ????  
              
2) use the AMI ID, gotten above to create an instance
... remember i hvnt gone to AWS to get this iD , i jst used this data source
LETS SAY I want to create an ec2 instance 
so i can create a resource


                                    CREATE AN INSTANCE USING A VARIABLE TO PASS THE AM ID FROM THE DATA SOURCE TO THE RESOURCE BLK

  i)resource "aws_instance" "data_test" {        hes just calling it data_test ...meee ie the resource name
    1.32.20  
how do we reference the data source/attribute from a resource or data source, we always use the . notation
 ii)ami= data.aws_ami.amazonlinux.id     (.id , bc we nid the id)         ****  instead of me hardcoding the AMI value , i am gon to get the ami frm my data vsource
iii) instance_type = t2.micro                                                         so the id is the attribute i want from the data source

  *********** now when i run init, validate and plan , it will run the data source , get the id and replace the id for the AMI 
so i hv dynamically gone to aws n got the AMI and substitute it here ie in the plan we see 
bc of this i can use this data source to get my AMis dynamically


                         WE DIDNT PASS A REGION SO IT RETURNED AN AMI FROM OUR DEFAULT REGION 
the AMI we got belong to US west 2.,, bc thats my default region 


                    WE DIDNT PASS A REGION SO IT RETURNED AN AMI FROM OUR DEFAULT REGION , USING THE SAME DATA SOURCE TO DYNAMICALLY GET AN AMI FROM A REGION WE STATED IN THE PROVIDER
if i pass a provider bc in my code i dnt hv a proider n my provider is AWS and pass a region
*******************  provider = "aws " {
                        region = "us-east-1"

when i run trfrm plan , it wil return an AMI thats ends with 5369 bc of the region , it has used d filter to find the moist recent AMI in thta region bc theyb wil al hv dis
filter similar name bt is just finding that AMi in d specoific region 
so if i change my region , i dnt hv to go on d console to do it, to find that AMi, so now i hv dynamically created it and it has returned for me this AMi and now creating it in 
US east2
*********************if i change my region to US west1, am jst changin my region bt i v my dtatsource
my dtasource will fetch an AMI id that is now 491b , bc this AMI belongs to USwest1
so this is hw we can dynamically use datasourec to provision our resources , we are nt harcoding , instaed we ar usin dataasource to fget info for us ,so i dnt nid to go to
d console  to knw wich region i am in bc we knw AMIs AR REGION SPECIFIC Bt if i use  adatasourec it go to what eber region its bein provision n it lways get the aMi fro , 
AMInthat is specifuc to that ergion and am able to provison my instance

**************** so thats hw we use  data source and data blk
if ur asked to get a data source for a VPC , u wnt to get the VPC id , u can use a data source n build filters n it wil go to any particular region n it wil gett d id based
on the filters u applied 





blk 8: modules blk  ..................1:38:48
the key of working with terfrm as infrastructure as a code is the use of modules
modules make our code very flexible


                                    HOW DO WE CREATE CUSTOM MODULES ..........Terfrm also has public modules we can use..3.00
stepA
      so we v the main general dir called terrafrm master class33 and inside this dir lets say we hv a dir called test  
this is the dir that has my  tefrm config files 
bc all my code is in inside this test dir, so i can use this test dir 

                                         THIS DIR IS OUR EC2 MODULE
so i can use the test dir as my module to create an ec2 instance bc all my code is packaged in der


stepB                                      CALL THE EC2 MODULE
while am inside of the same dir (terrafrm master class33) as the test dir, i can create a neew file called main.tf
then inside this main.tf, i can (call the module) by using the key word 'module' for ec2

 mdoule " ec2" {     ************ ec2 is the module name
 source = "./test"         the argument that is reQ inside my module is the source, wher is d code/module coming frm ? what is the source of ur module?
                               so i can say that my source is this presnt dir bt inside of a dir called test

to initialize this module i need to be outside the test dir but inside the overall dir terrsfrm master class33
when i ls in the  terrsfrm master class33 dir, 
it is goin to see  all the dir and the main.tf file
so ryt here when i run terfm init, it will see only the main.tf file , it isthe only tf file taht it sees in this dir, bc its nt goin to read inside of other directries
when i run terfrm init, it first initialies the backend and then the moudeles



********************************INTERVIEW  QUETSIOM ************
WHats the purpose of terfrm init???
firstly, it initializes the backend then 
it initilizies or downloads the modules
thirdly, the provider

                             WHERE IS THE MODULE 
in the  terrsfrm master class33 dir , we see
 it has created a .terfrm dir and in the dir  thers a dir called modules and providers , cos when we ran terfrm init it downloaded modules and providers pluggins
we open the module dir , we see it has a module.json file bt its pointin the source is the test dir , ie it sayin the module soure is in the test dir whic is wher our files
are 
*******now we run terfrm plan , we see its initilizing it frm the module ec2 and its reading that particular datasoure n creating a resource bt its creating it as a module
n its creatin an instance called 'data test' which is part of our module.so this is hw we reuse values/code. 

we can apckage our code , create our code after we v tested  it , put in a dir n that becomes our module




1.47.00
2                                     WE CAN CREATE MODULE FOR VPC
in the overall dir terrsfrm master class33 

a)he created a dir called vpc and inside it he ceated a file called main.tf (earlier we created a main.tf in the terrafrm master class33 dir )& in the main.tf, he created a
vpc resource 

             ***we hv 2main.tf, one in the general dir; terfrm master class33 dir & the other main.tf inside the vpc dir (the vpc dir is a sub dir in the terfrm master dir)
                     but if the ec2 resource blk inide test dir is also called main.tf, that means a total of 3 main.tf files


resource "aws_vpc" "vpc" {
     cidr_block = 10.0.0.0/16        ***so this is all i want inside this particular module & dis file is inside the vpc dir




                                         THIS DIR IS OUR VPC MODULE
   ****1.47.30... he said the vpc dir he created is a module to create the vpc


StepB                                         CALL THE VPC MODULE
now i can go bk to the main.tf file (where he used the keyword module to call the ec2 module) terrafrm master class33 & also use the keyword 'module' for vpc, to call the vpc
module

   module "vpc" {        **we can give it any name
       source = "./vpc"        **the source of this module is in the pwd, inside of  a dir called vpc


                                               
************ so now i v 2modules i am initializing, i v initialized the ec2 module earlier and now i hv a vpc module , so bc now i v added a new module the vpc, i need to run
terfrm init

                         RUN TERRAFRM INIT ANYTIME SMT IS ADDED TO A MODULE
so anytime u cahnge a module or add a module , u hv run terafrm init bc the module needs to be downloaded, d module nids to be initialized , 
so bc v added a new module here, this module lives in this vpc dir , inside of this vpc dir i hv my code bt wher am calling d module is on this file (main.tf in test dir)
am just refering wher my code lives


Step C
so in my terminal i run terferm init, bt if i just run terfrm plan, it wil say a ERROR, ders a module called vpc is nt installed 
afer runing trfrm init, i run terfrm plqn 
now its goin to create for me 2resources
the first plan we see is for the vpc with cidr  10.0.0.0/16
and also the  ec2 instance 
so i hv my code living here (test)tacked  away bt am calling them now as modules              ......1:51

****************tk note i didnt run terfrm apply yet*********** I NOTED dis here myself bc l8r on someone aksed if  DOES TERFRM DUPLICATE EACH  TIME WE RUN THE TRFRM COMMAN


IN the first video, we created a resource blk for vpc & instead of hardcoding, inside the vpc resource blk or we create a new file & inside it, create a variable for cidr 
then in the resource blk, we reference the variable
but now we are using resource blks as modules eg a resource blk for a vpc then we create a main.tf file, where we can call any/all the modules we want & we can make the 
modules flexible by using variables eg we create a variable for cidr in the vpc resource blk then in the main.tf file, we referenece the variable

                                    USING A VARIABLE TO MAKE THE MODULE FLEXIBLE 
******************bt still this module  that am passin here is still nt very flexible bc if i give u this code to use n ur calling the module main.tf (where we called al the
module) in terrafrm master class33 dir as it is,it means u are goin to use this cidr  10.0.0.0/16 but
 if i wanted to mk the cidr flexible, i will use a variable inside of the module/ vpc, main.tf ie inside the vpc resource blk, in( vpc dir) 


   1)                            CREATE A VARIABLE FOR CIDR IN module/main.tf (the vpc resource blk)in THE vpc dir
a)Create a variable for the cidr 
as it is,it means u are goin to use this cidr  10.0.0.0/16 but if i wnted to mk the cidr flexible, i will use a variable inside of the module/ vpc, main.tf ie inside the vpc
resource blk, in( vpc dir) i can create a variable:

     variable " cidr " {
           type = string        ( i am making it string and nt passing a defULT value, that way, i am making it  REQuired

b) reference the variable
And then i chnage the info in the vpc resource blk i created earlier   ....     
cidr_block = 10.0.0.0/16    to        cidr_block = var.cidr , so that u as the user can now supply the value

resource "aws_vpc" "vpc" {
     cidr_block = var.cidr

**** so i hv referenced the variable 
bt hv nt supplied the value so that u as the user can now supply the value bt frm this module/ vpc, main.tf  in( vpc dir) , we knw that it xpects  acidr blk 


                                    WHERE THE USER CAN PASS THE VARIABLE VALUE
   2)                         INSIDE MAIN.tf , where we called all the modules
       as the user pass the cidr value:
so then now i can cm to my mian.tf ((where we called al the modules, terrafrm master class33 dir) and on this module for vpc, i provide the value 
          module "vpc" {
       source = "./vpc"
       cidr = 10.0.0.0/16



now i can run terafrm init and trfrm plan , initializes the backend and plan reads the value frm the main.tf, where i called al d modules,in the terrafrm master class33 dir
so am supplying the value of the cidr as the user in the main.tf where am calling the module and if i edited the main.tf(in terfrm master class dir), am nt goin bk to the 
vpc main.tf file in the vpc dir
i dnt need to go bk to the  module/vpc (main.tf in vpc dir) to change the values,bc in the vpc file am making evrrytin as required/ or as varibales bt when am calling the
module , this is when am supplying the value bt i can equally mk it required so that i pass it as run time  ie comment it , bt if i dnt pass the value on the Main.tf where i
called all the modules



                                       MAKING VARIBLE REQUIRED/ USING VARIABLES TO MODULELARIZE MY CODE 
bt if i dnt pass the value in the Main.tf where i called all the modules
 ****** it is goin to complain that this value is required
eg; so on my main.tf, where i called all the modules, i need to declare it , i nid to declare a variable called cidr    bt still nt provide it (the value)   ******1:55

                 VARIABLE FOR CIDR  (But i hv to put 'var.cidr' for it to be declared as seen below)
         variable  "cidr" {
             type = string
 
bt  still complaining  ...... 1:55:27 , ie the codes were nt organized
      *************************************** i stil nid to format it 


                                           TERAFRM FORMAT
1:55: 30  \********************    terfrm fmt
so when i run terfrm format, it reformats your code , so that ur code is well organized the lines and all
this formtas your code 

now when i run terfrm VALIDATE it says missing reQ argument bc i didnt declare the cidr
   so in the module vpc ill  declare the cidr ie  cidr = var.cidr

STEP1;
module "vpc" {
       source = "./vpc"
       cidr = var.cidr       .......  I need to declare the cidr here
                                       its reading frm the module bt still i hvnt supplied the value so am still making it required
step2
  variable  "cidr" {
             type = string

so if i run terfrm plan, it now requires me to enter the value bc hv now mk the value required
So i enter the value: 10.0.0.0/24

############## so this is hw we use variableas to modularize or to make our code as flexible as possible 
 





QUESTION:  ..... ..........1:58             .... watch 2:06 
1)
       DOES TERFRM DUPLICATE EACH  TIME WE RUN THE TRFRM COMMAND???
if you notice, i only run tfrm plan, i didnt run terfrm apply ,I WAS JUST TRYING TO GENERATE THE PLAN BC THIS IS HW WE TEST whether EVRYTIN IS WRKING 
bt if i created a new resource and run trfrm plan , we can see the plan is to add 1 and destroy 0 
module.ec2.aws_instance.data_test:Refreshing state  .. THIS MEANS its only refreshing the instance resource we already have 
# module.vpc.aws_vpc.vpc will be created   ......... this means  this new resource will be created
terfrm apply 
 we check the stste file we ssee the resource taht was added 

if i run trfrm apply again .. it says 
no changes, your infrastucture matches the configuration
bc the configuration matches what is ur current actual state, so its checking , refreshing what is in ur state file n comparing it wit ur configuratn,so bc it sees everytin 
matches ,ders nothing to change or add
bt i if decide to add a like a tag on my vpc, it just means that am modifying my step ,wit that i can run trfrm init, trfrm plan, it sees ders a dif, it refrehes n statae n
say its now going to modify the vpc , it just updates, it goes to the vpc n put this tag 
  
********** terfrm state list shows hw many resources i hv captured in my state file 




2;10

2)    WHAT CRITERIA DO YOU LOOK AT TO KNOW THE VARIABLE TYPE TO USE 


                                                                 VARIABLES/TYPES

  ******************* THIS TAKES us to varaibale types................   2:12

a variable is a value that can change, depending on conditions or on information passed to the program.
Variables are used to store information to be referenced and manipulated in a computer program.
They also provide a way of labeling data with a descriptive name, so our programs can be understood more clearly by the reader and ourselves.
It is helpful to think of variables as containers that hold information, so when we are declaring/creating a variable, we are just creating like a place holder. Their sole
purpose is to label and store data in memory.
This data can then be used throughout your program, ie i can keep calling the variable whenever i need it, i can keep calling it bc it has stored some information

The following example shows the variable types that are supported by terraform.


1) string
Strings are usually represented by a double-quoted sequence of Unicode characters, "like this", If you declare a variable of type string without putting it in the quotation'
it will give you an error

variable "vpcname" {
  type    = string         ****declaring it is a 'string'
  default = "myvpc"
}

2) numbers , e.g we want to create a security grps & we want to pass the ssh port or https port, we can create a variable
eg for https port

    variable "https" {
        type = number        *declaring the variable as type number.
        default = 443

3) boolean;  Bools are represented by the unquoted symbols true and false.
represents true/false  e.g creating a nat gateway for vpc
     variable "nat" {
     type  = bool
     default = true    ,, its either true or fals


4)   list ***uses index
list : represented by a pair of square brackets containing a comma- seperated sequence of values, like ["a", 15, true]
   e.g a list of instance types ,   .......... i have multiple instance type i want to choose from
      
variabe "instance" {
  type = list [string] ... i knw that its a list bc if am creating a var for instance type, i normally use string bt what if i hv multiple instance type i wnt to choose frm
  default = ["t2micro", "t2 medium", "t3 micro"]   u put a default value, default val wil b a list                         (so it wil b a list of string bt a list of string
  & bc its a list of strings thefore the values that goes inside has to be quoted... these are values of my instance type
bc i hv these values from a list


2.22.20                     ACCESS VARIABLE TYPE LIST' IN THE RESOURCE BLK

bc i hv these values from a list, and i hv my resource blk to create an instance
so to get the value from the list, we reference the variable in the resource blk
But how do we access the values in the list

                                 HOW DO U ACCESS VALUES IN A LIST 
Values in a list are always accessed by an index and the index in a list always starts wit zero, 
video3, 11.30, first element is always 0 & the values are always in a bracket
whenever u access value in a list, u always use the index

    ***meee... stage,    dev,          prod
   e.g       ["t2micro", "t2 medium", "t3 micro"]
         index    0,       1,             2

now to access this in this instance resource blk 

     resource "aws_instance" "data_test" {
        ami = data.aws_ami.amazon_linux.id
        instance _type -var.instance[0]         ..... index of 0 , ie i want the value thats at index position 0 which is t2 micro
                                             terrafrm will go on the variable& it will return the t2 micro because thats the variable.

***************** so dis is hw we access values in a list             

                                              USING A VARIABLE OF TYPE LIST TO DEPLOY IN DIFF ENV
so u can create a variable of type list of strings , put ur values der, lets says u are creating a module that wil deploy instances both in the stage , dev n prod env n mayb
the req is when ur deploying in the stage env use a t2 micr, in the dev use a t2 medium, in the prod use a t3 large
so u can define a var with a list then based on the env u selsct the index, so ur just declaring one variable , ur reading it frm one variable bt its a list of variables n 
ur selecting the index based on the env.

*************************2:27

5) Map                         ***uses key value pairs
A map is basically key value pairs, thats what creates a map
whatever u hav inside tha brackets/calibras, these are key value pairs
so its is a map

bt we can declare a variable of type map
    varaiable "inst" {       inst is the name just for reference
    type = map       .... once i indicate a map" it is goin to open for me  brackets   ***i noticed that after we we run terfrm plan, this appears ' (any)'
    default = {              these are the default values
     " dev" = "t2.micro"               the key & the value pair
      "stage" = "t2.medium"
      "prod" = "t3.large"           the key & the value pair

so hv defined my map, map means i have mapped my env with the type of instance that i want


 2:29
                                 HOW TO READ/REFERENCE VALUES IN A MAP
ILL Use the square brackets but now instead of the index, bc our map is key value pairs, ill pass the key  ,  e.g dev , then terfrm wil return the value
2:32.50 Bc i hv declared the variable type is a map, then ill refernece the values in the map by using the key, then terrfrm will return the value 
  
resource "aws_instance" "data_test" {
        ami = data.aws_ami.amazon_linux.id
        instance _type = var.inst["dev"]         *** so this is how we read from a map

so if i was asked to deploy in the dev env, ill pass the key "dev", in the resource, then terfrm wil get the value which is "t2.micro"
 key      value
dev" = "t2.micro"


now once i run trfrm plan , it will return my instance as a t2 micro
  ......... the is hw we reference values in a map using the key



 ****meee***  USING A VARIABLE OF TYPE MAP     ***uses key & value   eg; key=dev & the value=t2 micro
so u can create a variable of type map , put ur values der, lets says u are creating a module that wil deploy instances both in the stage , dev n prod env n mayb
the req is when ur deploying in the stage env use a t2 micr, in the dev use a t2 medium, in the prod use a t3 large
so u can define a var of type map then based on the env u selsct the key, so ur just declaring one variable , ur reading it frm one variable bt its a variable of type map & 
ur selecting the key based on the env



6)NPUT Varibale
Declaring a variable but nt providing the default value , therfore am making it REQ & thefore it becomes an input variable & ill need to supply the value



 7)  OUTPUT  
attriibutes we try to get out
output "vpcid" {
  value = aws_vpc.myvpc.id
}


8)TUPLE   .. we wont focus on this much
it has a mixed data type
ITS LIKE A  LIST, IT can contain strings, numbers or other  list
Lists/tuples are represented by a pair of square brackets containing a comma-separated sequence of values, like ["a", 15, true].
tuple is objects within  a list while an OBJECT is a list within  a map



  9)    OBJECT     ......2:37
Its like a map , bt a mix , key value pairs of both strings n numbers , & list bt in the form of a map
so this is a list within a map

************************** this are the main type of variable we can pass inside our configuration

*** all these variables weare passing inside of our configuration but lets say we dnt want to pass the variables within the configuration
we can pass them as a file



                                  PASSING VARIABLES AS A FILE  (the file must end with 'tfvars', pass it on the CLI uing '-var-file= 'the file name')
                             ( we can use a variables file to deploy in multiple env)
when u dnt want to pass these varaibles within ur configuration , terfrm always gives the option for u to pass them as files

***  TYPES OF VARIABLE FILES TO PASS
1) Named files eg prod.tfvars
2) Unamed  filees eg terrafrm.tfvars or auto files



1) For named files ie files that didnt start with 'terrafrm or auto'
eg prod.tfvars 

e.g  if u want to pass a varaible as a file (named file) on the command line u can use an argument command line optional argument - var-file and reference the file that has
ur variables,the file has to end with .tfvars
   2.38.50  $ terafrm apply -var-file=foo.tfvars-var-file=bar.tvars

 
step**************************2:39:30
1)Create a file called: variables.tfvars
eg in video1, when we refactored ie seperated the diff level blks; we put the resource blk in a diff file and also put all the variable blk in a diff file (I bliv such file 
is called named fle' as he said below bc the file didnt end with .tfvars OR didnt start with 'terrafrm or auto') but then we didnt pass the variable as a file, so now this
is the steps to follow to pass the variable as a file
so this variables.tfvars file, i can use it to reference all/a particular variable frm my variables file .....
   in the variables.tfvars file, ill declare all/the variable i want  eg region
2)To pass the variables file
   terfrm plan -var-file=variables.tfvars 
************this will read frm the variable file n return whats needed 
So bc i created a file, i can pass it on the command line, these are what is called a variable file
I Can i hv all my variable required, all the variables i hv declared that am using, i can hv them required, probbaly i dnt supply the value **i bliv inside the variable blk
file, but i can then supply it inside the variables.tfvars file.
by doing so,  we can use a variables file to deploy in multiple env


**************2:45:00,,,............. WATCH
 we can use a variables file to deploy in multiple env
so i hv 2 variables files & they hv 2 diff values

for dev env    
dev.tfvars              to provision in the dev env
region = "us-west-1"
mytype = "t2.micro"
                  to deploy:  terfrm plan -var-file=dev.tfvars 
              it will read & provison a t2.micro

WHILE FOR prod env
prod.tfvars           to provision in the prod env
region = "us-east-1"
mytype = "t2.medium"
               to deploy:  terfrm plan -var-file=prod.tfvars 


2.47.50 we see that the ami's provisioned in the dev and that provisoned in the prod env are diff bc its a diff region, 
& bc am using a data source & its more flexible, i dnt need to go into aws to get the ami but at the same time am using variables file to supply my values
earlier when we treated data source we referenced it inside the resource for our instance & we are still using the same resource so thats what he meant by saying we are
using a data source.



   ************INTERVIEW QUESTION
have u ever used trfrm to provisoin in diff env  ??????  ............ HOW do u do it

ANS:
 first  thing we v learnt is that i can use diff varibales fil;es
i can use a variAbles taht contains value for my staging , or anoda variables file that contains value for prod env,
 so am supplying this values at run time 
when trfrm is running this values file are been read bc am passing them on the command line.
variable files are files that  starts with any name but ends with tf.vars , any file that has this convention u v to pass it on the CLI uing -var-file=
**************** 2:50


    2)       UNNAMED FILES
a)TERRAFORM.tfvars FILE
bt if u create a file that starts wit terraform.tfvars file, this file is automatically loaded u dnt hv to pass it (the file name)on the command line , ie to deploy it, you
just run 'terfrm plan' without supplying the values.... you dnt have to run; 'terfrm plan -var-file=prod.tfvars' 
it has to start with terferm
then i can just run terfrm plan without supplying d values then d file wil be automaticaly loaded(normally we wil pas d file name; ie terfrm plan -var-file=prod.tfvars then
terafrm apply -var-file=foo.tfvars-var-file=bar.tvars), but for variable files we dnt need to.
so if u hv values u like to be automatically loaded the u create a trfrm.tfvars , the values are automatically loaded

***meeee, above when we deployed in the diff env it was easily diferentiated bc of their names eg prod.tfvars 
so when am practicing, ill see if i can use eg 'prod.auto.tfvars',  'dev.auto.tfvars', terraform.dev.tfvars, but if its not possible 
inorder to easily use/supply the variable values in diff env using the TERRAFORM.tfvars FILE/.auto.tfvars file, 
 i will use TERRAFORM.tfvars for deploying in dev env then use the .auto.tfvars for prod env


                                  AUTO FILE
                              
b) auto files   
e.g test.auto.tfvars
as long as ther is auto then the file will be automatically loaded

  ********* bt files without this options, that has a diff name like prod.tfvars file , then u hv to supply on th CLI as -var-file= bc its a named file 
 auto or terraforms files, are files that are automatic to trfrm 
as u keep writing codes n keep working, u will see a lot of code , a terrafrm.tfvars file are files that supplies all your variables, u wil see this files a lot in code  
that pipo use to supply the values bc they are making variables reQ so that u can supply UR OWN values, i can create a module (VPC, ec2) n leave all the variables REQ e.g 
the name, the cidr , the tags and ill ask u create a .tfvars file to supply the values,, that way u can put ur own tag,name, cidr, and so that is now making ur code flexible,
and reusable , anyone one can reuse bc they can supply their own values , u hv nt hardcode values within terfrm 
thats hw we use variable files



the last variable you can create , lets say ur creating a variable that has a passwd

 2:55:08                            CREATING A VARIABLE THAT HAS A SECRET##################
    YOU CAN MARK IT AS sensitive =true

        variable "mytype" {
          type = string
         sensitive = true

what this does is that , bc when trfrm writes the state file evrytin is written in plain text it doesnt encrpyt it 
everyone can read the state file , 
so if i was passing a varibale like instance type, its nt encrypted 
so if i had passed a passwd & hv pass it as a vriable, mayb a database passwd, then terfrm is going to spit it out in the state file & anyone who has access to the state file
is able to read the secret 
but if i want terfrm to mask it i hv to mark it as sensistive that way in the state file, trfrm will not genertae it, u wil nt be able to see it bc its marked as sensitive
so thats how we deal with passwd or inf we deem as sensitive & we dnt wnat them exposed as plain text, we hv to mark them as sensitive


   49:00


                                   S3 BUCKET/MODULES
    ##############   QUESTION
1) on the work field, are we prorvided wit these file/code for a project given to u or u hv to create ur own code  ??

ANS:
U as an engr thats why we are learnig trfrm , u may be reQuired to write the trfrm code bt its very easy , 1) bc u hv a lot of documentation
e.g if ur asked to create an s3 bucket , u can type aws_s3_bucket in google, your trying to create a resource, it take su to terfrm registry , it gives u examples on hw to
create an s3 bucket copy it n paste in ur id, ie file ur creating, and i can modifty , e.g its for the dev env

 EXAMPLE
                            PRIVATE bucket wit tags
       resource "aws_s3_bucket" "dev_env" {
  bucket = "example-bucket"    .... then i put the name of the bucket here

 tags= {    , i can pass my tag
 Name           ="my bucket"
 Environment    = "Dev"
}

     but also mayb ur boss may REQ other things   ............... 3:00
what else can u pass when ur creating ths bucket ?     so u look at ur argument  click on argument reference and read tru it 



                                  TERFRM PUBLIC MODULES
********** also what we hv been creating here as we created our modules, these s3 bucket we copied is a module
we v been trying to create our own modules using resources, theese are called custom modules bt terfrm also has public modules or official modules 

e.g 
i want to create an instance
in google, i can type : aws instance module terrafrm or terrafrm-aws-modules-ec2-instance terraform and it takes me to the registry anD i see an aws instance module that has
been created and i can copy it and paste :

  module "ec2-instance" {
  source  = "terraform-aws-modules/ec2-instance/aws"   *** we seE the source is frm the terfrm registry, This is the source.             
  version = "5.6.1"
}                                                    3:05
              we seE the source is frm the terfrm registry, This is the source, so it wil be downlaoding the this version of module frm the regisrty
bt when ur working with modules frm the registry u hv to look below ,,, input : this is like the variable u can pass here, outputs ...., depencies
scroll down more , ull see for the same instance u can pass ur own values, so u are using the same module bt passing ur own values
when u click on inputs u see what u can pass 


   

3.6.00                        HOW TO USE THE OFFICIAL TERFRM MODULE 
     ***mee** it already has like a template for 'input', 'output', dependecies', 'resources eg ebs, 
so if ur using the official terfrm module, eg for instance, just copy the instance reource blk & paste in my own resource file then on the template, eg for inputs, i can see
all the things that it can input into the instance configuration, so i just read tru the template & see how i can pass the input in my own resource file 

eg1:   on the profie, to create iam instance profile, its set to false, but if i want to create/input it im my instance configuration i will say;
                           iam instance profile = true 

create_iam_instance_profile bool
Description: Determines whether an IAM instance profile is created or to use an existing IAM instance profile

Default: false


                      OVERRIDING THE DEFAULT VALUE OF THE OFFICIAL MODULE
eg2: the instance type is set to 't3 micro', so if i run the official module like that, its going to create a 't3 micro, for me  but if i dnt want t3,then in my resource file
where i pasted the offiicial module, i hv to indicate what i want eg; instance type = t2.medium or i can pass my value as a variable inside my variable file then, then my 
resource file whre i pasted the official module will read my values from my variable file, That way, it overrides the default value set in the module

instance_type string
Description: The type of instance to start

Default: "t3.micro"



  *** so u can find the code in the terfrm registry or most organisations will have their own private registry, mayb git , u may hv modules that hv already been created or 
********* so myab ur first task mayb to create a module for a vpc , we hv  a new env ,  we are now creatin an HR env, can u craete a vpc to be ddeployed in hat env
so u as an engr, u nid to knw wher ur resources are, u come to the documemtation and eithr create a custom module as we hv been doing or use an officIAL TRFRM MODULE frm the
registry n use it








**************3;11:15                         QUESTION
1) FOr the major , minor patches, u said we shud nt constrain it to a particualr version so it can get the particualar patches that are being done 
so if thers a major cahnge in the configufraion binary ,a major upate e.g fmr 1.5 to 2.00 , hw do i now update my version????????????????
will the use of * automtaically update the major part of the version
 
ANS:
lets says the version of our aws provider we'v constrained it to 3

3:10:20   (ignore,Just a passing statement)
 trfrm is declaractive, thats why i can put anything anywher i want , trefrm will read tru but when u cm to prod env u nid to arganize ur wrk
like this varaibles needs to go to vraiables file, provider ,ur data source , resources bt i was putin everytin togeda so that u guys can relate bt when we start refactoring 
then we hv to move everycode in its on place


                                           LOCK.hcl FILE/VERSIONING  (Answer to her question)
    THE FIRST Time u  run terfrm init, terfrm created for us this log file (terraform.lock.hcl) , the log file,it downloaded the versions n it locked them, this is the share
version of our provider aws, it downloaded the latest version , when subsequently u run terfrm init, it checks the log file, if its stil consistent, u hvnt updated any  
provider (to a diff version) it wnt go bk to donwload the plugins again. it wil reuse that dependencies it already downloaded

eg i just rsn terfrm init & we see it downloaded version 5... v5.42.0, which is the latest version 
but lets say ur code requires u to lock ur dependencies to may v3., ie we introduce a new configuration that sets my version to 3v & run terfrm init, it wil give me an error
bc v changed the version of my provider to 3.o  bt hv nt changed the logfile bc inside the lock file trfrm is reading whats in the log file which is 5.2.4 but what am now
passing as my required provider is 3.o 
so if i run terfrm init it is goin to fail bc in my package i hv 5.2.4 bt am trying to lock it to 3.0
bc whenever u run terrafrm init for the first time , terfrm downloads ur dependencies , 
****therfor if u cahnge ur provider version  or plugging but u hv run terfrm init before, to prevent it from failing u have to upgrade to upgrade ur pluggins ,

                                         MANAGING/UPGRADING PROVIDER PLUGGINS/VERSION
s0: run terfrm init -upgrade
now it will download the version which is 3.0 , so it is upgrading the lock version , so terfrn has made some cahges to the provider dependencies 
and in my lock file i can see the version is 3.76.1 bt the constraint is 3.0 , so this now becomes the depencies that terfrm is using , sO if i run terfrm init as long as
v constrain it , it wil nt go bk to download the dependcies again, it will reuse the dependecise
so this hw we manage our provider plugginds in term of version , so if terfrm does a change n it changes that , then u just hv to modify the constrian to that particular
vesrion bt u hv to upgrade ur puggins 



2) can i have more than 1 .tf file under the same folder???  ,,... since we dnt pas the name of the file when we run terfrm init ..

ANS: 
yes , when we refactor , we organize our env and create a file for each e.g resorces file, data file, provider file .. etc 
   now if i run terfrm init, it will initialize, terfrm wil read all the files and it will geneater for me the same plan as if they were all in the same file , ie  as if 
i didnt refactor 
so terfrm is declarative , it doesnt matter the number of files u have, it will reade tru all th efile and create a plan 


                                            2 DIFF PROVIDER FILES
3) e.g if u hv a provider aws and mayb mistakenly u created anoda provider that has azure or gcp 
how will terfrm read when u hv like 2 provider file wit diff values in them ????
   ANS:

provider = "aws " {
      region = var.region
}

provider "azurerm" {}
   ******************* ther are some other arguments am suppose to pass             .......... 3.24.20

  ****** when u run terfrm init , it will initialize the backend and we can look at our .terrafrm we see it now downloaded azure pluggins bt we already have aws pluggins
***meee** then i bliv its then left to you to decide if u want to create your resources using aws or azure bc u now hv dependencies for both providers



                                   CREATING A VARIABLE FOR TAG
4) when u map the variables to the prod , stage dev ,, how do we tag the resources so that it matches with the mapping???

  ANS:

  resource "aws_instance" "data_test" {
        ami = data.aws_ami.amazon_linux.id
        instance _type -var.instance[0] 

         tags = {
          Name = var.tags [0]
     }
  }

 varaiable "inst" {
    type = map      
    default = {
     " dev" = "t2.micro"
      "stage" = "t2.medium"
      "prod" = "t3.large"
  
   }
}
                        3.28.40              ***the variable TAG
varaiable "tags" {
    type = list(string)            ** i can create this as a list of string
    default = ["dev", "stage", "prod"]
}




3.30.50                                                     TERAFRM DESTROY
     5) THE Workflow terrafrom destroy
e.g u have 5 ec2 instance in aws and u wnt to specify just one to destroy, how can terrfrm do that

ANS:   ............. 3:30:30

  you can target

e.g
terrafrm state list
no state file found
so he ran terfrm init , terfrm plan, terfrm apply
then the s3 bucket resource we configured above was created
terfrm state list
data.aws_ami.amazon_linux
aws_instance.data_test
aws_s3_bucket.dev_env

todestroy the bucket:
terrafrm destroy -target=aws_s3_bucket.dev_env      .... to destroy the targeted resource

 its gives u the destroy plan but if i use auto destroy, it will automatically destroy it
now its destroyed 
3.37.35...bt if u run trfrm init, trfrm will think i want to recreate it again bc its stil in the configuration file , so if u dnt wnt it ot b recreated
u can delete it frm ur resource blk file (ie file where u hv all ur resources ie if u hv nt refactored meaning hv a diff file for variables)or comment it so trefrm doesnt 
see it

 now ,, terrafrm state ... we hv just this 2 left 
 
data.aws_ami.amazon_linux
aws_instance.data_test


 i can run terafrm state show aws_instance.data_test

it shows me the instance , hw its capturd in the state file  , if u want a specific thing frm the state file  , u run terfrm state show and the resource address

otherwise u can run terrafrm show , it shows you the instance and the data source

3.25.30... normally, i like working on one file then after evrytin is sorted out, i can refactor


                                            MOVED BLOCK (very important)
   used to rename or move our resources
**************  
LETS SAY I HV A RESOUREC IN MY STATE FILE 
      resource "aws_instance" "data_test"   and i change the name to    resource "aws_instance" "data_test1"
 if i run terfrm plan , it refreshes the state but plans to 
plan: 1 to add, 0 to change, 1 to destroy.  but why???
u lookn at the plan and u can see its planing to destroy an instance called  resource "aws_instance" "data_test" and 
add an instance called resource "aws_instance" "data_test1"

***********lets says ur boss ask you to change the name of a certain instance thats running in production, terfrm is goin to destroy it and recreate it 
this is what you dnt want to happen 
this is why we hv a 9th type of block called mOVED BLOCK





3:40:20
**************************  MOVED BLOCK   ,, used to rename our resources
E.G U USED TO Iive at point a  bt moved to point b , so ull go to the post office , u tell them i used to live here bt now there n give them ur forwarding address


in terrfrm , moved block u hv to define wher ur moving frm  ie 'test' to wher ur moving to 'test1'
i dnt intend to destroy my instance bt dis same instance used to be called 'data test' bt moving to data test1
so am using moved blk to relocate or rename my instance

 moved {
   from = aws_instance.data_test
   to = aws_instance.data_test1
}

now when i run terfrm plan , it will read the step 
it says : # plan :  it will add 0 , change 0 and destroy 0
# aws_instance.data_test has moved to aws_instance.data_test1  ........... so its nt destroying or deleting bt wihin the state file its just relocating the name

************** so evrytime ur working with trfrm, always run the plam first and look at what terfm is trying to do if ur comfortable with the plan then go ahead n apply

   ***********
in our case ur asked to change the name but ur not asked to destroy it so how are u goin to do it????
    we can easily use a moved blk to rename our resoures


if i needed to move this inside of a module then ican just give it the addreSs of the module and move the resource
 



             
    
















