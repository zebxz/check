************ version dertermines the syntax

WE CAN CREATE MODULE FOR VPC , USING VARIABLES TO MODULELARIZE MY CODE, TYPES OF VRAIABLES ,HOW DO U ACCESS VALUES IN A LIST, HOW TO REFERENCE VALUES IN A MAP, PASSING
VARIABLES AS A FILE, terraform.tfvars, auto files, QUESTION :terfrm init -upgrade, MOVED  BLOCK




###in summary ill say we created a data source and then used modules to make it flexible then using variables to modulerize the code , declaring a variable of type map, and
then using a variable file, 




 the installation process might REQ u to do some research, some times ther are somethings that are nt straight bc of the env, but this is why as an engr you wil use the skills
that u hv, use u knowledge of research & script & finding out frm the documentation & frm the vendor what is latest, bc sometimes u may b given a script dats outdated, that was
used last yr, and as u try to run it u find out that its not working, so through research & things like that we actually learn/find out how to do things & how not to do 
specific things




               TROUBLESHOOT INSTALLATION

Alexander was able to install it he sent the link in the chat /whenever you are installing a package, you have to make sure you an adminstrator or it wont allow you
1.50 ...youtube how to install terraform
another person said she couldnt unzip it

5.20 ... how she did her own using the link he sent , she had to closed the vscode & open it again after installing it on powershell
6.00 proff.. that is true, when you install a package on a certain terminal especially powershell, you need to close the terminal & reopen it
if u had your vscode the terminal running and you installed on powershell, u configure it so for it to be recognize on vscode u nid to open anoda terminal or close that 
terminal & reopen the terminal & once u do that it is going to pick up the path bc u already hv a terminal thats opens, so u just nid to close the terminal, close vscode & 
reopen it.

8.15    Choco wasnt recognized, install wasnt recognized
i downlaoded & extracted & create the path , but cudnt create terminal... terrafrm is still not working

  11.40 *** ALEXANDER said hes is also not working...
   i installed terrafrm on the terminal bt when i try to run terrafm init, it says the dir has no terfrm configuration files
so thats where i get stucked...

12.15 prof.. the system does nt lie if it says you dnt hv configuration files then you dnt have the file
the system is only reporting to you that in the dir there is no configuration file

 13.20 illustration:
 created a dir called project
cd ... takes us bk to the home where we see all the directories
cd/ project 
terraform init 
terrafrm initialized in a empty directory, the dir has no configuration files
the system is only reporting to you that in the dir there is no configuration file
then he created a file ... test.sh
terraform init 
   but we still got terrafrm initialized in a empty directory, the dir has no configuration files
    **** we still get error bc the file he created is nt .tf 
 he then created a file .. test.tf
terafrm read a .tf file but this file doesnt hv any content, it doeesnt hv any plugin bc terfrm doesnt knw wich puggin to download, so its just reporting that 
 its Initializing the backend
initializing provider pluggins
 terrafrm has been successfully initiated


          we will see what a backend is                   
16.40  wherever terrafrm operations is going to happen which is basically a local bc it will downlaod the terfrm file here, bt we dnt see any pluggins that hv been downloaded bc
terfrm doesnt know what pluggins/provider we need to use, so for me to do that i will apssa aprovider blk and am saying i want aws as my provider

 18.20
let me initiaize terrafrm , once i do that ...
now it is finding the latest version of hershicop/aws provider bc i told it i want my aws provider ryt here & so terfm installs the provider & downloads the plugging & creates
the .terrafrm/provider bc this is where/its inside here that it downloads the provider if u go inside the dir, it has downloaded frm the registry
hashicorp aws , we see the version (5.24.0/darwin.arm64)which is compartible wth the mark 'darwin' & it downloads it and brings it to your env bc you are running terfrm on 
your local env, so this provider will act as the API that is going to interact with aws
so whatever you are doing, whenevr terfrm reports that you hv initialized a dir but it says its empty so check to mk sure that whatever you are running the dir your in check to 
mk sure that you hv configuration files, to check run ls
so just run ls
if u hv a .tf, then it means you are in the right dir but if not then it means you are in the wrong path



        ****watch this
24.00                          USING VSCODE TO CLONE THE TERFRM REPO THAT HAS A RESOURCE BLOCK FILE

  HE DECiced to create a dir or open a folder
choose to create dir
mkdir class33-terraform
git clone https://github.com/LandmakTechnology/terraform-master-class-series.git


35.30  student had to share his screen 
    i see how to open powershell & use gitbash/bash terminal


38.15 .. another student said he has to save the file
she said whener u ls  & the main.tf showed zero, which means you had nothing inside thats how she knew it wasnt saved
  ****proff .. mk sure if ur using vscode put it on auto save that way u its easy, u dnt hv to worry about saving and all that

40.10   .. another student hv an issue, says  she does -version  says has an older version which she needs to update , it upgrades but its still nt working
   prof u can uninstall & reinstall or use package manger, it will try & install the latest version
for ur case as long as you hv terrafrm running, dnt worry abt aslong as u hv terfrm running we try & see how we manage diff versions of terfrm as we go on
bc ders a tool u can use to mg8 diff version of terfrm, right now as long as u hv terfrm wotking running, that shud be fine
but if u feel that you want the the latest version then unstall what u hv & reinstall the latest version


42.32 another student hv another issue ..  shared screen 
    46.00  ..     lol, shes drama
   

           **proff will send how to use vscode video





 48.10                             CLASS STARTS

49.50 
Terrrafrm init: initializes our working dir
whenvere we are running terfrm init
   terafrm configuration file has to be present in our environment for terrafrm to be able to intialize or download the appriopriate provider
 
Terfrm APPly
** desired state is determoned by my configuration file, if in the file i hv an ec2 instance that is t2 micro, then that is my desired state
i desire to hv an ec2 instance that is t2 micro, so terafrm apply will mk changes so that reach the desired state, so that what ever u hv in the configuration file matches
what is in the real word, matches what is in aws .

51.50
terrafrm destroy
when we no longer our resources, if u want to destroy specify infrastructure
as we go on u realise that you can pass on like cli arguments, you can pass them in the command line to target specific resources that you want to destroy




                    TERRAFRM VERSION DERTERMINES/ SYNTAX OF THE CONFIGURATION FILE
          syntax of hw diff versions of terfrm configuration files were written cud be diff based on the version of terrafrm 

                                  INTERVIW QUESTION   ................. 54:44
HOW DO YOU USE terrfrm setting blocks ( U SHUD BE ABLE to discuss this things abt setting ur rEq version & REQ provider version)

52.00
We also looked at the language syntax 
we started by saying terfm has 10 top setting blks
Depending on the terrafrm version that am running in my env, when i try to run my terfrm code based on hw the configuration files hv been written, bc of the version of terfrm
am running in my env it may give me errors bc the syntax of hw diff versions of terfrm configuration files were written cud be diff based on the version of terrafrm 
so if am running the latest version, it may support passing of arguments but mayb the earlier version didnt support this 
so depending on the version am running, it determines like the syntax, though most of them hv backward compartible, it wil jst give u warning that this has been depricated,
or u nid to update oru nid to upgrade, 

                                                 IN PRODUCTION 
but when it cms to prod u nid to constrain ur versions of terfrm so ur code doesnt break
eg we hv a code/project that was written 5/6 yrs ago, when terfm was verson 0.9 
when you look at the code syntax, it will look a little diff, if the code is running in prod then i nid to constrain the version of terfrm to 0.9 so that my code will stil run
if i run terfrm init, it will downlaod the ryt version of terfrm/the pluggin bc am constraining. 
bt if i leave it open , if i dnt pass the version then init will always download the current version
n when that happens my code may nt be comparible n it wil break n give me error 
so thats how we use terfrm setting block


for eg, this illustration ;for aws
     source  = "hashicorp/aws"
        version = "~> 3.0"

am constraining it to 3.0 but the latest version is about 5.o
but bc am constraining it, it will go and look for a an aws plugging/provider that is version 3.0



56.24
                      PROVIDER Blk
    when we dnt pass credential we say its goin to use a default profile
its not necessary to pass a profile as default, if its using default profile, but if its using any other profile then u hv to pass the profile with the name
also we can pass a region for my profile, & that overrides the region that i set when i did AWS configure


RESOURCE BLK
we use a resource blk to create anytin we want to create any resource


INput VARIABLES BLK
THis is were we can pass out input into terfrm ,
so instaed of hardcording values, like this  = "ami-0e5b6b6a9f3db6db8" , which is not reuseable & especially as we will be looking at modules
hardcoding is not really reuseable bc i hv restricted you that you can only use this AMI , thefore the code is not flexible
eg, only time you can use this Ami, if i had harded coded my instance as t2 micro, then it means that i  hv restricted that the instance can only use this AMi 
with a t2 micro type
but if i mk it flexible by using variables, am giving the user an option to change the varibale, cos a var is smt that can change
if am using a variable/variable blk, then i can set it like this:
variable "instance_type" {
  default     = "t2.micro"    or medium or t3 large ...  whatevr i want , i can change it
and when we ar workin with modules, we see that we v giving users the flexibility to pass in their own values
  if i wnt to create a t3large, then i can pass it without affecting or going to modify my code bc all i need to modify is the variable which is an input variable


1.01.00
OUTPUT VALUES BLK
after our resource hs been create an d we wnt to get a n attribute out of the resource then we use an output blk
we hv to configure an output, we hv to give it d value 
and the value of our output it uses dot (.) notation
we hv to reference our (resource type.the resource name.the attribute) 
e.g aws_instance.instl.public_ip       .... so this is referencing the resource eg instance, that we interested in.
eg of attributes we could want is: Arn, public ip, id etc  therefore it will be .Arn, or .id etc


LOCAL BLK  ..........1:09 
15.00  local.name   eg as we see the example below: local.business
we use local blk if we hv long names that we dnt want to repeat writing it in the code , we can define them in my locals blk and then just reference it in my code if this
is smt that is repeatative bc i may hv concatenating variables  e.g the BD  value is the (variable "vpc_name" and variable "my_env ), so i can jst define a locals blk n just
referencd it, so that makes my codes mangeable and easy to read bc hv done all my definitions in my local blk and am just referencing local
so i can put as many values in the local as i want if they are long names i might use inside of my code and then i just reference local
this is hw we use a locals blk


                                                          CREATING A LOCAL BLK


resource "aws_vpc" "my_vpc" {
   cidr _block ="10.0.0.0/16"

   tags = {
      Name = var.vpc_name
      Env = var.my_env                                     BD is the value of var.vpc_name & var.my_env
      BD = $(Var.vpc_name)-$(var.my_env)    if i want a business division (BD).... bc this is too long , iil rather define a locals blk, declare it & reference the locals blk
1.10,40  BD = local.business  ... so am referencing this as jst a local, it is frm the locals blk but its a key called business n d value of this takes the whole value 
     }                                     of this:  "$(var.vpc_name)"-"$(var.my_env)"  , but this value is read frm these variables (variable "vpc_name and variable "my_env)
   }                                                                                 wich wil translate to "my-vpc"_"prod"

variable "vpc_name" {
    type = string
    default = "my-vpc"
}

variable "my_env" {
  type = string
  default = "prod"
}

locals {
business = "$(var.vpc_name)"-"$(var.my_env)"

bucket_business = local.business   ( i did this myself based on the github note)

*********************** bc its a long name, i declare it in a locals blk 




 DATA SOURCE
########vidoe 3   ########### 15:20 
 we use data sources to get info to return info for us frm an API, IF WE wnt 2 get info frm AWS, mayb frm a vpc, AN INSTANCE, a s3 bucket, this obj we wnt to get info abt,
first it has to exist,   so if we hv an ec2 instance tht exists we are able to get info abt the instance ,  the id , public addres, its dns 
so we can use a data source and pass in our filters and we are able to filter out all d amis that are der and we are ablle to return jst the value of what we nid
we use data source for automation bc as engr u dnt want to go to d console to manually copy an ami or any info/attribute,instaed u can automate d proces by runing a comand 
an data source wil go fast into aws , it wil get the attribute/info that u need n terrafrm gives u a way wherby u can aripolate that, u can pass d it directly to d resource 
ur creating

e.g 
if we were  creating an instance, bc we hv a data source dat we are using, we able to directly pass taht as our AMI, N what we are pasing is that attribute we wnt to get
. we knw that the AMI nids to b an id, so we ar using a data source as it reads data frm that particular AMI source, we wnt it to return an id n as it returns an id we are
directin paasing it to d resource so d data source gets the infpoo n we pass it as an input to our resource n this is how we use data source to provision our resource 
#################



VIDEo 2
1.17.00   BLK 7: DATA SOURCE
A data ssource is what can go to AWs and fetch data from you




                                              CREATING/BUILDING A DATA SOURCE TO GET An AMI 'ID'
Ticket:
i)Create data source to get an AMi id
ii) use the data source to create an instance

lets create a data source for an AMi
ill create another file &call it data.tf

     ...... 1:17:35     create a data source for an AMI , we wnt to return a certain AMI 
first create n name the file and open it and startt56
YOU start to create a data source oR using a data blk with the keyword data, n data block needs 2 labels 


 
                                        HOW TO CHECK AMI ID  IN AMAZON
1.18.50***** when we go to aws, and look at amis, we are looking at the public registry/ images
we hv a lot of amis that are in the public registry, in this region , north virginia
normally, if i want to create an ec2 instance with an amazon linux, normally iil launch the instance afterwhich i hv the amazon linux ami, 
we can see the ami id, so i want to get the id
if i copy the id and go bk to the ami catalogue, & paste it in the search, i just want to search for the ami, it will show me/return tha ami
we see the name, the source, the owner, & the owner alias , its owned by aws, the platform is linux, the root device type is ebs 
if u click on the ami id, it shows the attribute of the ami


1) create the data source
1.21.00
        data "aws_ami" "amazon_linux" {   ...we want to return an amazon linux using the data so
          most_recent = true             .... we can see the date the ami was =created and req for the most recent ............1:21:01
         owners = ["amazon"]     we want the owner, its owned by amazon, its a list


                                                    APPLY OTHER FILTERS eg name
                                  we hv to put a filter name & a filter value

        filter {                  we wnt to filter the AMI bc when we are doing our search, it is goin to return all AMIs that ar owned by amazon n also d most recent
           name= "name"         we are trying to filter by the AMI name               so we ar goin to apply filters on the specific AMI that we wnt


                                     MAKING THE DATA SOURCE DYNAMIC SO THAT IT CAN GET AMIs FROM DIFF REGIONS
         values = ["al2023-ami-*-kernel-6.1-x86_64"]          ( we can remove the date n put* so it catches all the AMIs)
                                                                       ***its bc we can use this same data source to get diff AMIs  e.g wen we wnt toget AMI in a diff region
       
          filter {
             name = "root-device-type"
             values = ["ebs"]            this is also a list

Ls   .. i see data.tf file
when i run terfrm init, bc in my data source i hv referenced data_aws, therefore terfrm is sensitive enough to know that the plugging i desire to use is aws bc the data is
calling aws


                                           TROUBLESHOOTING
and terfrm validate error  ... set of string required
that means that everything needs to be a list , ie needs to be a list, bc its values
     initially he used the name like this  "al2023-ami-*-kernel-6.1-x86_64" , then corrected it by adding the calibres ..  ["al2023-ami-*-kernel-6.1-x86_64"]
and trfrm plan , it will read the data source n return for me the AMi ID , 
it will run this filters and return an id of an AMI
  successful.
so using just the AMi name, "root-device-type", etc, the data source was able to get the ID of the AMI for us.. 



1.32.20                                      HOW DO I NOW USE THIS ID  ????  
              
2) use the AMI ID, gotten above to create an instance
... remeber i hvnt gone to AWS to get this iD , hv jst used this data source
LETS SAY I want to create an ec2 instance 
so i can create a resource


                                    CREATE AN INSTANCE USING A VARIABLE TO PASS THE AM ID FROM THE DATA SOURCE TO THE RESOURCE BLK

  i)resource "aws_instance" "data_test" {        hes just calling it data_test ...meee ie the resource name
    1.32.20  
how do we reference the data source/attribute from a resource or data source, we always use the . notation
 ii)ami= data.aws_ami.amazonlinux.id     (.id , bc we nid the id)         ****  instead of me hardcoding the AMI value , i am gon to get the ami frm my data vsource
iii) instance_type = t2.micro                                                         so the id is the attribute i want from the data source

  *********** now when i run init, validate and plan , it will run the data source , get the id and replace the id for the AMI 
so i hv dynamically gone to aws n got the AMI and substitute it here ie in the plan we see 
bc of this i can use this data source to get my AMis dynamically


                         WE DIDNT PASS A REGION SO IT RETURNED AN AMI FROM OUR DEFAULT REGION 
the AMI we got belong to US west 2.,, bc thats my default region 


                       USING THE SAME DATA SOURCE TO DYNAMICALLY GET AN AMI FROM A REGION WE STATED IN THE PROVIDER
if i pass a provider bc in my code i dnt hv a proider n my provider is AWS and pass a region
*******************  provider = "aws " {
                        region = "us-east-1"

when i run trfrm plan , it wil return an AMI thats ends with 5369 bc of the region , it has used d filter to find the moist recent AMI in thta region bc theyb wil al hv dis
filter similar name bt is just finding that AMi in d specoific region 
so if i change my region , i dnt hv to go on d console to do it, to find that AMi, so now i hv dynamically created it and it has returned for me this AMi and now creating it in 
US east2
*********************if i change my region to US west1, am jst changin my region bt i v my dtatsource
my dtasource will fetch an AMI id that is now 491b , bc this AMI belongs to USwest1
so this is hw we can dynamically use datasourec to provision our resources , we are nt harcoding , instaed we ar usin dataasource to fget info for us ,so i dnt nid to go to
d console  to knw wich region i am in bc we knw AMIs AR REGION SPECIFIC Bt if i use  adatasourec it go to what eber region its bein provision n it lways get the aMi fro , 
AMInthat is specifuc to that ergion and am able to provison my instance

**************** so thats hw we use  data source and data blk
if ur asked to get a data source for a VPC , u wnt to get the VPC id , u can use a data source n build filters n it wil go to any particular region n it wil gett d id based
on the filters u applied 





blk 8: modules blk  ..................1:38:48
the key of working with terfrm as infrastructure as a code is the use of modules
modules make our code very flexible


                                    HOW DO WE CREATE MODULES .......... ?/?????
stepA
      so we v the main general dir called terrafrm master class33 and inside this dir lets say we hv a dir called test  
this is the dir that has my  tefrm config files 
bc all my code is in inside this test dir, so i can use this test dir 

                                         THIS DIR IS OUR EC2 MODULE
so i can use the test dir as my module to create an ec2 instance bc all my code is packaged in der


stepB                                      CALL THE EC2 MODULE
while am inside of the same dir (terrafrm master class33) as the test dir, i can create a neew file called main.tf
then inside this main.tf, i can (call the module) by using the key word 'module' for ec2

 mdoule " ec2" {     ************ ec2 is the module name
 source = "./test"         the argument that is reQ inside my module is the source, wher is d code/module coming frm ? what is the source of ur module?
                               so i can say that my source is this presnt dir bt inside of a dir called test

to initialize this module i need to be outside the test dir but inside the overall dir terrsfrm master class33
when i ls in the  terrsfrm master class33 dir, 
it is goin to see  all the dir and the main.tf file
so ryt here when i run terfm init, it will see only the main.tf file , it isthe only tf file taht it sees in this dir, bc its nt goin to read inside of other directries
when i run terfrm init, it first initialies the backend and then the moudeles



********************************INTERVIEW  QUETSIOM ************
WHats the purpose of terfrm init???
firstly, it initializes the backend then 
it initilizies or downloads the modules
thirdly, the provider

                             WHERE IS THE MODULE 
in the  terrsfrm master class33 dir , we see
 it has created a .terfrm dir and in the dir  thers a dir called modules and providers , cos when we ran terfrm init it downloaded modules and providers pluggins
we open the module dir , we see it has a module.json file bt its pointin the source is the test dir , ie it sayin the module soure is in the test dir whic is wher our files
are 
*******now we run terfrm plan , we see its initilizing it frm the module ec2 and its reading that particular datasoure n creating a resource bt its creating it as a module
n its creatin an instance called 'data test' which is part of our module.so this is hw we reuse values/code. 

we can apckage our code , create our code after we v tested  it , put in a dir n that becomes our module




1.47.00
2                                     WE CAN CREATE MODULE FOR VPC
in the overall dir terrsfrm master class33 

a)he created a dir called vpc and inside it he ceated a file called main.tf (earlier we created a main.tf in the terrafrm master class33 dir )& in the main.tf, he created a
vpc resource 

             ***we hv 2mian.tf, one in the general dir; terfrm master class33 dir & the other main.tf inside the vpc dir (the vpc dir is a sub dir in the terfrm master dir)

resource "aws_vpc" "vpc" {
     cidr_block = 10.0.0.0/16        ***so this is all i want inside this particular module & dis file is inside the vpc dir




                                         THIS DIR IS OUR VPC MODULE
   ****1.47.30... he said the vpc dir is a module to create the vpc


StepB                                           CALL THE VPC MODULE
now i can go bk to the main.tf file (where he used the keyword module to call the ec2 module) terrafrm master class33 & also use the keyword 'module' for vpc, to call the vpc
module

   module "vpc" {        **we can give it any name
       source = "./vpc"        **the source of this module is in the pwd, inside of  a dir called vpc


                                               
************ so now i v 2modules i am initializing, i v initialized the ec2 module earlier and now i hv a vpc module , so bc now i v added a new module the vpc, i need to run
terfrm init

                         RUN TERRAFRM INIT ANYTIME SMT IS ADDED TO A MODULE
so anytime u cahnge a module or add a module , u hv run terafrm init bc the module needs to be downloaded, d module nids to be initialized , 
so bc v added a new module here, this module lives in this vpc dir , inside of this vpc dir i hv my code bt wher am calling d module is on this file (main.tf in test dir)
am just refering wher my code lives


Step C
so in my terminal i run terferm init, bt if i just run terfrm plan, it wil say a ERROR, ders a module called vpc is nt installed 
afer runing trfrm init, i run terfrm plqn 
now its goin to create for me 2resources
the first plan we see is for the vpc with cidr  10.0.0.0/16
and also the  ec2 instance 
so i hv my code living here (test)tacked  away bt am calling them now as modules              ......1:51

****************tk note i didnt run terfrm apply yet*********** I NOTED dis here myself bc l8r on someone aksed if  DOES TERFRM DUPLICATE EACH  TIME WE RUN THE TRFRM COMMAN




                                      MAKING THE VARIABLE FLEXIBLE 
******************bt still this module  that am passin here is still nt very flexible bc if i give u this code to use n ur calling the module main.tf (where we called al the
module) in terrafrm master class33 dir


                                INSIDE main.tf in vpc dir
as it is,it means u are goin to use this cidr  10.0.0.0/16 but if i wnted to mk the cidr flexible, i will use a variable inside of the module/ vpc, main.tf  in( vpc dir)
i can create a variable:

     variable " cidr " {
           type = string        ( i am making it string and nt passing a defULT value, that way, i am making it  REQuired


And then i chnage the info in the vpc resource blk i created earlier   ....     
cidr_block = 10.0.0.0/16    to        cidr_block = var.cidr , so that u as the user can now supply the value

resource "aws_vpc" "vpc" {
     cidr_block = var.cidr

so i hv referenced the variable 
bt hv nt supplied the value so that u as the user can now supply the value bt frm this module/ vpc, main.tf  in( vpc dir) , we knw that it xpects  acidr blk 
 so then now i can cm to my mian.tf ((where we called al the moules, terrafrm master class33 dir) and on this module for vpc, i provide the value 
          module "vpc" {
       source = "./vpc"
       cidr = 10.0.0.0/16


                                  INSIDE MAIN.tf , where we called all the modules
now i can run terafrm init and trfrm plan , initializes the backend and plan reads the value frm the main.tf, where i called al d modules,in the terrafrm master class33 dir
so am supplying the value of the cidr as the user in the main.tf where am calling the module and if i edited the main.tf(in terfrm master class dir), am nt goin bk to the 
vpc main.tf file in the vpc dir
i dnt need to go bk to the  module/vpc (main.tf in vpc dir) to change the values,bc in the vpc file am making evrrytin as required/ or as varibales bt when am calling the
module , this is when am supplying the value bt i can equally mk it required so that i pass it as run time  ie comment it , bt if i dnt pass the value on the Main.tf where i
called all the modules



                                        USING VARIABLES TO MODULELARIZE MY CODE (when am making my varaiable required)..........................

bt if i dnt pass the value Main.tf where i called all the modules
1) it is goin to complain that this value is required
so on my main.tf, where i called all the modules, i need to declare it , i nid to declare a variable called cidr    bt still nt provide it (the value)   ****************1:55
         variable  "cidr" {
             type = string
 
bt  still complaining  ...... 1:55:27 , ie the codes were nt organized
      *************************************** i stil nid to format it 


                                           TERAFRM FORMAT
1:55:   \********************    terfrm format
so when i run terfrm format, it reformats your code , so that ur code is well organized the lines and all
this formtas your code 

now when i run terfrm plan it says missing reQ argument 
   so in the module vpc  ill 
 
module "vpc" {
       source = "./vpc"
       cidr = var.cidr       .......  its reading frm the module bt still i hvnt supplied the value so am still making it required

  variable  "cidr" {
             type = string

so if i run terfrm plan, it now requires me to enter the value bc hv now mk the value required


############## so this is hw we use variableas to modularize or to make our code as flexible as possible 
 



QUESTION:  ..... ..........1:58             .... watch 2:06 
1)
       DOES TERFRM DUPLICATE EACH  TIME WE RUN THE TRFRM COMMAND???
if you notice, i only run tfrm plan, i didnt run terfrm apply ,I WAS JUST TRYING TO GENERATE THE PLAN BC THIS IS HW WE TEST whether EVRYTIN IS WRKING 
bt if i created a new resource and run trfrm plan , we can see the plan is to add 1 and destroy 0 
module.ec2.aws_instance.data_test:Refreshing state  .. THIS MEANS its only refreshing the instance resource we already have 
# module.vpc.aws_vpc.vpc will be created   ......... this means  this new resource will be created
terfrm apply 
 we check the stste file we ssee the resource taht was added 

if i run trfrm apply again .. it says 
no changes, your infrastucture matches the configuration
bc the configuration matches what is ur current actual state, so its checking , refreshing what is in ur state file n comparing it wit ur configuratn,so bc it sees everytin 
matches ,ders nothing to change or add
bt if decide to add a like a tag on my vpc, it just means that am modifying my step ,wit that i can run trfrm init, trfrm plan, it sees ders a dif , it refrehes n statae n
say its now going to modify the vpc , it just updates, it goes to the vpc n put this tag 
   ********** terfrm state list shows hw many resources i hv captured in my state file 




2)    WHAT CRITERIA DO YOU LOOK AT TO KNOW THE VARIABLE TYPE TO USE 


  ******************* THIS TAKES us to varaibale types................   2:12

a variable is a 

1) string
2) numbers , e.g used for security grps 
    variable "https" {
        type = number 
        default = 443
3) boolean   , true/false  e.g usedfor nat gateway
     variable "nat" {
     type  = bool
     default = true

4) list : represented by a pair of square brackets containing a comma- seperated sequence of values, like ["a", 15, true]
   e.g a list of instance types ,   .......... i have multiple instance  type i want to choose from
      variabe "instance" {
          type = list [string]  .......     for a variable instance type i normally use string
          default = ["t2micro", "t2 medium", "t3 micro"]
            
************************       HOW DO U ACCESS VALUES IN A LIST **************
Values in a list are always accessed by an index and the index in a list always starts wit zero
   e.g       ["t2micro", "t2 medium", "t3 micro"]
         index    0,       1,             2

now to access this in this instance resource blk 

     resource "aws_instance" "data_test" {
        ami = data.aws_ami.amazon_linux.id
        instance _type -var.instance[0]         ..... index of 0 , ie i want the value thats at index position 0 which is t2 micro

***************** so dis is hw we access values in a list
so u can create a variable oftype list of strings , put ur values der, lets says u are creating a module that wil deploy inatnces both in the stage , dev n prod env n mayb
the req is hwen ur deploying in the stage env use a t2 micr, in the dev use a t2 medium, in the prod use a t3 large
so u can define a var with a list then based on the env u selsct the index, so ur just declaring on evariable , ur reading it frm one variable bt its a list of variables n 
ur selecting the index based on the env.

*************************2:27

5) Map
A map is basically key value pairs, thats what creates a map
whatever u hav inside tha brackets/calibras, these are key value pairs
so its is a map

bt we can declare a variable of type map
    varaiable "inst" {
    type = map       .... once i indicate a map" it is goin to open for me  brackets
    default = {
     " dev" = "t2.micro"
      "stage" = "t2.medium"
      "prod" = "t3.large"

so hv defined my map, map means i have mapped my env with the type of instance that i want

 2:29
******************************* HOW TO REFERENCE VALUES IN A MAP
ILL Use the square brackets but now instead of the index, bc our map is key value pairs, ill pass the key  ,  e.g dev , then terfrm wil return the value

  resource "aws_instance" "data_test" {
        ami = data.aws_ami.amazon_linux.id
        instance _type = var.inst["dev"] 

 key      value
dev" = "t2.micro"

so if i was asked to deploy in the dev env, ill pass dev bt i need to pass the correct variable and in this case its "inst"

now once i run trfrm plan , it will retuen my instance asa t2 micro
  ......... the is hw we reference values in a map using the key




**********************  iNPUT Varibale
declaring a variable but nt providing the default , thereby making it REQ






   OUTPUT  
attriibutes we tyr to get out


TUPLE
it has a mixed data type
ITS LIKE ALIST, IT can contain strings, numbers or othe r  list
tuple is objects within  a list while an OBJECT is a list within  a map



      OBJECT     ......2:37
Its like a map , bt a mix , key value pairs of both strings n numbers , list bt in the form of a map
so this is a list within a map

************************** this are the main type of variable we can pass inside our configuration


             PASSING VARIABLES AS A FILE    ( we can use a variables file to deploy in multiple env)
when u dnt want to pass these varaibles within ur configuration , terfrm always gives the option for u to pass them as files

e.g  if u want to pass a varaible as a file on the command line u can use an argument command line optional argument - var-file and reference the file that has ur variables,
the file has to end with .tfvars
    $ terafrm apply -var-file=foo.tfvars-var-file=bar.tvars


**************************2:39:30
so i can create a file taht has my variables    ..... call it variables.tfvars
to pass the variables file
   terfrm plan -var-file=variables.tfvars 
************this will read frm the variabel file n return whats needed 

**************2:46:50,,,............. WATCH
 we can use a variables file to deploy in multiple env

   ************INTERVIEW QUESTION
have u ever used trfrm to provisoin in diff env  ??????  ............ HOW do u do it

ANS:
 first  thing we v learnt is that i can use diff varibales fil;es
i can use a variAbles taht contains value for my staging , or anoda variables file that contains value for prod env,
 so am supplying this values at run time 
when trfrm is runningthis values file are beein run bc am passing them on the command line.
variable files are files that  starts with any name but ends with tf.vars , any file that hs this concvention u v to pas it on the CLI uing -var-file=
**************** 2:50
1)bt if u crtaete a file that starts wit terraform.tfvars  file, this file is automatically loaded u dnt hv to pass it on the command line , it has to start with terferm
then i can just run terfrm plan without supplying d values then d file wil be automaticaly loaded(normally we wil pas d file name  terafrm apply -var-file=foo.tfvars-var-file=bar.tvars)

so if u hv values u like to be automatically loaded the  u create a trfrm.tfvars , the values are automatically loaded

2) auto files   
e.g test.auto.tfvars
as long as ther is auto then the file will be automatically loaded

  ********* bt files without this options, that has a diff name like .tfvars file , then u hv to supply on th CLI as -var-file= bc its a named file 
 auto or terraforms files, are files that are automatic to trfrm 
as u keep writing codes n keep working, u will see a lot of code , a terrafrm.tfvars file are files that supply only your variables, u wil see this files a lotin code  that 
pipo use to supply the values bc they are making variables reQ so that u can supply UR OWN values, i can create a module (VPC, ec2) n leave all the variables REQ e.g the 
name, the cidr , the tags and ill ask u create a .tfvars file to supply the values,, that way u acn put ur own tag,name, cidr, and so that is now making ur code flexible, n
reusable , anyone one can reuse bc they can supply their own values , u hv nt hardcode values within terfrm 
thats hw we use variable files


 2:55:08  ################# CREATING A VARIABEL THAT HAS A SECRET##################
    YOU CAN MARK IT AS sensitive =true

        variable "mytype" {
          type = string
         sensitive = true

what this does is that , bc when trfrm writes the state fiel evrytin is written in plan text it doesnt encrpyt it 
everyone can read the state file , 
so if i want terfrm to mask it i hv to mark it as sensistive that way in the state file, trfrm will not genertae it, u wil nt be able to see it

   49:00



    ##############   QUESTION
1) on the work env are we prorvided wit these file for a project given to u or u hv to create ur own code  ??

ANS:
U as an engr thats why we are learnig trfrm , u may be reQ to write the trfrm code bt its very easy , 1) bc u hv a lot of documentation
e.g if ur asked to create an s3 bucket , u can type aws_s3_bucket in google , it take su to terfrm registry , it gives u e.g on hw to create an s3 bucket 
copy it n paste in ur id, ie file ur creating, and i can modifty , e.g its for the dev env

 EXAMPLE
                            PRIVATE bucket wit tags
       resource "aws_s3_bucket" "dev_env" {
  bucket = "example-bucket"    .... then i put the name of the bucket here

 tags= {    , i can pass my tag
 Name           ="my bucket"
 Environment    = "Dev"
}

     but also mayb ur boss may REQ other things   ............... 3:00
what else can u pass when ur creating ths bucket ?     so u look at ur argument  click on argument reference and read tru it 


********** also what we hv been creating here as we created our modules, these s3 bucket we copied is a moudle
we v been trying to create our own modules using resources, theese are called custom modules bt terfrm also has public modules or official modules 

e.g 
i want to create an instance
in google, i can type : aws instance module terrafrm  aws instance module terraform and it takes me to the registry an di see an aws instance module that has been created and 
i can copy it and paste :

  module "ec2-instance" {
  source  = "terraform-aws-modules/ec2-instance/aws"                    
  version = "5.6.1"
}                                                    3:05
              we se the source is frm the terfrm registry, so it wil be downlaoding the this version of module frm the regisrty
bt when ur working with modules frm the registry u hv to look below ,,, input : this is like the variable u can pass here, outputs ...., depencies
scroll down more , ull see for the same instance u can pass ur own values, so u are using the same odule bt passing ur own values
when u click on inputs u see what u can pass 


   ********* so myab ur firts task mayb to create a module for a vpc , we hv  a new env ,  we are now creatin an HR env, can u craete a vpc to be ddeployed in hat env
so u as an engr , u nid to knw wher ur resources are , u come to the documemtation and eithr createa ciutom module or use an officIAL TRFRM MODULE frm the registry n use it



3:10:20
 trfrm is declaractive, thats why i can put anything anywher i want , trefrm will read tru but when u cm to prod env u nid to arganize ur wrk
like this varaibles needs to go to vraiables file, provider ,ur data source , resources bt i was putin everytin togeda so that u guys can relate bt when we start refactoring 
then we hv to move everycode in its on place


**************3;11:15                         QUESTION
1) FOr the major , minor patches, u said we shud nt constrain it to a particualr version so it can get the particualar patches that are being done 
so if thers a major cahnge in the configufraion binary ,a major upate e.g fmr 1.5 to 2.00 , hw do i now update my version????????????????
 
ANS:

    THE FIRST Time u  run terfrm init terfrm created for us this log file (terraform.lock.hcl) , the log file,it downloaded the versions n it locked them, this is the share
version of our provider aws, it downloaded the latest version , when subsequently u run terfrm init, it checks the log file, if its stil consistent, u hvnt updated any  
provider it wnt go bk to donwload the plugins again. it wil reuse that depsncies

bt bc v changed the version of my providerto 3.o  bt hv nt changed the logfile bc inside the log file trfrm is reading whats in the log file which is 5.2.4
so if i run terfrm init it is goin to fail bc in my package i hv 5.2.4 bt am trying to lock it to 3.0

******** so whenever u run terrafrm init for the first time , terfrm downloads ur dependencies , therfor if u cahnge ur provider version n run  terfrm init again , it wil
fail so u have to upgrade to upgrade ur pluggins , s0: run terfrm init -upgrade
now it will download the version which is 3.0 , so it is upgrading the lock version , so terfrn has made some cahges to the provider dependencies 
and in my lock file i can see the version is 3.76.1 bt the constraint is 3.0 , so this now becomes the depencies that terfrm is using , s if i run terfrm init as long as v 
constrain it , it wil nt go bk to download the dependcies again, it will reuse the dependecise
so this hw we manage our provider pluggindsin term of version , so if terfrm does a change n it changes that , then u just hv to modify the constrian to that particular
vesrion bt u hv to upgrade ur puggins 

2) can i hvae more tahn 1 .tf file under the same folder???  ,,... since we dnt pas the name of the file whaen we run terfrm init ..

ANS: 
yes , when we refactor , we organize our env and create a file for each e.g resorces file, data file, provider file .. etc 
   now if i run terfrm init, it will initialize, terfrm wil read all the files and it will geneater for me the same plan as if they were all in the same file , ie  as if 
i didnt refactor 
so terfrm is declarative , it doesnt matter the number of files u have, it will reade tru all th efile and create a plan 

3) e.g if u hv a provider aws and mayb mistakenly u created anoda provider thathas azure or gcp 
how will terfrm read when u hv like 2 provider file wit diff values in them ????
   ANS:

provider = "aws " {
      region = var.region
}

provider "azurerm" {}
   ******************* ther are some other arguments am suppose to pass             .......... 3.24.20

  ************* when u run terfrm init , it will initialize the backend and we can look at .terrafrm we see it now downloaded azure pluggins bt we already have aws pluggins


3) when u map the variables to the prod , stage dev ,, how do we tag the resources so that it matches with the mapping???

  ANS:

  resource "aws_instance" "data_test" {
        ami = data.aws_ami.amazon_linux.id
        instance _type -var.instance[0] 

         tags = {
          Name = var.tags [0]
     }
  }

 varaiable "inst" {
    type = map      
    default = {
     " dev" = "t2.micro"
      "stage" = "t2.medium"
      "prod" = "t3.large"
  
   }
}

varaiable "tags" {
    type = list(string)      
    default = ["dev", "stage", "prod"]
}


     4) THE Workflow  terrafrom destroy
e.g u have 5 ec2 instance in aws and u wnt to specify just one to destroy, how can terrfrm do that

ANS:   ............. 3:30:30

  you can target

e.g
terrafrm state list
data.aws_ami.amazon_linux
aws_instance.data_test
aws_s3_bucket.dev_env
 terrafrm destroy -target=aws_s3_bucket.dev_env      .... to destroy the targeted resource

 its gives u the destroy plan but if i use auto destroy, it will automatically destroy it
now its destroyed 
bt if u run trfrm init, trfrm will think i want to recreate it again bc its stil in the configuration file , so if u dnt wnt it ot b recreated
u can delete it frm ur file or comment it so trefrm doesnt see it

 now ,, terrafrm state ... we hv just this 2 left 
 
data.aws_ami.amazon_linux
aws_instance.data_test


 i can run terafrm state show aws_instance.data_test

it shows me the instance , hw its capturd in the state file  , if u want a specific thing frm the state file  , u run terfrm state show and the resource address

otherwise u can run terrafrm show , it shows you the instance and the data source


**************  
LETS SAY I HV A RESOUREC IN MY STATE FILE 
      resource "aws_instance" "data_test"   and i change the name to    resource "aws_instance" "data_test1"
 if i run terfrm plan , it refreshes the state but plans to 
plan: 1 to add, 0 to change, 1 to destroy.  but why???
u looknat the plan and u can see its planing to destroy an instance called  resource "aws_instance" "data_test" and 
add an instance called resource "aws_instance" "data_test1"

***********lets says ur boss ask you to change the name of a certain instance tahst running in production, terfrm is goin to destroy it and recreate it 
this is what you dnt want to happen 
this is why we hv a 9th type of block called mOVED BLOCK





3:40:20
**************************  MOVED BLOCK   ,, used to rename our resources
E.G U USED TO Iive at point a  bt moved to point b , so ull go to the post office , u tell thme i used to live here bt now there n give them ur forwarding address


in terrfrm , moved block u hv to define wher ur moving frm test  to wher ur moving to test1
i dnt intend to destroy my instance bt dis same instance used to be called data test bt moving to dtat test1
so am using moved blk to relocate or rename my instance

 moved {
   from = aws_instance.data_test
   to = aws_instance.data_test1
}

now when i run terfrm plan , it will read the step 
it says : # plan :  it will add 0 , change 0 and destroy 0
# aws_instance.data_test has moved to aws_instance.data_test1  ........... so its nt destroying or deleting bt wihin the state file its just relocating the name

************** so evrytime ur working with trfrm, always run the plam first and look at what terfm is trying to do if ur comfortable with the plan then go ahead n apply

   ***********
in our case ur asked to change the name but ur not asked to destroy it so how are u goin to do it????
    we can easily use a moved blk to rename our resoures


if i needed to move this inside of a module then ican just give it the addres of the module and move the resource
 



              TRY AN ATTEMPT THIS TASK 

    

#############################################################################################################################################


################# TO CREATE VARIABLE 
We create the resource block with the  defaultvalues  (hardcoding)
e.g resource AMi
then we create the variable with type string and the default value 
e.g variable AMi
then go bk to the resource blk, remove the hardcoding we did ( default values) and and reference the variable 
ie :  ami = var.myami


********************   how do u mk a variable  REQuired?
by not giving a default value
when we dnt supply a default value, we make it rEQ variable
e.g , now, in the variable file, if i comment on the instance type, bt in the main file i stil refernce the variable , then the variable becomes a REQ variable







TERFRM SETTING 
u can put a partivular version of terfrm u wnt ur code to run with
~ we sue this symbol before the version
e.g "~>1.5"  .. this means thst the version of trfrm or this code can run with any version, again this is symetic versioning any version like terfrm 1.5 wit any path version
version is always in 3digits , major.minor.patch
the fisrt didgit is the major 
then minor 
then patch
e.g    major.minor.patch
           1.4.5 
so   amyb every 2wks they ar goin to update they value of terfrm, once they update they patch it up , mayb its a security or a bug 
so it goes frm 1.4.5 to 1.4.6 , 1.4.7
but lets say the update is a feature then it becomes 1.5.0 , then the patch wil reset to 0 
bc if i update a miNor version the patch wil reset to 0
what if i update a major version , if create a whole newv version of terfrm .... 2.0.0












