  
LINUX , scripting, git , maven, tomat/ngnix tomcat, sonar, nexus, jenkins , aws, docker, k8, terraform, ansible, k8/helm 
In our env, we use LINUX OS for file,process,package,security mgt, GIT FOR VERSIONING, MAVEN FOR BUILD, JENKINS automates the end to end process, 
AWS for cloud computing services/resources, DOCKER for containerization, KUBERNETES for 

 

so from warheouse associate to customer rep to business teacher, every single one of those led me to this point, i didnt trow any of those skills away & trust
mw when i say you gonna get a slice of every piece of it.



In docker applications run as containers   
QUESTIO .. 2:27:00
is docker a replacement for tomcat
no its nt , its a newer version to deploy appl by containerizing the appl including the appl code n all its components ,, with docker u can deploy any type of appl including
python,nodejs, tomcat, docker can containerize any form of apllication

************************************************



DOCKER7
### so when we talk abt a ntwrk its ensuring the devices are able to communicate with each other using containerIPS,under same docker network.
If Containers are in two different networks. They can't communicate/access each other.
types of netwrk
1) Default bridge network 
2) host network
3) none network

PROBLEMS WITH DEFAULT BRIDGE NTWRK
containers communicate with only the containerID
e.g  if a container was dead and it comes bk to life  e.g smt goes wrong n its recreated, it comes bk to life with a new IP address and as such communication
will be broken bc containers communicate with the ip adress in the default bridge ntwrk so for that reason, we use what is called custom bridge ntwrk. 

PROBLEMS OF MONOLETHIC ....................... 20;11
1)DIFFIcult to scale
eg if thers a spike  eg if 10million people are registering but only 1million is making payment, we will hv to scale up both the entire appl even though only 
1m is making payment,so thers a lot of waste with resource usage in monolethic design 
2)also micro service appli are light weight but monelethic are larger and thats a problem
3)lots of lines of code not easy to mange 
e.g if ur dealing wit a monolitic appl and ur code is in github we hv a single repository wich is for ebay only
if ur using just ebay, ebay could hv 
monolithic = ebay / 20,000 lines of code 


**************28:30     CUSTOM BRIDGE NTWRK
containers communicate with IPS and the container name, so even if a container is recreated, it will be recreated with the same container name so it can stil communicate wit
each other.

WHY IS IT IMP TO DECOUPLE
1)A Micor service architecture is easy to manage, 
2)its also easy to scale
microservices architecture wich ebay has been decoupled: login 2,000 lines of code, registration 4,000 lines of code, cart 2,000 lines of code, pay 6,000 lines of code 
order 2,000 lines of code, return 8,000 lines of code   
******* therfore micro services is easier to manage:

3)better/efficient resource usage : 
********e.g in a case wher the login increases frm 20m to 28m then i nid to scale login only, i dnt v to scale/modify the entire appl
    so micro services leads to better use of resource bc when u scale jst a component, it means the overall resources to be used wil be smaller 

4)****************versioning is easier to manage with microservices (bc we hv to modify some codes)
also if thers a new version of the appl that relates with only the login e.g we ar changing the login interface, then we dnt nid to modify the the entire 20,000 line of 
codes as with monolithic but only the 2,000lines of code for login for microservices


We support Java based applications:
===================================
We support nodeJS and .net based applications: (also some python base appl, like we saw when we were doing container, we deployed a python base application)

 For our micro service applications, in our environment, we hv legacy appl that are running as monolectic which as a devops engr we are now decoupling 
monoletic appl into micro services


 Deploy a microservice application for tesla.  
we are using an application developed using the spring boot framework
 while deploying this appl, it need a database
we need to deploy the springapp and the database - mongo   ... (the database in this case is mongo) as we can see it defined in github: data: 
  ie developers are  recommending the mongo database           
########copied frm the file in github:      ****** this application is developed using the spring boot framework
spring:
  data:
    mongodb:
      host: ${MONGO_DB_HOSTNAME} .. this is dynamic bc no values were given
      port: 27017
      username: ${MONGO_DB_USERNAME}
      password: ${MONGO_DB_PASSWORD}
      database: users
      authentication-database: admin
server:
  port: 8080


      




CONNECTING HOW APP IS DEPLOYED USING DOCKER AFTER CODE IS COMMITTED
Once developers commit the code to github The next step is to clone & build, the appl is cloned as a micro application, ie instead of deploying the appl as
a monothelic appl, we decouple it and then we have a micro service appl with stanalone entities, a repo for login, a repo registrtaion, a repo to cretae a
cart, a repo for returns,these ar the diff repo we hv created when it comes to this projeect, so when we pull this image we ar creating multiple packages e.g
login.jar up to retruns.jar, etc.
Next step is the netwrk, ie a group of servers communicating with each other using a specific netwrk, we make sure communication is established btw the
servers using the container name.  with the images of these stanalone entities built into containers we deploy our containers in these deployment server using
a custom bridge ntwrk so that the login container can communicate with registaration container ,cart container needs to communicate with pay container, 
we also v a db container etc and all of this is captured in the dabase container












***********   SUMMARIZED FOR INTRVIEW**********************
Am good with docker 1&2, 5&5b & some of 3&4 videos

In tomcat applications are deployed in heavy weight virtual machines VMs:
In docker applications are deployed in lightweight containers:
****i bliv the short fall of tomcat is resolved by docker & the short fall of docker is resolved by k8... 

In my environment we use docker to containerize applications ie applications run as containers
Docker: Is a containerization multi-platform software use to;create, build, ship, share and deploy containerize applications 
Compared to the Traditional/Physical Deployment & Virtualized Deployment options, containers are light weight,containers starts up very fast like a cheetah n the integration is very 
easy. containers also resolved the issue of repetitive task associated with the virtualized system, eg(having to install in the dev en & also testing env ) & thats because 
Docker containers: Is a Run time instance of a docker image docker image contains everything required for an application to run create or evry tin req for appl/process to run 
(App Files (code), Dependencies, (Softwares +Libraries), ENV vars & Other Configuration files) & we are able to build images from a docker file
we have a docker file from the file we build an image from the file n the process of building the image is called containerization IE PACKAGING THE APPL with all its DEPENCIEDS IN AN IMAGE N FRM DER WE AR
ABle to run containers/ deploy applications
1:42 we v a build server,with the server we executing mvn package, creating package , we ar also building images  using docker file, for docker build n once dat is done we
can distribute these images , we can use dockerhub or nexus ,or amazon ecr or jfrog to distribute the images .. these images are push into the image registry and frm
the registery a lot can be made to happen ,, we can pull the images and deploy appls in any enev, therfore ,we can pull the images for deployment, docker pull to pull
d image n docker run to deploy the application, in the deployment server we v the pull n run and dats where deployment is taking place and this can take place in
multiple env like dev, stage and prod,, the same image ,, we can deploy in any number of env... once they ar built these images are shared/distributed 
meaning it can be easily reused as many times as possible.
with the docker exec command we can interact with containers, get into containers troubleshoot issues and do a lot of other stuffs as well.
with docker cp command we can copy copying files and directories between a Docker container and the local filesystem of the Docker host without needing to 
restart or rebuild the container 
** mee*** and this is very useful bc the uptime of we appl is very important. we dnt hv to keep restarting our appl everytime we nid to mk changes so thats a 
plus with docker
when the process in a container is running der ar obviously some changes
when u deploy a container, der wil b some changes btw the container n the image wich was used to create the cointainer e.g we v copied some files into the 
container, and to know the changes that have occured in the container we use the 'docker diff command' docker diff container name/id
its the diff btw the image used to create the container n the changes tahe hv occurred in the container and inorder to maintain
the changes in future application , we can commiit the changes using the 'docker commit command' which enables us to extract an image frm a running container
***meee*** however k8 is a more powerful tool that knocks docker out the water & i'd be glad to expand more on that.



PROFF
#####u guys dnt nid to freakout, the big issue of docker u can explain it in less than 2minutes in an interview
my experience inclues writing docker files, maintaining docker files, to containerize our applications, we generally have java base application in our envr, 
we run those application on a CI/CD platform and before we run the application , we nid a odcker file to containerize it as part of the CI/CD process , so i am 
task to write and modify docker files and when i do so, i mk use of key Docker words like: FROM for my base image , COPY to copy files from the host to the 
container,RUN to execute commands ,CMD and ENTRYPOINT instruction to execute command while creating d container and it is important for me to make mention tht 
in writing my docker file in our env we mk use of docker file  best practices and these practices that we implement in our env include ensuring that our images 
are light weight and for that to happen, we are adviced nt to download unnecessary packages, nt to copy unnessary files into our containers, nt to use multiple
run instructios, so we use the && instructor as much as possible and that reduces the number of layers and by so doing we are going to be creating light weight
portaBLE images.also we only make use of official images as our base images, so docker official images those are the ones that we choose. in an attempt to keep
our images as light weight as possible, in our env we use alpine images as much as possible bc linux alpine is the lightest OS for linux that u can get bc docker
is intended to be light weight
In Passing our CMD and ENTRYPOINT Instructions, we are using executable form over shell form this will be enable our application process to run as a parent 
process and as such, it cannot be killed unnoticed
We also enabled scanning in our env, such that everytin is autoscanned and if thers any issue, pull REQ are been deployed for us to take remedial action 
*************docker is intended to be light weight bt then u nid to do smt to mk it light weight by making the right choices



WHAT IS SOME OF THE PROBLEMS U HAVE FCAED IN UR ENVR RECENTLY AS A DEVOPS ENGR.
we hv some of our docker files which we hv used to build and deploy applications and we had issues wher  applications were failing, endusers were complaining,
so i had to TS , ha sto check hw the docker files were written and i realized that our CMD were been passed in shell form and as a result, the applications 
process were been killed unnoticed and i quickly modify the dockerfile, changed it from shell form to executable form such that the application will run as a
parent process. 

there are some things u are going to explain, that will be the end of the interview , they wil knw that u knw, bc ther are some intricacies that somebody who is at work
whose hands are dirty like yours, u ar going to be making mention of them n they will knw this guy his hand is really dirty when it come sto containerization 
with docker






DOCKER5B
UESTION
with regards to out of memory issues, is der a way we can use autoscaling 
EVEN THOUGH WE Spoke abt out of memory, it rarely happens bc containeriztion itself has a lot of options that we ;ll look at when we get to kubertnets
### ull cm to realise that docker basically is going to ends with docker files
the rest we ar going to be using docker to create images, push the images and then use kubernetes to deploy the application
**** when it comes to deployment,we wont use docker to deploy bc docker cannot scale 
e.g u cant decide to deploy 10 replicas of webapp with docker but with kubernetes u can deploy as many replica as u want
bc docker cannot scale, it can only deploy one replica of an appliaction and that is a problem


*************** END**********************


  Is a containerization multi-platform software use to; create, build, ship, share and deploy containerize applications  
Docker is developed in Go Lang/Go Language.

O.S --> Cross Platform (Docker can be installed in any O.S)
        Docker Can Be Installed on Linux, Windows OS, macOS  
        Desktops as well as servers.

Docker is available in 2 Editions:

 1) Docker CE: --> Community Edition (Free to use)
 2) Docker EE: --> Enterprise Edition (Commercial/Licensed)
     EE is the docker CE+ is

Linux Flavors :there are diff linux flavors ie Linux distributors we can install docker on particularly the docker Community Edition 
 CentOS
 Amazon Linux
 Red Hat   : nt for docker CE 
 Ubuntu
 Debian
 Fedora
 SUSE Linux …etc




 DoKCER 5&5B


**************** this is wher he now applied this command 
##########copy from a container:  
copy from a container:
docker cp webapp:/usr/local/tomcat/webapps/tesla/jsps/home.jsp . 
docker cp webapp:/usr/local/tomcat/webapps .

docker exec webapp ls webapps/tesla/jsps
home.jsp
i wnt to copy this file called home.jsp n modify smt 
docker exce webapp ls webapps/tesla/jsps/home.jsp
now ders a command called docker cp
we wnt to copy the filw called home.jsp to the container called webapp
this relative path didnt wrk :.   docker cp webapp webapps/tesla/jsps/home.jsp .   ,, i bliv webapps is wher deployment takes place in tomcat
 WE run decker exec webapp pwd ,, we can see,  /usr/local/tomcat   ,   wich is the absolute path

1:40;34 **** so we use the absolute path ,, here we copied the webapps dir to the container webapp
docker cp webapp:/usr/local/tomcat/webapps .
and it says successfully copied to /home/ubuntu/.   ,, we wre unable to copy bc we wre using the relative path
ls n we can see /webapps  ...... i bliv this was copied to the pwd ,, i understand bt i can still ask ??????????????????????????????????????????????????????
now if i wnt to copy that exact file that is inside webapps (/tesla/jsps/home.jsp)
  docker cp webapp:/usr/local/tomcat/webapps/tesla/jsps/home.jsp . 
successfully copied , we can see /home.jsp ,,,, i bliv this was copied to the pwd ,, i understand bt i can still ask ??????????????????????????????????????????????????????
COPIED TO  /home/ubuntu/ .
#######  vi /home.jsp    , to change one line
we change the line but when we check on the browser , we stil cant seee the change
we wnt the change to b part of the container so i v to copy file to my container 

*******1:45:28 copy file to a container:
docker cp home.jsp webapp:/usr/local/tomcat/webapps/tesla/jsps/ 
now we v successfully copied it to the webapp conatiner 
it shows :COPIED TO webapp:/usr/local/tomcat/webapps/tesla/jsps/ 
and when we check in the browser we can see the line that we changed

