  
LINUX , scripting, git , maven, tomat/ngnix tomcat, sonar, nexus, jenkins , aws, docker, k8, terraform, ansible, k8/helm 
In our env, we use LINUX OS for file,process,package,security mgt, GIT FOR VERSIONING, MAVEN FOR BUILD, JENKINS automates the end to end process, 
AWS for cloud computing services/resources, DOCKER for containerization ie deploying light weight containers, KUBERNETES for container orchestration/MGT  

 

so from warheouse associate to customer rep to business teacher, every single one of those led me to this point, i didnt trow any of those skills away & trust
mw when i say you gonna get a slice of every piece of it.


*** if you think what uve have heard so far is interesting then you should let me introduce you to k8
AT this point you would think thats where the magic ends but no, you havnet heard about ansible & terraform.


In docker applications run as containers   
QUESTIO .. 2:27:00
is docker a replacement for tomcat
no its nt , its a newer version to deploy appl by containerizing the appl including the appl code n all its components ,, with docker u can deploy any type of appl including
python,nodejs, tomcat, docker can containerize any form of apllication

docker5&6
 MULTI STAGE DOCKER FILE
 multi stage docker file  :  it has multiple 'FROM' keyword


************************************************




***********   SUMMARIZED FOR INTRVIEW**********************
Am good with docker 1&2, 5&5b, docker7 & some of 3&4 videos

In tomcat applications are deployed in heavy weight virtual machines VMs:
In docker applications are deployed in lightweight containers:
****i bliv the short fall of tomcat is resolved by docker & the short fall of docker is resolved by k8... 
 so when we containerize with docker we ar going to manage those containers with kubernetes, dats what we wil be seeing

Docker is all about 
Docker files for creating docker images, Images for creating containers, containers are the run time of a docker image.
ONCE THE applications are containerized, we ar able to run containers
 and we need  networks--- (default bridge,custom bridge, host or null network) for the containers to communicate with each other communication[internal or
external] 
And finally volumes;volumes = storage/mounts for the containers, the storage can be stateless (does not store data), or stateful needs to maintain its state,
to prevent data loss,therefore it needs a piece of storage to capture data, data nids to be stored.this include data bases , applications like jenkins
   databases / jenkins, we use jenkis to be able to deploy a lot of works, so we hv jobs in jenkins.
so we can create a mountpoint and mount it wit the dockerhost server,he is the guy hosting all our containers.


In my environment we use docker to containerize applications ie applications run as containers
Docker: Is a containerization multi-platform software use to;create, build, ship, share and deploy containerize applications 
Compared to the Traditional/Physical Deployment & Virtualized Deployment options, containers are light weight,containers starts up very fast like a cheetah n the integration is very 
easy. containers also resolved the issue of repetitive task associated with the virtualized system, eg(having to install in the dev en & also testing env ) & thats because 
Docker containers: Is a Run time instance of a docker image, docker image contains everything required for an application to run create or evry tin req for appl/process to run 
(App Files (code), Dependencies, (Softwares +Libraries), ENV vars & Other Configuration files) & we are able to build images from a docker file
we have a docker file from the file we build an image from the file n the process of building the image is called containerization IE PACKAGING THE APPL with all its DEPENCIEDS IN AN IMAGE N FRM DER WE AR
ABle to run containers/ deploy applications
1:42 we v a build server,with the server we executing mvn package, creating package , we ar also building images  using docker file, for docker build n once dat is done we
can distribute these images , we can use dockerhub or nexus ,or amazon ecr or jfrog to distribute the images .. these images are push into the image registry and frm
the registery a lot can be made to happen ,, we can pull the images and deploy appls in any enev, therfore ,we can pull the images for deployment, docker pull to pull
d image n docker run to deploy the application, in the deployment server we v the pull n run and dats where deployment is taking place and this can take place in
multiple env like dev, stage and prod,, the same image ,, we can deploy in any number of env... once they ar built these images are shared/distributed 
meaning it can be easily reused as many times as possible.
with the docker exec command we can interact with containers, get into containers troubleshoot issues and do a lot of other stuffs as well.
with docker cp command we can copy copying files and directories between a Docker container and the local filesystem of the Docker host without needing to 
restart or rebuild the container 
** mee*** and this is very useful bc the uptime of we appl is very important. we dnt hv to keep restarting our appl everytime we nid to mk changes so thats a 
plus with docker
when the process in a container is running der ar obviously some changes
when u deploy a container, der wil b some changes btw the container n the image wich was used to create the cointainer e.g we v copied some files into the 
container, and to know the changes that have occured in the container we use the 'docker diff command' docker diff container name/id
its the diff btw the image used to create the container n the changes tahe hv occurred in the container and inorder to maintain
the changes in future application , we can commiit the changes using the 'docker commit command' which enables us to extract an image frm a running container
ONCE THE applications are containerized, we ar able to run containers
 and we need  networks--- (default bridge,custom bridge, host or null network) for the containers to communicate with each other communication[internal or
external] 
And then we have volumes;volumes = like bind mounts ie we can attach a piece of storage to the containers mount point because our data base can either be 
stateless (does not store data)or stateful needs to maintain its state,to prevent data loss,therefore it needs a piece of storage to capture data, data nids
to be stored.so we can create a mountpoint and mount it wit the dockerhost server,he is the guy hosting all our containers.so we can create a mountpoint &
mount it with the dockerhost server,he is the guy hosting all our containers.
FInally, in our env we create Monitoring dashboards, that monitors and report if there are issues, so if there is a problem, we are aware before the customers
starts complaining 

***meee*** however k8 is a more powerful tool that knocks docker out the water & i'd be glad to expand more on that.



PROFF
#####u guys dnt nid to freakout, the big issue of docker u can explain it in less than 2minutes in an interview
my experience inclues writing docker files, maintaining docker files, to containerize our applications, we generally have java base application in our envr, 
we run those application on a CI/CD platform and before we run the application , we nid a odcker file to containerize it as part of the CI/CD process , so i am 
task to write and modify docker files and when i do so, i mk use of key Docker words like: FROM for my base image , COPY to copy files from the host to the 
container,RUN to execute commands ,CMD and ENTRYPOINT instruction to execute command while creating d container and it is important for me to make mention tht 
in writing my docker file in our env we mk use of docker file  best practices and these practices that we implement in our env include ensuring that our images 
are light weight and for that to happen, we are adviced nt to download unnecessary packages, nt to copy unnessary files into our containers, nt to use multiple
run instructios, so we use the && instructor as much as possible and that reduces the number of layers and by so doing we are going to be creating light weight
portaBLE images.also we only make use of official images as our base images, so docker official images those are the ones that we choose. in an attempt to keep
our images as light weight as possible, in our env we use alpine images as much as possible bc linux alpine is the lightest OS for linux that u can get bc docker
is intended to be light weight
In Passing our CMD and ENTRYPOINT Instructions, we are using executable form over shell form this will be enable our application process to run as a parent 
process and as such, it cannot be killed unnoticed
We also enabled scanning in our env, such that everytin is auto scanned and if thers any issue, pull REQ are been deployed for us to take remedial action 
*************docker is intended to be light weight bt then u nid to do smt to mk it light weight by making the right choices



WHAT IS SOME OF THE PROBLEMS U HAVE FCAED IN UR ENVR RECENTLY AS A DEVOPS ENGR.
we hv some of our docker files which we hv used to build and deploy applications and we had issues wher  applications were failing, endusers were complaining,
so i had to TS , ha sto check hw the docker files were written and i realized that our CMD were been passed in shell form and as a result, the applications 
process were been killed unnoticed and i quickly modify the dockerfile, changed it from shell form to executable form such that the application will run as a
parent process. 

there are some things u are going to explain, that will be the end of the interview , they wil knw that u knw, bc ther are some intricacies that somebody who is at work
whose hands are dirty like yours, u ar going to be making mention of them n they will knw this guy his hand is really dirty when it come sto containerization 
with docker





**meee****
STEPS FOR HOW APP IS DEPLOYED USING DOCKER AFTER CODE IS COMMITTED
1)the first step is developers commiting codes to scm , then we use mave to build the application and deploy either in the tomacat or docker
for tomcat deployment takes place in the opt/webapps dir target dir and the packages are created in the the target dir of our project & also uploading the artifacts into the maven local/default
repo OR custom repo
2)But in our evn we use docker for deplyment therefore;
Once developers commit the code to github The next step is to clone & build, the appl is cloned as a micro application, ie instead of deploying the appl as
a monothelic appl, we decouple it and then we have a micro service appl with stanalone entities, a repo for login, a repo registrtaion, a repo to cretae a
cart, a repo for returns,these ar the diff repo we hv created when it comes to this projeect, so when we pull this image we ar creating multiple packages e.g
login.jar up to retruns.jar, etc.
3)Next step is the netwrk, ie a group of servers communicating with each other using a specific netwrk, therfore we create a netwrk to make sure communication 
is established btw the servers using the container name. so with the images of these stanalone entities built into containers we deploy our containers in 
these deployment server using a custom bridge ntwrk so that the login container can communicate with registaration container ,cart container needs to 
communicate with pay container, we also v a db container etc and all of this is captured in the dabase container (i bliv the inf needed frm endusers to access
the other containers will be captured in the db)
4)Next is volume, ie attaching a piece of storage to the container. it can be statless or stateful. and this takes us to the volume concept in docker;
bind mount our app container which is a STATELESS does nt store data, bt d database is STATEFUL n needs to maintain its state, to prevent data loss,therefore
it needs a piece of storage to capture data, so we can create a mountpoint and mount it wit the dockerhost server,he is the guy hosting all our containers.






*************** END**********************



 



DOCKER1&2
  CONTAINERS HAVE ALL THE REQUIRED DEPENDENCIES 
 *****now the quetsion is what can be done to be able to package d appl plus its dependencies n kip such dat if i wnt to deploy d appl all i hv to do is ship the app to 
the deployment env and it comes wit the dependencies already packged meaning ders no nid going to the dev enev n carry out conf, test n run , we can easily ship dis appli
how can we mk this process simplified?
therefore we will be usisng :
Containerization Software/Runtime --> : with this we can package an appl code plus its dependencies
 these ar the dif dockerization software
Docker, = over 80% usage , in the industry, it has the most level of trust

Docker:  
  Is a containerization multi-platform software use to;    
  create, build, ship, share and deploy containerize applications  


Dockerfiles are input use to build docker images, docker file is a simple text file that consists of instructions to build/assemble a docker image
Docker can build images by reading the instructions from a docker file

Docker images are input needed/used to create containerised applications  

Docker containers : Run time instance of a docker image 
                  if you execute: Docker run, a container is created from the image
DOCKER8&9
In tomcat applications are deployed in heavy weight virtual machines VMs:
In docker applications are deployed in lightweight containers:
****i bliv the short fall of tomcat is resolved by docker & the short fall of docker is resolved by k8... 
 so when we containerize with docker we ar going to manage those containers with kubernetes, dats what we wil be seeing

we use the docker client / wich is the cli, command line interface that permits u to run docker commands   
 = docker build/push/pull/run  (and this docker client generally starts with
   docker 

WE also have docker daemon
docker daemon/service =  this enforces the command that is run, e.g when u run docker build, the docker deamon knowns he has to create an image etc                                                                                   
  docker registry  , wher we ship images to and make them distributable0      = ship/share[dockerhub/ecr(elastic container registry) /nexus]    




DOCKER 8&9
docker run --name mongo --network tesla -e MONGO_INITDB_ROOT_USERNAME=devdb -e MONGO_INITDB_ROOT_PASSWORD=devdb@123 mongo
1.08.05    ****Mongo, is the host database hostname...  .... i didnt knw thats hostname, thought it was application name, or mayb its application hostname.




DOCKER7                  

                              APPLICATION ARCHITECTURE

DOCEKR8&9 we can use docker to containerize both monolithic and microservices application
' ... bt docker will shine more when it comes to micro services bc they ar very light weight & docker containers are light weight


 1)           MONOLETHIC APPLICATION
MONOLITHIC ARCHITECTURE: ebay webapp
this type of appl wher everytin is coupled together is called monolithic architecture, so it is developed using monolithic architecture
   if u wnt to acces thhis appl, it has cm with diff component : so when u acces this appl, u can login/registration/cart/pay/order/ 

 
PROBLEMS OF MONOLETHIC ....................... 
1)DIFFIcult to scale
eg if thers a spike  eg if 10million people are registering but only 1million is making payment, we will hv to scale up both the entire appl even though only 
1m is making payment,so thers a lot of waste with resource usage in monolethic design 
2)also micro service appli are light weight but monelethic are larger and thats a problem
3)lots of lines of code not easy to mange 
e.g if ur dealing wit a monolitic appl and ur code is in github we hv a single repository wich is for ebay only
if ur using just ebay, ebay could hv 
monolithic = ebay / 20,000 lines of code 


2)  MICROSERVICE APPLICATON
bt now we can decide to use microservices , with microservices, the monolethic application is decoupled, we hv each of theses appl  components decoupled
 ebay.war  = decoupled  , they are now stanalone entities
   login.jar/registration.jar/cart.jar/pay.jar/order.jar  return.jar  
************** so we hv decouples these appl from a monolithic to a micorservice appli
**meee*** Therfore beacuse the monlethic application has been decoupled into diff stanalone applications, when we deploy these seperate entities as
containers, we use network to ensure comunnication between them as well as our data base. we will be deploying these application with a data base 


WHY IS IT IMP TO DECOUPLE
1)A Micor service architecture is easy to manage, 
2)its also easy to scale
microservices architecture wich ebay has been decoupled: login 2,000 lines of code, registration 4,000 lines of code, cart 2,000 lines of code, pay 6,000 lines of code 
order 2,000 lines of code, return 8,000 lines of code   
******* therfore micro services is easier to manage:

3)better/efficient resource usage : 
********e.g in a case wher the login increases frm 20m to 28m then i nid to scale login only, i dnt v to scale/modify the entire appl
    so micro services leads to better use of resource bc when u scale jst a component, it means the overall resources to be used wil be smaller 

4)****************versioning is easier to manage with microservices (bc we hv to modify some codes)
also if thers a new version of the appl that relates with only the login e.g we ar changing the login interface, then we dnt nid to modify the the entire 20,000 line of 
codes as with monolithic but only the 2,000lines of code for login for microservices






               NETWORKS
### when we talk abt a ntwrk its ensuring the devices are able to communicate with each other using containerIPS,under same docker network.
If Containers are in two different networks. They can't communicate/access each other.
types of netwrk
1) Default bridge network 
2) host network
3) none network

PROBLEMS WITH DEFAULT BRIDGE NTWRK
containers communicate with only the containerID
e.g  if a container was dead and it comes bk to life  e.g smt goes wrong n its recreated, it comes bk to life with a new IP address and as such communication
will be broken bc containers communicate with the ip adress in the default bridge ntwrk so for that reason, we use what is called custom bridge ntwrk. 



**************28:30     CUSTOM BRIDGE NTWRK
containers communicate with IPS and the container name, so even if a container is recreated, it will be recreated with the same container name so it can stil communicate wit
each other.


  DIFF BTW THE TYPES OF NETWORKS

 ********docker 3&4 .... 1:25:00 to deploy a 2nd conatiner using the d same image, 
2 containers cannot v the same host port number& name  , bt can v the same conatainer number
host port must change ie we hv to choose a port nmuber for each contaoiner but container port is nt changing
**** docker7; networks:  
We can't create more than one container with d same container port in host network, except in the default bridge netwrk, bt we hv to do port publishing


1)DEFAULT BRIDE NETWRK
containers communicate with only the containerID
e.g  if a container was dead and it comes bk to life  e.g smt goes wrong n its recreated, it comes bk to life with a new IP address and as such communication
will be broken bc containers communicate with the ip adress in the default bridge ntwrk so for that reason, we use what is called custom bridge ntwrk. 
****mee*** in the default bridge netwrk, We can create more than one container with d same container port , bt we hv to do port publishing

Depploying in the bridge ntwrk: we dnt need to create a netwrk like we do for custom bridge netwrk
the normal way we  create & run containers, it now in the bridge ntwrk 
docker run --name app -d -p 8000:8080  mylandmarktech/java-web-app


2)CUSTOM BRIDGE NETWRK
 docker network create tesla        ***to create the tesla netwrk
containers communicate with IPS and the container name, so even if a container is recreated, it will be recreated with the same container name so it can stil communicate wit
each other.
  ***Deploying in the custom bridge ntwrk: we have to create a netwrk 
   create a ntwrk for tesla :  docker network create tesla
docker run --name app -d -p 8000:8080 --network tesla mylandmarktech/java-web-app

3)HOST NETWRK  
We can't create more than one container with d same container port in host network, except in the default bridge netwrk, bt we hv to do port publishing
         2.21.20   docker logs apps .. we see binding exception

Docker Host Network.:
If we create containers in host network. 
Container will not have IP Address. and we cant do port forwarding -p
 Container will be created in a system network.

Deploying in the host netwrk
docker run --name javaapp -d --network host mylandmarktech/java-web-app   
   ContainerPort: 8080                                                        ************ IT HAS ITS CONTAINER PORT 8080  
*********i can deploy the application & access this first application/container but if icreate .



4)NONE/NULL NETWRK
If we create container in none/null network. Container will not have IP Address.
We can't access  containers in this network  Internal or external 
****************** we can use this ntwrk to isolate containers

Deplying in the Null/None network
docker run --name hello -d --network none mylandmarktech/hello   
cant be accessed Internal or external 



We support Java based applications:
===================================
We support nodeJS and .net based applications: (also some python base appl, like we saw when we were doing container, we deployed a python base application)

 For our micro service applications, in our environment, we hv legacy appl that are running as monolectic which as a devops engr we are now decoupling 
monoletic appl into micro services


 Deploy a microservice application for tesla.     *** WE need the spring appl & a database 
we are using an application developed using the spring boot framework
 while deploying this appl, it need a database
we need to deploy the springapp and the database - mongo   ... (the database in this case is mongo) as we can see it defined in github: data: 
  ie developers are  recommending the mongo database           
########copied frm the file in github:      ****** this application is developed using the spring boot framework
spring:
  data:
    mongodb:
      host: ${MONGO_DB_HOSTNAME} .. this is dynamic bc no values were given
      port: 27017
      username: ${MONGO_DB_USERNAME}
      password: ${MONGO_DB_PASSWORD}
      database: users
      authentication-database: admin
server:
  port: 8080

bt we want to write images that dynamic, images that can run in any environment, so we can jst use diff envr variables 
this is an application that is being deployed and some inf needs to be captured so a database is needed.

                                          THIS APPLICATION NEEDS 2THINGS
*****meee****
1) the applictaion image , in this case its; springapp
2) the database image, in this case its; mongo

we need to deploy the springapp and the database - mongo   ... (the database in this case is mongo) as we can see it defined in github: data: 
  ie developers are  recommending the mongo database                                                                                     mongodb:

For thIS APPLICATION, we hv our images so we can pull bt i also nid a mongo image for db (he doesnt hv any mongo image in his repository) bt ders a mongo image in dockerhub
so once i pull this 2images am able to deploy my application
      



 

*******************************************************************************


DNT PRINT


DoKCER 5&5B      **** lol**** THIS is a wrong interpretation i did in 2024


**************** this is wher he now applied this command 
##########copy from a container:  
copy from a container:
docker cp webapp:/usr/local/tomcat/webapps/tesla/jsps/home.jsp . 
docker cp webapp:/usr/local/tomcat/webapps .

docker exec webapp ls webapps/tesla/jsps
home.jsp
i wnt to copy this file called home.jsp n modify smt 
docker exce webapp ls webapps/tesla/jsps/home.jsp
now ders a command called docker cp
we wnt to copy the filw called home.jsp to the container called webapp
this relative path didnt wrk :.   docker cp webapp webapps/tesla/jsps/home.jsp .   ,, i bliv webapps is wher deployment takes place in tomcat
 WE run decker exec webapp pwd ,, we can see,  /usr/local/tomcat   ,   wich is the absolute path

1:40;34 **** so we use the absolute path ,, here we copied the webapps dir to the container webapp
docker cp webapp:/usr/local/tomcat/webapps .
and it says successfully copied to /home/ubuntu/.   ,, we wre unable to copy bc we wre using the relative path
ls n we can see /webapps  ...... i bliv this was copied to the pwd ,, i understand bt i can still ask ??????????????????????????????????????????????????????
now if i wnt to copy that exact file that is inside webapps (/tesla/jsps/home.jsp)
  docker cp webapp:/usr/local/tomcat/webapps/tesla/jsps/home.jsp . 
successfully copied , we can see /home.jsp ,,,, i bliv this was copied to the pwd ,, i understand bt i can still ask ??????????????????????????????????????????????????????
COPIED TO  /home/ubuntu/ .
#######  vi /home.jsp    , to change one line
we change the line but when we check on the browser , we stil cant seee the change
we wnt the change to b part of the container so i v to copy file to my container 

*******1:45:28 copy file to a container:
docker cp home.jsp webapp:/usr/local/tomcat/webapps/tesla/jsps/ 
now we v successfully copied it to the webapp conatiner 
it shows :COPIED TO webapp:/usr/local/tomcat/webapps/tesla/jsps/ 
and when we check in the browser we can see the line that we changed





