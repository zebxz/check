\1:27 ........we studied devops with aws, linux and k8  
****************************************************************************************************
1:51:20   ****he said we are talking abt hw we deploy applictaions in k8 
kubernetes Service , FQDN = Fully Qualified Domain name.,,what is Static Pods ?,, controllers, CONTROL MANAGERS, HOW TO CREATE A REPLICATION controller, 
that wil be creating a particular pod

HOW POD IS MANGED ,create a secret for dockerhub
 

********************************************************************************************************************
1:51:20   ****he said we are talking abt hw we deploy applictaions in k8 which is a very key aspect when it comes to your understanding with k8
we shud be able to esta the fact that applications are deployed in ports

 ILLUSTRATION  ( 1 to 8), SET CONFIGURED NAMESPACE TO CURRENT NAMESPACE/ CURRENT CONTEXT, DEPLOYING A POD USING DECLARATIVE APPROACH (MANIFEST FILE),
TROUBLESHOOTING,  SERVICE DISCOVERY, LABELS & SELECTORS EXPLAINED, KUBERNETES SERVICE, CREATING SERVICE TYPE; CLUSTERip, FQDN, APPLYING FQDN, 
USING THE 'EXEC -it' TO RUN FQDN, CANT USE THE SERVICE TO COMM BTW PODS IN DIFF NS, USING SERVICE NAME TO COMM WITH PODS INSIDE THE SAME NS, 
DISADVANTAGES OF POD, STATIC PODS, USING MANIFEST FILE TO CREATE STATIC POD,  CONTROLLER MANAGERS,  WORKLOADS, k8 POD LIFE CYCLE, 
USING MANIFEST FILE TO CREATE A REPLICATION, NODEPORT SERVICE MANIFEST FILE, KUBEPROXY/ENDPOINTS/NODEPORT, NODE PORT COMES WITH CLUSTERIP, COMMANDS FOR
REPLICATOR CONTROLLERS, WE CAN SCALE WITH RC, WE ONLY USE DOCKER TO, WHERE APPLICATIONS ARE DEPLOYED IN K8, HOW POD IS MANGED, REPLICA SET, CREATING a 
rePLICA SET, DEPLOYING appl using RS, NODE PORT COMES WITH CLUSTERIP,  PULL IMAGE FROM PRIVATE REPO, DIDNT BUILD, TAGGED IT & PUSHED IT, DEPLOYING REPLICA 
SET WITH MANIFEST FILE , CREATE SECRET FOR DOCKER HUB, APPLY THE SECRET TO THE MANIFEST FILE, USE THE NODEPORT'S CLUSTERIP & API's, REPLICA SET TEMPLATE



****from video 1&2

NAMESAPCE     ***i bliv its kinda similar to label & restriction in docker swamp
1:34:30  **********************generally for this deployment to tk place even in k8, we will make use of a namespace
how DO WE ENSURE THE APPL ARE ABLE TO COMMUNICATION  & all of that , ders a concept in k8 called:
Namespace:
  It is a virtual cluster inside your cluster  ,,, we can create a name space for dev stage, uat stage , prod stage , sales ... dependn on d project u are managing
     [ dev / uat / prod ],                            if u create a namespace for e.g, u wnat a situatn wher what dev ar doin does nt affect what is runin in uat &prod
     [sales, accounts, cs, payroll]                so we can use name spaces for isolation, we'l isolate d dev env frm uat, frm prod using namespaces



            ILLUSTRATION  ( 1 to 8)  showing steps to follow from the installation to how to esta comm but containers 

After installing the multi node cluster
creater 3servers (one for the master node &  the other 2 is for the worker nodes)
next;
1)created dev namespace
ubuntu@master:~$ kubectl create namespace dev --v=8  
kubectl create namespace prod

2) created pod for container 'hello'
# Create POD Using Command
kubectl run <podName> --image=<imageName> --port=<containerPort> -n <namespaceName>
pod/hello created
ubuntu@master:~$ kubectl get pod
no resources found in default namespace 
   no resources found in the default namespace    ****************************** this is set to my current context , its my current name space
ubuntu@master:~$ kubectl get po -n dev          *** i had to specify that i want resoures in the '-n dev' namespace bc i hv not set 'current context' to 'dev'
NAME    READY      STATUS       RESTARTS      AGE
hello     1/1      running         0            11s
*********************************we have been able to deploy this application

3)created pod for container webapp
Used manifest file to create pod


*** VIdeo 3&4, starts...

4)    SET CONFIGURED NAMESPACE TO CURRENT NAMESPACE/ CURRENT CONTEXT
originally, the default namespace is the 'current namspace'
*Mee*by default, kubectl get po' lists the pods in the configured ns, BUT you hv to run the 'kubectl config set-context' command, to set the ns you configured/
created to be the current ns/current context' BC in (no.2) above, it says .. no resources found in the default namespace   

kubectl config set-context --current --namespace=dev       ** now its be set
ubuntu@master:~$ kubectl get po     ....***********now  kubectl get po, lists d pods in the dev namespace, bc d dev namespace has become my current namespace


  **** created now sets of pods, so forget about the 2pods he created from video 1&2 (which are the step3&3 above)
5)USED MANIFEST FILE TO DEPLOY POD ... Called hello
to deploy the manifestfile  we created below it wil deploy a pod called hello   *** now using pod to replace what we called image we create when we build 
mkdir manifests                                                                                                             an app in docker
vi manifest/hello.yml  and paste the file 
kubectl apply -f manifest

6) *** seen below        USE OF CLUSTERIP SERVICE
created service called HelloSVC  for 'hello' to enable communication btw another app call webapp
HelloSVC is a (clusterip service), the cluster-ip  10.105.209.246(which is the service ip) **clusterip its a k8 service used for internal comm within d cluster
Curl  cluster-ip   10.105.209.246        ,, and we successfully communicated with the app usin d service ip address
When I wnt to curl, we curl on port 80 cos if my service port was smt else then I v to write the port number but since it is 80 , I can curl without it

So my hellosvc is a clusterip service  and it has a service ip address, so when the webapp is trying to comm wit it its going to use this service n the
webapp talks to the service on the service port, port80 and the service is routing the traffic to the appl on the appl port number , d container port number
wich is also port80 in this case

7)APPLYING FQDN         **** If one POD need to access service & which are in different names space we have to use the FQDN of the service.
let me jst use a command to create a new pod   in the default namespace
kubectl run web --image=mylandmarktech/java-web-app --port=8080 -n default    ***now, i v a pod, the name of my container is web, in default namespace
ubuntu@master:~$   kubectl exec -it web -n default bash         .....  
root@web:/usr/local/tomcat#  curl hellosvc.dev.svc.cluster.local        *** web container est comm with the hello container using the FQDN command  
we successfully commu with the container (they are in 2diff name space)     

8)SERVICE NAME
we cant est communication btw containers in diff name space using the service name  BUT we can if use the service name if the containers are in the same ns

***  in k8, the pod lifecycle is very short so if we ar going to deploy appl, we shud nt use pod
We should not create pods directly to deploy applications.
If a node  goes down in which pods are running, Pods will not be rescheduled.
We have to create pods using controllers which manages the POD life cycle.
controllerManagers: eg RC, RS, deployment, daemon set.
**** therefore in the manifest file, kind will be 'rc' & we will also hv a template for pod inside the same manifest file & if we need to create service, 
we wil also have a template/section for service

9) Controller manager....   continue with the rest of the video from there..  1.05.00
    we can scale WIth controller mangers but we cant scale with pod
We scale based on demands, if Request increases, we scale up
kubernetes is used to Orchestrate containers     .. .. .with k8, we can scale,, if a junior engr mistakenly delete our pods, k8 will automatically recreate them 
1:49:30**************** ..... there is no component in docker that is capable of recreating containers,, so we shudnt use a software taht is limited ,but
docker is nt completely useless, so we are studying docker bc we dnt need to use k8 to create docker files and build images, k8 does nt use docker files to
build n share images in image registry so we nid docker to be able to create a docker file,build images and share those images to docker registry so that 
k8 can pull the images to deploy application

***if we dnt pass replica, its goin to create one...


 therefore in the manifest file, kind will be 'rc' & we will also hv a template for pod inside the same manifest file & if we need to create service, we wil
                        also have a template/section for service



        ***** VIDEO 3&4 starts

ubuntu@master:~$ kubectl get po       **** By default, it lists pods in the currently configured namespace.
no resources found in the default namespace    ****************************** this is set to my current context , its my current name space

ubuntu@master:~$ kubectl get po -n dev    ............**************** we can see some pod that v been  deployed in the dev namespace
NAME      READY      STATUS       RESTARTS      AGE
hello     1/1       running         0            8m38s
webapp    1/1       running         0             12s



                                SET CONFIGURED NAMESPACE TO CURRENT NAMESPACE
originally, the default namespace is the 'current namspace'    *** i bliv it means the 'default namespace' was created by the k8 system.
*Mee*by default, kubectl get po' lists the pods in the configured ns, BUT you hv to run the 'kubectl config set-context' command, to set the ns you configured/
created to be the current ns ....   even after we set this, we can still create other pods in the default space by indicating '-n default' as the namespace.

 WHEN I RUN  kubectl get po  i want it TO LIST THE pods in my (dev namespace) in the default namespace
----
at the moment the default namespace is my current namespace, thats why when i execute  kubectl get po , it says no resources in the default namespace bt once
i run :
kubectl config set-context --current --namespace=dev       **v modified my current workspace such that if i execute  kubectl get po it lists d pods in the
dev namespace

ubuntu@master:~$ kubectl get po     ....******************************  kubectl get po it lists d pods in the dev namespace, so d dev namespace has become my current  
NAME      READY      STATUS       RESTARTS      AGE                                                                                    namespace
hello     1/1       running         0            8m38s
webapp    1/1       running         0             12s

**************originally, it was the default namespace that was the current namspace but i v changed my context to dev
SO even if i dont state/indicate the namespace in the manifest file, the app will be deployed in (dev namespace we made)it our default namespace by modifing 
it above
                                                                              


########################### MORE PODS COMMANDS ............7:25
kubectl get all
kubectl get events
kubectl delete po (podname)
kubectl delete all --all 
kubectl delete all --all -n dev     
kubectl delete pod --all                                                                                               interpretin , creatin &mangin d pod 
kubectl get pods                               Anotation is a metadata info abt ur pod that is set by d sys/k8 service n it is what d sys wil understan when it comes to
kubectl get pods -o yaml   ...   will present the pod in that are runnin in our clustera yml file, we can see annotation,bt when we made d file to create d
                                                                                                            pod der was no anotation
kubectl get pods --show-labels
kubectl get pods -o wide           **************** gives more inf abt the pods
kubectl get pods -o wide --show-labels
kubectl get node
kubectl get node -o wide    *************** we see d nodes we v , the k8 version, the kernel version and the runtime which is containerd and not docker .(tk note)
kubectl delete node node5   ******************* to delete node5

in docker we run: docker inspect  to get more info abt the container
kubectl  describe pod <podName>      *********to get more info abt the pod 
kubectl  describe pod <podName> -n <namespace>




                                     DEPLOYING A POD USING DECLARATIVE APPROACH (MANIFEST FILE)
16:10:00
kubectl run <podName> --image=<imageName> --port=<containerPort> -n <namespaceName>
kubectl run hello --image=mylandmarktech/hello --port=80 -n dev 
kubectl run app --image=mylandmarktech/hello --port=80              ... dis wil deploy a pod called hello
 

hello.yml       >>>>>>>>>>>>>>>>   using the declaractive approach  ....  (20:50) *********WE want to creat/deploy an appl called pod (i think he meant hello)
=========   kams     ........ this is the acronmy, it stands for kind,apiversion, metadata, spec
kind: Pod   
apiVersion: v1    
metadata: 
   name: hello                   *** i bliv pod name is hello
   labels:                            ** this is wrong as explained in the 'TROUBLESHOOTING' below, label is a dictionary not a list
     -app: hello           ** i bliv app is the label & the hello is the container name, for service to discover the pod, we need the 'key value pair' app:hello
spec:                                         ***online. the label must not be the same as the container name
   containers:
   - name: hello      **i bliv container name is also hello
     image: mylandmarktech/hello  
     ports:                                          *********with dis definition file, we can deploy our application ,,,
     - containerPort: 80      #######  we did nt declacre our  namespace so.. but what is our current namespace???/ wher wil d app wil be deployed (dev namespace bc we made)
                                                                                                        it our default namespace by modifing it above
***********************************************************************************************************************************************************
kubectl api-resources   *********** to get the apiresources for our pod,, we can see so many api resources , ...
kubectl api-resources | grep pod      ....  so to specify n grep for pod , we see we can either call it pods or po and the apiversion is v1
******************************************************************************************

########## to deploy the manifestfile  we created above 
mkdir manifests
vi manifest/hello.yml and paste the file 
kubectl apply -f manifest


                                    TROUBLESHOOTING
ubuntu@master:~$ kubectl apply -f manifest
error: unable to edcode "manifest/hello.yml:json cannot unmarshla array into 
       GO struct field ObjectMeta.metadata.labels of type map[string}string

************************so he vi again into the file and saw that he listed label' bt its suppose to be a dictionary not a list 
    metadata: 
   name: hello
   labels:
     -app: hello     .....so he corrected it to  app: hello
  
ubuntu@master:~$ kubectl apply -f manifest
pod/hello created
ubuntu@master:~$ kubectl get all
NAME            READY       STATUS      RESTARTS       AGE
Pod/hello         1/1        Running     0              18s         **** the pod is running bt hw do we discover the pod in our clutser?  service discovery




                                      SERVICE DISCOVERY
ServiceDicovery:
==============
*********the first service type is:
ClusterIP is the default kubernetes service type that support
communication within the cluster. 
************** to communicate within our cluster, we will use a clusterip service type                                            
e.g we v the hello app on node1,& d webapp on node9 ,, for webapp to comm with hekllo app, we v to create a service for our helloapp, Lets call it;
helloSVC n D sevice type is clusterip
if u look at the pod we created in the definition file , we v a label; app is mapped to hello
POD=labels:
  app: hello            *******........... app is mapped to hello
Serice = selectors:  
   app: hello  



                                LABELS & SELECTORS EXPLAINED
****SERVice makes pods accessible using labels & selectors

********************* for a service to deiscover any pod, its going to be using labels, so what is the label of the pod
so we v labelas n we also v selectors...  so ders a label that says app is mapped to hello, its under the pod, so we v Pod label, so 
under service, we ar goin to v sevice selectors
in my k8 cluster der wil b many sevices,  hw wil the service be able to identify this pod,, it nids to create a selector that matches this pod like that so
... (hello)
#########so in the hello service (helloSVC), ther will be a selector, n the selector s saying app, bc this selector depends on the pod, so in the app pod, 
we v a label; app is mapped to hello 
*******************
        ***kub1&2, 1.36.42... webService is the clusterip..... 

webService                                        hello
helloSVC                                          labels
selector                                         app:hello
app:hello               d 'app' has a container port  80     ***i think this should be 'hello' not app, cos 'hello' is the container name
ClusteriP                 
targetport80       when u create a service, wher u v the container port will be represented by the target port, so d servixe is targeting port80
 so the webapp wants to com with thw helloapp , d webbapp can nt comm with d helloapp directly in the cluster, its nt supported in k8, so hw is the com to 
be established?,
via service discovery..

lets assume the webapp pod has its own label:
webapp
app:web
8080           container port
so the webapp wants to com with thw helloapp, the comm is goin to be est via the helloSVC ,webapp is goin to route traffic to the service that is controling
the hello pod
once it does that, then the service will comm with the pod in this order
this is service within the cluster
in k8 we can create a service and we will look at theta very soon 

lets talk abt k8 SVC:  .........,30:52


                                    KUBERNETES SERVICE
   ****SERVice makes pods accessible using labels & selectors
                     
kubernetes Service:
  In Kubernetes Service makes our pods accessible/discoverable 
  within the cluster or exposing them outside  the cluster.
  service will identify pods using it's labels And Selector. 
  Whenever we create a service a ClusterIP (virtual IP) Address 
  will be allocated for that serivce and DNS entry will be created for that IP.
  So internally we can access using service name(DNS).

2174  2409
                              ########CREATING SERVICE TYPE; CLUSTERip
hellosvc.yml  
=========== kams    ..... .....acronmy
kind: Service  
apiVersion: v1  
metadata:
  name: hellosvc    ... i can assign a servicename
spec:
   type: ClusterIP    ...service type      ***** used for internal communication within the cluster
   selector:   ... hw wil the service be identified or hw will it identify the app that its suppose to route traffic to ., it wil be based on the label of the appl
      app: hello     .... its hello bc refferring to the manifest/identifictaion file we used to create the hello pod above ,, the label says app:hello
   ports:                                                                              therefore, my selector will be hello, so it can route traffic to the appl
   - port: 80           ......service port  bc our container port in the manifest file is we used to create the pod is 80
     targetPort: 80        

#############we can create a new file or add it to the existing manifest file we already have  by ,, (--- to seperate the files)

******************************************************************

kind: Pod   
apiVersion: v1    
metadata: 
   name: hello
   labels:
     app: hello     
spec:
   containers:
   - name: hello   
     image: mylandmarktech/hello  
     ports: 
---
kind: Service               *** this down part is for the service
apiVersion: v1  
metadata:
  name: hellosvc    
spec:
   type: ClusterIP    
   selector:   
      app: hello     
   ports:                                                                              
   - port: 80           
     targetPort: 80        

**********************************************************************
ubuntu@master:~$ kubectl apply -f manifest/
pod/hello unchanged
service/hellosvc created
ubuntu@master:~$ kubectl get all 
we see both opd n service 
ubuntu@master:~$  kubectl get events        38:00
with the help of the container runtime, w esee it created n started the container 

We can check the service 
   Kubectl  get svc 
NAME                TYPE               CLUSTER-IP                EXTERNAL-IP       PORTS      AGE         
Hellosvc           ClusterIP           10.105.209.246              none              80/TCP      97s
          
To get the end point 
Kubectl get ep
NAME                    ENDPOINTS                  AGE
Hellosvc                  10.36.0.1.:80             105s           .... it has just one end point  43:40

Kubectl  get svc –o wide
NAME                TYPE               CLUSTER-IP                EXTERNAL-IP       PORTS      AGE         SELECTOR
Hellosvc           ClusterIP           10.105.209.246              none              80/TCP      116s         app=hello


 (which is the service ip)
Curl  cluster-ip   10.105.209.246        ,, and we successfully communicated with the app usin d service ip address
When I wnt to curl, we curl on port 80 cos if my service port was smt else then I v to write the port number but since it is 80 , I can curl without it

So my hellosvc is a clusterip service & it has a service ip address, so when the webapp is trying to comm wit it(hello) its going to use this service n the
webapp talks to the service on the service port, port80 and the service is routing the traffic to the appl on the appl port number , d container port number
wich is also port80 in this case

Other commands regarding service

kubectl get svc -n <namespace>       (svc is service)
kubectl get svc -n dev  


kubectl get svc -n dev  
kubectl describe svc  
kubectl get ep      ... we can get the end point.. one/ A single service can route traffic/LB to multiple replicas of an appl  43:20
kubectl describe svc     gives more info abt the service
kubectl delete svc

ubuntu@master:~$  kubectl describe svc hellosvc
Name:             hellosvc
Nmaespace;         dev
Labels;            none
selector          app=hello
IP                 10.1 05.209.246
IPS:               10.105.209.246
Endpoints:          10.26.0.1:80

ubuntu@master:~$  curl  10.26.0.1:80   --------> 10.36.0.1:80 
when we curl on port 80, the service route the traffic to the container IP address  ie we curl to acces the container on that iP address





                     #########################  FQDN

*******************************
What is FQDN?               ..........          45:21   in kubernetes by default we create containers in the same namespace to enable them comm wit each oda, however, 
FQDN = Fully Qualified Domain name.                                                     if pods ar nt in the same namespace we have to use the FQDN
If one POD need to access service & which are in different names space 
we have to use the FQDN of the service.
******************Syntax: <serivceName>.<namespace>.svc.cluster.local
                 ex: myappsvc.dev.svc.cluster.local

 ubuntu@master:~$    curl hellosvc.dev.svc.cluster.local 
curl: (6) could not resove host: hellosvc.dev.svc.cluster.local                                                                47:30
*****this is bc this is nt hw am suppose to run this command, am suppose to run it in a diff appli bc that is going to be within the clutser,, if we v more 
than one container or more than one pod running we can execute this command in one other pod so that we ar able to access the appl that runs in a completely
diff Namespace.

serviceNAME  = hellosvc   
service FQDN = hellosvc.dev.svc.cluster.local    

    
                                                    APPLYING FQDN TO EST COMMUNICATION

let me jst use a command to create a new pod   in the default namespace  & one in the dev namespace
 1)kubectl run web --image=mylandmarktech/java-web-app --port=8080 -n default  
 2) kubectl run web --image=mylandmarktech/java-web-app --port=8080 -n dev

ubuntu@master:~$ kubectl get po                                  *** these are pods in the dev namespace
NAME            READY       STATUS      RESTARTS       AGE
hello            1/1         Running      0              4s           
web               1/1        running     0               10s       .... we see web running

ubuntu@master:~$  kubectl get po -0 wide -n default                 *** this is the pod  we created in the default namespace
NAME            READY      STATUS      RESTARTS      AGE     IP            NODE      NOMINATED NODE
web                1/1      running      0            48s    10.44.0.1      node1

ubuntu@master:~$ kubectl get svc 
NAME                TYPE               CLUSTER-IP                EXTERNAL-IP       PORTS      AGE         
Hellosvc           ClusterIP           10.105.209.246              none              80/TCP    14m




                                USING THE 'EXEC -it' TO RUN FQDN                                                                           
 We want to est communictaion btw the 'hello container' in the dev namespace & the 'web container' created in the default namespace using the 
hello service :helloSVC ..... we created it above earlier...
                                                                                                                                          
********i cud a command in this pod  just like docker,  kubectl exec web,  or interactive  (kubectl exec -it web) its the same in k8
ubuntu@master:~$   kubectl exec -it web -n default bash         .....  now, i v a pod, the name of my container is web, in default namespace
kubectl exec [POD] {COMMAND] is DEPRECIATED and will be removed in a future version.
root@web:/usr/local/tomcat#                *************now we are inside the web container and it is running in the default name space 
     #### i want to comm with my hello container using the FQDN

root@web:/usr/local/tomcat#  curl hellosvc.dev.svc.cluster.local        52:47   
we successfully commu with the container (they are in 2diff name space)


                                               CANT USE THE SERVICE TO COMM BTW PODS IN DIFF NS 
             1) errror... the 'web pod' in the default namespace TRYING TO use the service name to COMM with the 'hello container in the dev namespace  
root@web:/usr/local/tomcat#  curl hellosvc
curl: (6) could not resolve host: hellosvc    ,,,  wheni use just the service name am unable bc they ar in diff namespaces, so u hv to use the FQDN when d 
containers ar running in  diff namespaces.
            

                       USING SERVICE NAME TO COMM WITH PODS INSIDE THE SAME NS
       2)successful:  the 'web pod' in the dev namespace TRYING TO use the service name to COMM with the 'hello container in the dev namespace  
container
root@web:/usr/local/tomcat#  exit              54:10  ####remember earlier we config our default namespace to be dev n now we didnt indicate default so its 
in dev lik hello
ubuntu@master:~$  kubectl exec -it web bash          **this is the 2nd web container we created in the dev namespace n using just the service name am able to comm
root@web:/usr/local/tomcat# curl hellosvc        ****now am accessing a container that are in the same namespace .. in the same namespace wit just d service name it wil work n 
successfully communicated                                                                 also with the FQDN it wil also work ..

*******so am inside the webapp pod , i wnat to acces the helloapp, am doing that through the hello service


                                  DISADVANTAGES OF POD
54:45
root@web:/usr/local/tomcat#  exit
ubuntu@master:~$ kubectl get po                           ***containers in the dev namespace
NAME            READY       STATUS      RESTARTS       AGE
hello            1/1         Running      0             32m
web               1/1        running     0               5m30s

ubuntu@master:~$ kubectl delete po web
pod web deleted 

ubuntu@master:~$ kubectl get po                         ***we dnt see the 'web container' again bc it wasnt recreated
NAME            READY       STATUS      RESTARTS       AGE
hello            1/1         Running      0             32m

                   
********We deleted the 'web container' but it wasnt recreated bc when u use pod to deploy k8 objects, pods cannot be recreated and it cannot be scaled
e.g we cannot decide to have more replicas of hello if we ar going to be using pod
in k8, the pod lifecycle is very short so if we ar going to deploy appl, we shud nt use pod    .....
(we shud use controllers like Replica Sets, Deployment, Deamon sets to keep pod alive)

**Mee*** therefore in the manifest file, kind will be 'rc' & we will also hv a template for pod inside the same manifest file & if we need to create service, 
we wil also have a template/section for service

56:20 ##################  READ UP POWERPOINT   ***WE should USE CONTROLLERS





************************************* STATIC PODS***************

IQ: what is Static Pods ?
    Static Pods are controlled by the kubelet service  
1.2.50 ..If we delete a static pod, So long as the manifest file still exists, it will continue to recreate the pod, the kublete service wil restart the pod
To permanently delete a static pod you must have to delete the manifest file used to create the static pod



                                USING MANIFEST FILE TO CREATE STATIC POD
creating static pod
sudo vi /etc/kubernetes/manifests/file.yml            ************we ar creating it in this dir

kind: Pod    
apiVersion: v1   
metadata: 
   name: myapp 
   namespace: dev     .. we wnt to create a pod in the dev namespace
spec:   
   containers:
      - name: myapp   
        image: mylandmarktech/java-web-app   
        ports:
        - containerPort: 8080   

ubuntu@master:~$ sudo vi /etc/kubernetes/manifests/file.yml      ***1.00.00
then paste the file  ... Once we paste & exit the file, it automatically starts to create the pod
ubuntu@master:~$ kubectl get po
NAME            READY       STATUS      RESTARTS       AGE
hello            1/1         Running      0             37m
myapp-master      1/1        running     0              21s      ..... the file was created and we didnt need to run kubectl apply -f /etc/kubernetes/manifests/file.yml 
 so the static pod is running                                                                       we are going to get permisson denied

ubuntu@master:~$ kubectl get po
NAME            READY       STATUS      RESTARTS       AGE
hello            1/1         Running      0             37m
myapp-master      1/1        running     0              21s  
my app              1/1       running     0             64s        ***** immediately the file was created,we realise that a static pod was created.

ubuntu@master:~$  kubectl describe po myapp
ubuntu@master:~$ kubectl delete po --all
pod hello deleted
pod myapp deleted
pod myapp-master deleted    ************ all pods deleted 

ubuntu@master:~$ kubectl get po
NAME            READY       STATUS      RESTARTS       AGE                the pod was recreated
myapp-master     1/1         Running      0             8s     ...  this pod is still running bc it is a static pod wich is controlled by the kuberlete service 
                                                                  so long as the manifest file exists, it wil be restarted

************to delete a static pod , we v to delete the manifest file..   .... I BLIV HE DELEted the manifest file




 ######################CONTROLLERS****************************************1:05:00
---
NB:
We should not create pods directly to deploy applications.
If a node  goes down in which pods are running, Pods will not be rescheduled.
We have to create pods using controllers which manages the POD life cycle.

**Mee*** therefore in the manifest file, kind will be 'rc' & we will also hv a template for pod inside the same manifest file & if we need to create service, 
we wil also have a template/section for service



                     CONTROLLER MANAGERS
controllerManagers:
  ReplicationControllers 
  ReplicaSets, 
  Deployments, 
  DaemonSets  

                                              WORKLOADS
A workload is an application running on Kubernetes consisting of a single 
component or several components that work together inside a set of pods. 
In Kubernetes, a Pod represents a set of running containers on your cluster.


                                   k8 POD LIFE CYCLE
Kubernetes pods have a defined lifecycle. 
For example, once a pod is running in your 
cluster and the node hosting the pod fails then pods running on the node
will fail. Kubernetes treats that level of failure as final. 
You would need to create a new Pod to recover,even if the node later becomes healthy.
****Therfore we nid to use controller mangers such that if this  node goes down a controler manger will ensure that this pod is rescheduled on another node 



1:07:00   ################ USING MANIFEST FILE TO CREATE A REPLICATION controller, that wil be recreating a particular pod (webapp)
                        includes manifest/template for ReplicaControllers, template for Pod, & template for service (Nodeport)

ReplicationControllers = rc 
=========================== kams 
kind: ReplicationController      ......keypair      ***mee** our kind is now 'replica controller' NOT Pod
apiVersion: v1   
metadata:    ..... dictionary
   name: apprc          ..app replication controller,it wil control d state of my pod,for it to select d pod, for selector,app is mapped to web, so the RC wil
   namespace: dev                                            be selectin any pod dat has the label app=web n it wil ensure 3replicas are running  ...1:14:53
   labels:
      app: apprc          ..... this is my replication controller label
spec:
   selector:
      app: web     1.13.40  ** i bliv web is the label & the app is the container name, for service to discover the pod, we need the 'key value pair' app:web
   replicas: 3    
   template:     #podTemplate   ... this is my pod template
      metadata: 
         name: webapp       ...... my pod here is webapp          1;10;56
         labels: 
           app: web    
      spec:
         containers:
         - name: app  
           image: mylandmarktech/java-web-app       ......  .... THIS IMAGE is on a tomcat base image  n the container port is 8080 
           ports:                             this replication controller we ar creating called apprc, its meant to mange this pod info here ie the pod template ..
           - containerPort: 8080           & it will be selecting any pod that has the label app:web & it wil ensure that 3replicas are running


---                                NODEPORT SERVICE MANIFEST FILE
kind: Service      ###### AS part of this deployment, we wnt to create a service as well           
apiVersion: v1  
metadata:
  name: webappsvc       **********name of service 
spec:
   type: NodePort         *********this app nids to be accessed externally so we change this from ClusterIP to NodePort  ... . ..1:17:25
   selector: 
      app: web             ********this is also based on the pod template
   ports:
   - port: 80  
     targetPort: 8080               >>************target port is the same as container port
     nodePort: 31000 #30000-32676            *****since we hv node port, i can also decide the node pod to us so 31000 .... nodport range frm 30000 - 32676
                                                    if i dnt choose a pod n #nodePort:, the system wil dynamically assign a port n it will be with the port range



vi manifests/app.yml   and paste file 
kubectl apply -f manifest/app.yml     .......deploy application
successful

ubuntu@master:~$ kubectl get all
NAME                 READY       STATUS      RESTARTS       AGE
pod/apprc-kgh2g        1/1         Running      0             20m
pod/apprc-tmlz8        1/1        running      0              20s  
pod/apprc- zncll          1/1       running     0             20s       

#############AL the pods are running ,, 3pods are running bc in the manifest file we defined 3replicas

ubuntu@master:~$  kubectl get rc 
NAME        DESIRED    CURRENT      READY        AGE 
apprc        3            3           3          80s

ubuntu@master:~$  kubectl describe rc apprc       ..... to see more info
ubuntu@master:~$    kubectl get events
ubuntu@master:~$   kubeectle get svc -0 wide 
NAME            TYPE           CLUSTERIP            EXTERNAL     PORTS        AGE          
hellosvc       clusterip       10.105.209.246         none         80/TCP
webappsvc       Nodeport         10.99.250.229        none        80:31000/TCP
                            this is the service ip

ubuntu@master:~$ kubectl get ep
NAME             ENDPOINTS
hellosvc            none               **** the hello pod is nt running bc we deleted the pods so this service doesnt v any endpoint
webappsvc          10.36.0.1:8080, 10.36.2:8080, 10.44.0.2:8080      *********** webappsc has 3endpoints , we hv 3ports here if i wnt to comm wit them it has to be done
                                                                       via the sservice
ubuntu@master:~$ kubectl get all
NAME                 READY       STATUS      RESTARTS       AGE
pod/apprc-kgh2g        1/1         Running      0             3m9s
pod/apprc-tmlz8        1/1        running      0              3m9s  
pod/apprc- zncll          1/1       running     0             3m9s       

ubuntu@master:~$  curl 10.99.250.229  (this is the serviceip)
successful

1.39.00
                 **check 'GOT my dream file' for beta understanding**** KUBEPROXY/ENDPOINTS/NODEPORT       ** this is service discovery to take note of
&************* we hv 3ports here if i wnt to comm wit them it has to be done via the sservice  but we v a nod eport that has been created
with  the node port service called webappSVC
WE V 3REPLICAS E.G     webapp1 , webapp2, webapp3    ,, bt when der ar some many names der can be a problem,, but when it comes to our service that is 
routing traffic to all dis pods ,,, the target port is 8080 and we v a master node as part of the cluster and our service is nodeport and this menas it can
process external traffic e.g der ar 25million users trying to acces the appli , what happens is that each of this node has an IP address (a node IP address) he login to aws n got the ip adress
(we had deleted node5 earlier so now he deleted it in aws)                         (nodeport)
1:34:18  .. so the users are typing any of the node ip e.g masterIP = 3.128.206.139:31000 , now when traffic gets into this cluster , rmeber that in our 
clusters, we v kubeproxy running and as such, it will immediately identify that this traffic is meant for a particular service n so it wil be routed 
immediately to the service concerned frm the service, which  now has endpoints ie our pods/containers, so traffic gets to the endpoints

2.09.19                                  NODE PORT COMES WITH CLUSTERIP 
***********nternally, i created a nodeport service for python but that nodeport  service also has a cluster IP assigned to it, so if i wnat to access my 
python appl, i can curl, using the clusterip ,to  access the appl internally


in our cluster we have
masterIP = 3.128.206.139
NODE9-IP= 3.148.106.135
                                  *************this is service disCOVERY, WHICH IS A VERY KEY aspect to take note of 
3.148.106.135:31000  ... accessed online successful, momentarily, we can see d trafic routed as it switches btw d pod names: pod/apprc-kgh2g ,pod/apprc-tmlz8,pod/apprc- zncll 

ubuntu@master:~$ kubectl get all
NAME                 READY       STATUS      RESTARTS         AGE       IP           NODE         NOMINATED NODE       READINESS
pod/apprc-kgh2g        1/1         Running      0             15m      10.36.0.2      ndde9         none                none
pod/apprc-tmlz8        1/1        running      0              15m      10.36.0.1      node9          none
pod/apprc- zncll          1/1       running     0             15m      10.44.0.2       node1             none

1:39:44 ###################### # ##########READ UP
Kubernetes Objects
NodePort - Exposes the service on each Node's IP at a static port. A ClusterIP service, to which the NodePort service will route, is automatically created. 
You'll be ableito contact the NodePort service, from outside the cluster, by using
"<NodelP>:<NodePort›".


 ##########more COMMANDS FOR REPLICATOR CONTROLLERS
labels:    app: web   = address: gra  
selectors: app: web   = address: gra  
replicas = 3  

kubectl apply -f <filename.yml>
kubectl apply -f rc.yml
kubectl get rc 
kubectl get rc -o wide  
kubectl get rc -n <namespace>
kubectl get all
kubectl scale rc <rcName> --replicas <noOfReplicas>   ..     **************** ..... WE CAN ASLO SCALE the replication controller 

kubectl scale rc apprc --replicas 4     
kubectl describe rc <rcName>
kubectl delete rc <rcName>

###################   **********.................. EXAMPLE
ubuntu@master:~$ kubectl delete po --all
deleted    ************ all pods deleted 
pod/apprc-kgh2g        deleted
pod/apprc-tmlz8        deleted
pod/apprc- zncll       deleted

ubuntu@master:~$ kubectl get po
NAME                 READY       STATUS      RESTARTS       AGE
pod/apprc- 7jr9m      1/1         Running      0            12s
pod/apprc-ffv25       1/1        running      0             12s  
pod/apprc- hdd8r      1/1       running     0            12s    ............. all the pods have been rescheduled/recreated bc my pods are been manged by a 
                                         Rplication controller n the RC has a label app:web n the RC has a selector that has selected the label, once it is
                                          selected, the pod labels hv define dthat the replicas is 3, so at all times, the RC must maintain d desired state  
                                                         of my appli which is 3 


                          WE CAN SCALE WITH RC
SO IN deploying i shud nt deploy using a pod as an object  but rather controllers managers like RC

ubuntu@master: ~$
ubuntu@master:~$ kubectl scale rc apprc-- replicas 4
replicationcontroller/appre scaled
ubuntu@master: ~$
ubuntu@master: ~$ kubectl get po
NAME            READY       STATUS           RESTARTS           AGE
apprc -64d27     1/1      Running                               7s
apprc-7jr9m       1/1     Runn ing                              2m3s
apprc-ffv25       1/1      Running                              2m3s
appre-hdd8r       1/1      Running                               2m3s

ubuntu@master: ~$
ubuntu@master:~$ kubectl scale rc appre --replicas 0
replicationcontroller/apprc scaled
ubuntu@master:~$
ubuntu@master:~$
ubuntu@master: ~$
ubuntu@master:~$
ubuntu@master: ~$ kubectl get po
No resources found in dev namespace.
 ubuntu@master: ~$
ubuntu@master: ~$
ubuntu@master: ~$
ubuntu@master:~$ kubectl scale rc appre -- replicas 2
replicationcontroller/appre scaled
ubuntu@master: ~$
ubuntu@master: ~$ kubectl get po
NAME            READY       STATUS           RESTARTS           AGE
apprc -fsfsk     1/1        Running                                 4s
apprc-lzmdn      1/1       Runn ing                                4s


kubectl scale  pod app --replicas 4    = NO        ,, we cant scale pod ..................1:46:41
kubectl scale  rc apprc --replicas 1   = YES  
kubectl scale  rc apprc --replicas 4   = YES  
kubectl delete rc apprc


###################******************* we can scle depending on demand 
1 replicas running and serving 10m requests from users       ... ...****** if request incresases to 50m users we can then scale up to 5
5 replicas running and serving 50m requests from users   
spike 
     but we cant sacel in docker , thats why in our env, we use docker to:
  docker is use to containerise                    
  kubernetes is used to Orchestrate containers     .. .. .with k8, we can scale,, if a junior engr mistakenly delete our pods, k8 will automatically recreate them 

                        WE ONLY USE DOCKER TO
1:49:30**************** ..... there is no component in docker that is capable of recreating containers,, so we shudnt use a software taht is limited ,but
docker is nt completely useless, so we are studying docker bc we dnt need to use k8 to create docker files and build images, k8 does nt use docker files to
build n share images in image registry so we nid docker to be able to create a docker file,build images and share those images to docker registry so that 
k8 can pull the images to deploy application


1:51:22                                    HOW WE DEPLOY APPLICATION IN K8
########### hw we deploy applictaions in k8 , which isa very key aspect when it comes to my understnading of k8, 


                    WHERE APPLICATIONS ARE DEPLOYED IN K8
where are applications deployed in k8?/??......     we shud be able to est the fact that applictaions/containers are running in pods   
so pods can be deployed/managed by using:
     
      HOW POD IS MANGED
pods can be deployed/managed by using:
 1. pods as a kubernetes objects  
 2. controllerManagers kubernetes objects , thers a list of k8 objects when it comes to controller managers, we hv seen the first controller manager k8 objects
   *** now we want to talk about replica sets.. 


                                      REPLICA SET   **check 'GOT my dream file' for beta understanding***
ReplicaSet = RS :   ...  ****************HOW TO USE REPLICA SET TO deploy our application    ......1:53:50
==========
What is difference b/w replicaset and replication controller?
RS is the next generation of replication controllers 
The only difference as now is the selector support.

RC --> Supports ONLY equality based selectors. (**mee**We saw the use of labels)   ......equality based is equal conditions
key == value(Equal Condition)    
selector:
    app: javawebapp
    tier: fe    
    client: tesla  
###while
RS --> Supports eqaulity based selectors and set based selectors.  ,(set based is that we can hv keys in multiple volumes)
eqaulity based:
key == value(Equal Condition)     ****me**use of labels
set based:
  key in [ value1, value2, value3 ]   

      e.g for replication controller, as we have seen 
selector:
   matchLabels:   -# Equality Based    ***use of labels
    key: value
    app: javawebapp
    tier: fe    
    client: tesla
WHILE RS                                for set base we can have one key that is equal to multiple values or a set of values
   matchExpressions: -# Set Based  ,   under selectors: it can either be  matchlabels which is Equality conditions OR matchexpression which is set based where we can have
   - key: app              ********* we can hv key, operator, values , so 'app' alone can match to javawebapp,myapp and fe  ... .....1:56:50
     operator: in
     values:
     - javawebpp
     - myapp  
     - fe  
**************************************************************************************************************

 

rs.yml  = kams      ******************************** CREATING a rePLICA SET  .. this is the template
--------------
kind: ReplicaSet
apiVersion: apps/v1  
metadata : 
   name: rsName  
spec:                                      spec, can start with template bt for best practice we also hv it in this order...............1:58:12
   replicas: noOfReplicas  
   selector:                *********************   we can either hv equality based selector or set based selector
      matchLabels:
         <key>: <value>
         <app>: myapp
      matchExpressions:
      - key: <key>
        operator: <in / not in>
        values:
        - <value1>
        - <value2>
        - <value3>  
   template: #PODtemplate  
     metadata:
       name: podName
       labels:
         <key1>: <value1>
         <key2>: <value2>     
     spec:  
       containers: 
       - name: <containerName>
         image: <imageName:tag>
         ports:
         - containerPort: containerPortNumber  
          

                                          **DEPLOYING appl using RS
---                            WE wnat to DEploy rs.yml
rs.yml   
kind: ReplicaSet
apiVersion: apps/v1  
metadata:
  name: pythonapprs            ... we are deploying a python web applictaion
spec:
  replicas: 1       ... if we dnt pass any replica, its going to crreate 1replica
  selector:
    matchLabels:
      app: python    
  template: 
    metadata:
      name: webapp  
      labels:
        app: python  
    spec:
      containers:
      - name: web 
        image: mylandmarktech/python-flask-app:2       .. we are puling this frm docker hub
        ports:
        - containerPort: 5000        ... as seen in the file in docker hub
---
kind: Service          ********* we wnt to create a service that can access this appli externally
apiVersion: v1  
metadata:
  name: pythonsvc    
spec:
   type: NodePort  
   selector: 
      app: python       
   ports:
   - port: 80  
     targetPort: 5000   ...... shud be the smae as container port
     nodePort: 31100 #30000-32676  ......... we already used port 31000 earlier, so now we use can use a diff port like 31100

now ,,, vi rs.yml  and paste the file ..........  (its a yml file, manifest file are written in a language called yml)
kubectl apply -f rs.yml  
successful

ubuntu@master:~$  get all 
NAME                          READY       STATUS                RESTARTS           AGE
pod/apprc -986bl                  1/1        Running                  0               4s
pod/apprc-ffmtc                   1/1       Runn ing                  0            4s
pod/pythonapprs-94dfl            0/1      containerCreating           0

ubuntu@master:~$  kubectl get ep
NAME             ENDPOINTS                 AGE 
hellosvc          none                     112m
pythonsvc         10.36.0.2:5000            23s
webappsvc     10.36.0.1:8080,10.44.0.2:8080      69m

ubuntu@master:~$  kubectl get po -o  wide

ubuntu@master:~$  kubectl get svc -o wide
NAME                TYPE               CLUSTER-IP                EXTERNAL-IP       PORTS      AGE         
Hellosvc           ClusterIP           10.105.209.246              none              80/TCP    114m
python svc          nodeport             10.99.232.74               none
webappsvc           nodeport            10.99.250.229               none

2.09.19                                  NODE PORT COMES WITH CLUSTERIP 
***********nternally, i created a nodeport service for python but that nodeport  service also has a cluster IP assigned to it, so if i wnat to access my 
python appl, i can curl, using the clusterip ,to  access the appl internally

ubuntu@master:~$ curl 10.99.232.74
App Works!!! ubuntu@master:~$              .......2:10:06

i can also curl by using one of the IP addresses of my servers
in our cluster we have
masterIP = 3.128.206.139           ... i think we already deleted master  earlier2
NODE9-IP= 3.148.106.135

ubuntu@master:~$ curl 3.148.106.135:31100
App Works!!! ubuntu@master:~$   

also on the browser :3.148.106.135:31100
successful

***************appl successfully deployed using replica set 
*******************************


                                    PULL IMAGE FROM PRIVATE REPO, DIDNT BUILD, TAGGED IT & PUSHED IT
2:20:00 (he tried to pull an image from a private repository then he made the repo public so that we can access it) 
he then created a new private repo.. pull the nodejs image frm github, tag and pushed the same image to the new repo he created  
2:26:32  .......   my job with docker is to containerize


'###############ALL this is done in the docker server 
docker pull mylandmarktech/nodejs-app:2  ............           .2:24:00
docker tag mylandmarktech/nodejs-app:2 mylandmarktech/nodeapp
docker push mylandmarktech/nodeapp  


######################## IN the k8 server, we ar deploying in k8 , docker only help us containerize n share the images in image registry


                              DEPLOYING REPLICA SET WITH MANIFEST FILE  (with image pulled from private reg but it failed bc need secret key)

node-rs.yml            
==========                            deploying using replica set
kind: ReplicaSet
apiVersion: apps/v1  
metadata:
  name: node-rs    
spec:
  replicas: 1 
  selector:
    matchLabels:
      app: node       
  template: 
    metadata:
      name: nodeapp  
      labels:
        app: node    
    spec:
      imagePullSecrets:
      - name: dockerhublogin       *** we added this after we created the secret below
      containers:
      - name: nodeapp  
        image: mylandmarktech/nodeapp   
        ports:
        - containerPort: 9981  
---
kind: Service  
apiVersion: v1  
metadata:
  name: nodesvc    
spec:
   type: NodePort  
   selector: 
      app: node         
   ports:
   - port: 80  
     targetPort: 9981
     nodePort: 30500   #30000-32676    .... when u dnt assign a node port, one will be assigned to you
---
2:31:28
ubuntu@master:~$  vi node-rs.yml 
replicaset.apps/node-rs created
service/nodesvc created
buntu@master:~$
ubuntu@master:~$ get po
NAME                          READY       STATUS                RESTARTS           AGE
pod/apprc -986bl                  1/1        Running                  0             64m
pod/apprc-ffmtc                   1/1       Runn ing                  0             64m      #########error  pulling image
node-rs-cx9t2                     0/1        ErrImagepull             0             10s
pythonapprs-94dfl                 1/1        Running                  0
buntu@master:~$
buntu@master:~$  kubectl decribe po node-rs-cz9t2
##############we the pod is controlled by 'a ReplicaSet'....can see the pod is in pending state bc of the image pull error: failed to pull image; access denied, may reQ 
authorization and this is bc we ar tyring to pull the image froom a private image registry .. therefore we nid to create a secret for dockerhub



                               CREATE SECRET
Create a secret that will authenticate kubernetes to pull images from dockerHub/nexus/jfrog  
dockerHublogin
kubectl create secret docker-registry regcred     ...****************** docker-registry is the name of the secret which we call regcred 
 --docker-server=<your-registry-server>  docker.io
 --docker-username=<your-name>  mylandmarktech
 --docker-password=<your-pword>   admin123
 --docker-email=<your-email>     ********************************can enter email but without email it will work


*******i will run this in my k8  CLI server        ....................2:37:40

kubectl create secret docker-registry dockerhublogin \             **************      we called it dockerhublogin
    --docker-server=docker.io --docker-username=mylandmarktech \
    --docker-password=admin123  

ubuntu@master:~$ kubectl get secret
and now i can see the secret    .... now i can pull images
ubuntu@master:~$    kubectl describe secret dockerhublogin
i can also dercribe the secret


                                     APPLY THE SECRET TO THE MANIFEST FILE
*************** i will go back to my file above and under spec, i will add :imagepullsecrets; name:dockerhublogin

ubuntu@master:~$  vi node-rs.yml 
Kubectl apply -f node.yml
replicaset.apps/node-rs configured
service/nodesvc unchanged
buntu@master:~$
ubuntu@master:~$ get po
NAME                          READY       STATUS                RESTARTS           AGE
pod/apprc -986bl                  1/1        Running                  0             64m
pod/apprc-ffmtc                   1/1       Runn ing                  0             64m    
node-rs-cx9t2                     0/1        ErrImagepull             0             10s
pythonapprs-94dfl                 1/1        Running                  0
buntu@master:~$
buntu@master:~$  kubectl delete po node-rs-cz9t2
pod"node-rs-cz9t2" deleted
buntu@master:~$
buntu@master:~$  kubectl get po
NAME                          READY       STATUS                RESTARTS           AGE
pod/apprc -986bl                  1/1        Running                  0             73m
pod/apprc-ffmtc                   1/1       Runn ing                  0             73m    
node-rs-jtmrb                     0/1        containerCreating             0             8s          ..... the new container is being created n later we see its running
pythonapprs-94dfl                 1/1        Running                  0              33m

################################################sUCCESSFULLY deployed..........  2:41:15

ubuntu@master:~$  kubectl get svc -o wide
NAME                TYPE               CLUSTER-IP                EXTERNAL-IP       PORTS      AGE         
Hellosvc           ClusterIP           10.105.209.246              none              80/TCP    114m
python svc          nodeport             10.99.232.74               none
webappsvc           nodeport            10.99.250.229               none
nodesvc             Nodeport             10.99.250.229              none           80/TCP


ubuntu@master:~$  kubectl get ep
NAME             ENDPOINTS                 AGE 
hellosvc          none                     112m
pythonsvc         10.36.0.2:5000            23s
webappsvc     10.36.0.1:8080,10.44.0.2:8080      69m
nodesvc         10.44.0.3:9981                10m            ************* the nodesvc  routing traffic to this endpoint


2.44.10                       USE THE NODEPORT'S CLUSTERIP & API's
############if we ar trying to access the nodesvc, WE can use the its cluster ip paired with the restful APi's
we can check in github, he checked in the repo we pulled the image frm, we wnt to access our nodejs appl, the appl has
some resful API

 RESTFULAPIs:                     
   /landmarktechnologies
   /html
   /jsonData

 like in BOA ...  these are REstful apis
    boa.com/login   
   boa.com/transfers  
   boa.com/mortgages  


#############we run this in our CLI ,, we get a response ..... welcome to Landmark technologies
  curl 3.148.106.135:30500/landmarktechnologies   

    curl 3.148.106.135:30500/jsonData   
we run this online and successful


################################################################################################ this is probably for nxt class we didnt use this in this video   
apiVersion: v1                                                   
kind: Pod
metadata:
  name: private-reg
spec:
  containers:
  - name: private-reg-container
    image: <your-private-image>
  imagePullSecrets:
  - name: regcred
#########################################################################################

i
kubectl get rs 
kubectl get rs -n <namespace>
kubectl get rs -o wide  
kubectl get all
kubectl scale rs <rsName> --replicas <noOfReplicas>

kubectl describe rs <rsName>           ************** once we deleted, the replica set controller manger will recreate it bc it has a desired state of 1replica
kubectl delete rs <rsName>              ********** all the pod associated wit the controller will be deleted and not recreated bc the controller was deleted

kubectl scale rs nodeapp --replicas 3 
kubectl scale rs nodeapp --replicas 0


  landmarktechnologies

   http://34.219.16.213:31500/landmarktechnologies

    http://34.219.16.213:32000



                                      REPLICA SET TEMPLATE
deployment of applications using ReplicaSet in kubernetes:  .. replica set is a controller manger bc applications are running in a pod
                                 THIS IS A POD TEMPLATE, and the pod is controlled by the replica set
ReplicaSet:
   selector:
      matchLabels:
         app:  node                                    the replica set wil identify the application based on the label
   template:
      metadata:
         name: webapp                          the name of the pod
         labels:
            app: node                            the replica set wil identify the application based on the label
      spec:
         containers: 
         - name: webapp  
           image: mylandmarktech/hello  
           ports: 
           - containerPort: 80                we are tryin to deploy this container wich is running in a pod  n the name of the pod is webapp
---
spec:
   type: NodePort  
   selector:
      app: node   



############he said we will look at set based selectors as we progress with the course

DaemonSet:
==========
https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/



