
Okay.. So you're able to make a request as far as a resources is  concerned, based on what you are trying to realize. And that's a very key aspect.. That's a very key
aspect in k8, you know. And now we have seen that,  while deploying your pod, right? You can decide how much resources should be assigned to this pod. And if you do that, 
the scheduler  wil only , schedule, that port on, they node  that got sufficient resources to provide what the pod is requesting. So please take notice. Very important.It's
a very key aspect as far as k8 this is concerned. So this aspect is always considered. While Trying to deploy a pod.
 So when the scheduler is about to schedule a pod, hes is going to schedule that pod based on the node that got sufficient resources. That's what is being considered. You
see that. So you are node, should have sufficient resources before the pdt is being scheduled. And k8 must always check, you know, in terms of how much resources the node 
Got before it's able to schedule a port. On that note. So those are very key aspect in k8 to take note of. 

**************************************SCALING:
SCALING
 Now, let's assume we want to deploy an application. We have said one of the features of k8 is that if you deploy your application using a controller, we are able to scale.
Okay. So how do we scale scaling in k8? 
How do we scale?
 we have Manual scaling and automated Scaling
How do we scale manually in k8 If you deployin your application for you to scale manually, you can run the command:
kubectl scale deployment/rs/rc/sts
ie we can scale rs , deployment, rc, stateful set, ...... these ar the scalable objs in k8 and these scaling can be done maually
we can also scale automatically, in k8 using another object Callled HPA .

scaling in kubernetes:
   manual scaling:
      kubectl scale deployment/rs/rc/sts/ app --replicas 4      
   automated scaling:
      Horizontal Pod AutoScaling  - HPA  :
      ============================
POD AutoScaling --> Kuberenets POD AutoScaling Will make sure u have minimum number 
pod replicas available at any time & based on the observed CPU/Memory utilization
on pods, it can scale PODS automatically.
HPA Will Scale up/down pod replicas of Deployment/ReplicaSet/ReplicationController 
based on observerd CPU & Memory utilization base the target specified. 

What is difference b/w Kubernetes AutoScaling(POD AutoScaling) & AWS AutoScaling?
 when we did aws, we also saw how we can auto scale by creating auto scaling grp 
AutoScaling group in aws : so we can have min, desired , max 
     min     = 5          the max
     desired = 5      so these are the no. of servers that we epxect
     max     = 100              max, so it  cant create more than 100 ,,, so scalin policy hS a tARGET, THE target can b memory utilzation or cpu ultilization ...... 8:14

but then when shud it scal? .....  so we hv scaling policy
 scaling policies in aws : it can scale based on 
    memory utilization    ... we can say that if mem exceeds 70% add servers 
       mem > 70% add servers      
    cpu utilization   
       cpu > 70% add servers 

  ScalingPolicy:
     memory utilization
       cpu -gt 80% 
       cpu -lt 40%     
     cpu utilization
difference b/w Kubernetes AutoScaling(POD AutoScaling) 
                   & AWS AutoScaling?
8:50 
for us to be able to understand hw mch resources are been consumed, we nid to check hw much resources the pods are already consuming, similarly, we can do this in k8
we cus decide we wnt to scale our pod..

resources:
   requests:     under resources, a pod is able to reqest for this much 
     memory: "128Mi"   
     cpu: "500m" 
deployment:     lets assume this req is created undera controler manger wich is deployment an dthe deployment has replica as 5
   replicas: 5    if my replica is 5, hw much resources is each of d replica suppose to consume? for memoery 128mi and cpu:500m, thi sis hw much resources a pod can consume
hpa:                 ************* we deploy an hpa and we say min number of pod 5
   min: 5 + 1 =    and say min number of pod is 5      (so we hv a deployment we are deployin and an HPA) 
   max: 50           and max is 50 pod 
kubectl top pods  
kubectl top nodes  

error: Metrics API not available
    kubernetes addons/plugins:
      Metrics Server

Configure a Metrics Server on our Cluster4??
===========================================
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml


wget https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml


https://github.com/LandmakTechnology/metric-server
git clone https://github.com/LandmakTechnology/metric-server
kubectl apply -f metric-server/metrics-server-deploy.yml
=====================================================

ubuntu@master:
~$ kubectl apply -f metric-server/metrics-server-deploy.yml
serviceaccount/metrics-server unchanged
clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader unchanged
clusterrole.rbac.authorization.k8s.io/system:metrics-server unchanged
rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader unchanged
clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator unchanged
clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server unchanged
service/metrics-server unchanged
deployment.apps/metrics-server configured
apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io unchanged

metrics-server:
  nodes  
  pods 

RBAC objects:
  serviceaccount metrics-server 
     - user  
     - groups 
     - pods     
  clusterrole
     - pods/nodes [get/watch/list] 
  clusterrolebinding
     - 
  rolebinding
Deployment with HPA
==================
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hpadeployment
spec:
  replicas: 2
  selector:
    matchLabels:
      name: hpapod
  template:
    metadata:
      labels:
        name: hpapod
    spec:
      containers:
        - name: hpacontainer
          image: k8s.gcr.io/hpa-example
          ports:
          - name: http
            containerPort: 80
          resources:
            requests:
              cpu: "100m"
              memory: "64Mi"
            limits:
              cpu: "100m"
              memory: "256Mi"

---
apiVersion: autoscaling/v2 
kind: HorizontalPodAutoscaler  
metadata:
  name: autoapp        
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment 
    name: hpaapp  
  minReplicas: 2
  maxReplicas: 5
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 40
  - type: Resource
    resource:
     name: memory
     target:
      type: Utilization
      averageUtilization: 40
---
apiVersion: v1
kind: Service
metadata:
  name: hpaclusterservice
  labels:
    name: hpaservice
spec:
  ports:
    - port: 80
      targetPort: 80
  selector:
    name: hpapod
  type: ClusterIP

-# Create temp POD using below command interatively and increase the 
-# load on demo app by accessing the service.

kubectl run -i --tty load-generator --rm  --image=busybox /bin/sh

-# Access the service to increase the load.

while true; do wget -q -O- http://hpaclusterservice; done  

Vertical Pod AutoScaling : 
Horizontal Pod AutoScaling  :
Cluster AutoScaling:


kubernetes = 15 hours   :
   kops / helm  /    
   stateless and stateful applications   
   volumes  
   configMaps and Secrets 
   EFK  / 
   Prometheus and Grafana  
   AMAZON EKS   
   Kubernetes Security     


Date  Local time  Change

Nov 05, 2023   2:00 am  -1 hour to standard time
Days: Mondays/Tuesdays/Saturdays  
Times: 7pm - 11pm EST Toronto/NewYork  Time     
Nigeria/Cameroon: 1am - 5am   
UK: 12am - 4am   




