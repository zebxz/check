RECAP , PROVISIONERS AND BACKENDSRECAP,
PROVISIONERS, TYPES OF PROVISIONERS, LETS SEE HOW REMOTE EXEC WORKS, CREATING AN EC2 INSTANCE, subnet, REFACTORING, PASSING A PROVIDER 
 create a subnet/subnets inside of the vpc , ACCESSINg ATTRIBUTE IN A MODULE, IMPLICIT DEpendency, LOCAL BACKEND, .TerrAFRM DIR, terfrm state file, READING FRM A STATEFILE,
REMOTE STATE DATA SOURCE ,Elastic ip, NULL RESOURCE, INLINE command and explanation of the scripts been transferred into the instance , AWS_key_pair, TERRAFORM CONSOLE
USING LOOP , USING FUNCTION, SLICE FUNCTION  ,, COMPLETE VPC TO CREATE 

   **** in the main.tf file (resource block for instance) we referenced the key variable to pass the key BUT in the null resource, we used a file to pass sthe key 

diff btw output and datasource
https://stackoverflow.com/questions/75246774/difference-between-data-source-and-output-block-in-terraform


what is meta data ??

tefrm gives you what are called mata arguments
these are arguments that alter the normal behaviur of our resources 
by default resources that we create in trfrm has a certain convention/behaior
the normal convention is that if i declare 1resource block , itwil cratea 1 resource bt if i want to reuse d same code to create multiple resources of d same tin then i can
pass in an arguemt thta wil manipulate the behavior ... that is what is a mata argument 

WHILE , 
an ARGUMENT, acts as an input, if u  wnt to input inf into a resource ,u can pass an argument so that it becomes part of the input into your resource
so we put in arguments 

BUT, 
ATTRIBUTES , is what we need to get out of our resource

A MODULE:
we say that you can create a module and a module is just resources (terfrm resources) that you can put inside a dir, now that becomes a module and we can ( call that) can
create 
those rsources just by using the module block
so this is one of the trfrm blks among the 10 tfrrm blks that we hv used so far
so u can use a module blk to actually create resources

Tonight we wil continue wit our exploration of teRRAFORM

we'll go over PROVISIONERS AND BACKENDS

PROVISIONERS:
You can use provisioners to model specific actions on the local machine or on a remote machine  
in order to prepare servers or other infrastructure objects for service

9:15
illustration:
i have my laptop here , and i want to craete an ec2 instance, in my aws account, i can use trfrm in my laptop to provision the ec2 instance in aws
i can have a resource blk, run trefrm init, terfrm apply , it wil create the ec2 instance
***************** but what if, lets say i have a file in (laptop) my local env and i want it transferred into my ec2 instance once that instance has been created and launchd
and bootstrapped.
this now becosmes a process of configuration, am tryin to config this ec2 instance by transfering a file into it , or i want to run a script once the instance has created

********11:20
one way we saw we can run a script is by using user data, we can use user data to run a script, that is a porcess of configuraton, this is hw i can configure my instance
usingtfrm by using user data
but what if i have a script on my local env that am nt passing as user data bt i wnat such that after my instance has created i want to transfer the script into my instance
then once this script has been transferred run this script on the instance
so trfrm gives you what is called provisioners, u can use provisioners to do that
so i have used this process of provisioners to craete my instance bt then am using what we call a provisioner to do what we call configuration

############ when u look at the documentaion, trfrm gives a strong warning that *************** PROVISIONERS ARE OUR LAST RESORT****************
WHEN ur using provioners, it is recommended that only use them when neccesssary jst bc of the nature of hw provisioners wrk
onof the things u wil realise as u work with provisioners is that if a provisioner fails e.g  if d script ur trying to install fails then the provisioner wil b deleted
and when this happens , if the provisiner was working on a resource like an ec2 instance , the instance will be deleted and recreated
thats why we hv to use provisioners as last resort.

TYPES OF PROVISIONERS

1) file provisioner
The file provisioner copies files or directories from the machine running Terraform to the newly created resource. The file provisioner supports both ssh and winrm
type connections.

that is :if i have a file on my local env, i can use a file provisoner that will copy the file and tk it to the destination which is the remote machine (the machine that is
been provioned)

2) LOCAL-EXEC PROVISIONER
he local-exec provisioner invokes a local executable after a resource is created. This invokes a process on the machine running Terraform, not on the resource. See the
remote-execprovisioner to run commands on the resource.

Note that even though the resource will be fully created when the provisioner is run, there is no guarantee that it will be in an operable state - for example system 
services such as sshd may not be started yet on compute resources.

THAT IS:
A local exec basically runs on your local env ,i can run a command on my local env after my remote instance has been craeted
and we will see exactly what i mean once we use it 

3)  REMOTE- EXEC
The remote-exec provisioner invokes a script on a remote resource after it is created. This can be used to run a configuration management tool, bootstrap into a cluster, 
etc.
To invoke a local process, see the local-exec provisioner instead. The remote-exec provisioner requires a connection and
supports both ssh and winrm.

THAT IS:
it perfroms a task on your remote resource, if am creatin an ec2 instance , i can use a remote exec, i can run commands on the remote instance ie the instance hv jst created
if i use a remote exec provisioner but for me to be able to run command inside of the instanc e(the remote instance), iil need to connect to it 
hw do i connect to an instance , il use ssh , iil need to ssh into that particular instance for me to be able to conect to the instance after wich am then able to run either
my script or command after the connection.

resource "aws_instance" "web" {
  # ...

  # Establishes connection to be used by all
  # generic remote provisioners (i.e. file/remote-exec)
  connection {
    type     = "ssh"
    user     = "root"
    password = var.root_password
    host     = self.public_ip
  }

  provisioner "remote-exec" {
    inline = [
      "puppet apply",
      "consul join ${aws_instance.web.private_ip}",
    ]



^^^^^^^^^^^^^^^ 16;00

  LETS SEE HOW REMOTE EXEC WORKS
we have this provisioners file 

    
                  ************   WE WANT TO CREATE OUR EC2 INSTANCE 

this ec2 instance we will use a data source
we hv dis data source which is creating an ubuntu server sowe wil use this data source to get our AMI 

1) this wil gnerate an AMI for ubnutu


          data.tf file

data "aws_ami" "ubuntu" {
  most_recent = true
  owners    = { 09879009}

filter {
   name    = "aws"
   values  = 
}
 filter {
   name = 

2)      ***********  once we get AMI, we are goin to use it in our  (instance) resource block

                     main.tf

resource "aws_instance" "my_ekl_instance" {
ami           = data.aws_ami.amzlinux2.id                             *** am reading my instance type frm  a variabale
instance type = var.myInstance                          **i can use what we call camal casing (he changed d i in instance to I and he changed it in the var file too)
subnet_id        =data.taerraform_remote_state.                ********* am passin a subnet id bt d subnet is , i dnt hv d subnet yet
key_name         =                                         19:15  so lets try n create d vpc first, so bc am in dis provisoner lets create anoda dir here n create a 
                                                                                                      module for my vpc
 


3)      ##########variable.tf file     (variable for the instance)

varaiable "region" {
  type      = list(string)
  default   = ["us-west1", "us-west-2", "us-east-1"]
}
varaiable "myInstance" {
    type = list(string)
    default = ["t2.micro", "t2.medium"]
}
varaiable "my_key" {
    type     = list(string)
    default  =  "eks-instance"
}
varaiable "my_path" {
    description   = "private key path"
    default  =  "mykey/elk-instance.pem"
}
varaiable "instance_user" {
    default  =  "ubuntu"
}




19:15
 ********* AS see above, am passin a subnet id bt d subnet is ,i dnt hv d subnet yet so lets try n create d vpc first, so bc am in dis provisoner lets create anoda dir here
n create a module for my vpc, i  now hv a dir here called vpc
now ill go to the trfrm registry ND TYPES aws_vpc as a resource 
he copied the basic usage :
    
resource "aws_vpc" "main" {
   cidr_block = "10.0.0.0/16"

in the vpc dir, he created a new file (vpc.tf)
and pasted it
so this will craete my vpc
so on this vpc he added some tags


4)     ********* vpc.tf file

resource "aws_vpc" "main" {
   cidr_block = "10.0.0.0/16"

tags = {
   Name = " Demo-vpc"}

                                  REFACTORING/creating variables
5)                    ******** then let , REFACTOR this code, ie i can pass this as variables 


vpc.tf file

resource "aws_vpc" "main" {
   cidr_block = "10.0.0.0/16"       
 

tags = {
   Name = " Demo-vpc"}
 }
}

varaiable "cidr" {
    type  =  "string"
Default   = "10.0.0.0/16"
}

varaiable "tags" {
    type  =  "string"
Default   = "Demo-vpc"
}

5a)    *********** referencing the variable cidr and vpc tag   ( he usually just goes back to NO.4 and refernce it by doing the changes e.g "10.0.0.0/16" to "var.cidr"

 resource "aws_vpc" "main" {
   cidr_block = "var.cidr"       *********** so we are referencing the CIDR variable above

 tags = {
   Name = " var.tags"}          ****************** referencing the vpc tag above


  6)                                                   PASSING MY PROVIDER 
  23:08  ************* so have declared 2 varaiables...... 

after have done this, for this particular vpc  i need to pass a provider 
i NEED  to PASS MY PROVIDER block , am using AWS 

provider "aws" {
   region = "us-west-1"      ********so this is where am creating my vpc 


************* so now inside of the vpc dir, i can create anoda file and call it varaiables.tf
so ill remove the variables from the vpc file and paste them inside its own file (the varaiables.tf file) .....********** the is the process called REFACTORING******** 
SO THAT it is easy to read , 
am making sure i only have resources in one file
providers in one file, so now ill create a file for providers ........................     25.03

7)      variables.tf file 

varaiable "cidr" {
    type  =  "string"
Default   = "10.0.0.0/16"
}

varaiable "tags" {
    type  =  "string"
Default   = "Demo-vpc"
}


8)      remove the provider from my vpc and put it on its file
  provider.tf

provider "aws" {
   region = "us-west-1"


******************** so bc i have declared my provider and variables and vpc on their own file , so this in itself and bc its inside of the vpc dir 
so i can call this as my vpc module bc everything in this vpc dir has to do with jsut the vpc only
so i can go ahead and create the vpc first
bt before i create the vpc, i realise that in my code (resourec block) to create my instance
i need a certain subnet
bt ill wnat to get the subnet frm this vpc that am craeting 
now since this vpc is a module on its on, for u to get something out of a module you must create an output, 
there must be an output for you to access the attribute of the module
right now we are creating this vpc but we do not hv any output, so ders no way of accessing the attributes of the vpc

9)   so for us to be able to access the attributes we will need to craete an output 


vpc.tf file

resource "aws_vpc" "main" {
   cidr_block = "var.cidr"

tags = {
   Name = " var.tag"}
 }
}
     NO.9
output "vpc_id" {                                   ************so this output will return the vpc id 
  value = "aws_vpc.main.id                              so am using an output to access the attribute of that value (an attribute of the vpc)
                                                         so i have to declare this particular output

28:25    ********** havin created that particular output, i probably want to create a subnet/subnets inside of this particular vpc 


10)       HOW TO CREATE A SUBNET 
in the registry he copied the resource block and pasted in the vpc file 

resource "aws_vpc" "main" {
   cidr_block = "var.cidr"

tags = {
   Name = " var.tag"}
 }
}

output "vpc_id" {                                 
  value = "aws_vpc.main.id 

}    NO.10
resource "aws_subnet" "main" {             ****** am creating a reosurce called a subnet,i wnat to craete the subnet inside this vpc,  so ill nid to pass this vpc id
    vpc_id   = aws_vpc.main.id                       (aws_vpc.main.id) this will return the id of the vpc,  so i need a vpc id where the subnet will be created
    cidr_block = "10.0.1.0/24"             ********as we looked at d varaiable, my vpc cidr 10.0.0.0/16, so my subnet cidr has to b a subset of that, so we can leave it at 
                                                                                          this 
                              
tag = { 
  Name = "Demo - subnet"
 }
}

11) ***********    again i can pass this as varaiables 
   now i can create 2variables (this is again refactoring)

varaiable "sub_cidr" {
    type      =  "string"
    Default   = "10.0.1.0/24"


************* variable for the subnet tag
     varaiable "sub_tag" {
    type      =  "string"
    Default   = "Demo-subnet"

 11a)    ************************    31:44
    Referencing the variable for the sub_cidr  and subnet tag  ( he usually just goes back to NO.10 and refernce it by doing the changes e.g "10.0.1.0/24" to "var.sub_cidr"
    
resource "aws_subnet" "main" {             
    vpc_id   = aws_vpc.main.id                       
    cidr_block = "var.sub_cidr"         ******************referencing the variable sub_cidr

tag = { 
  Name = "sub_tag"         ******************referencing the variable sub_tag

       so we have refactored our code 
    

     33:05  *********** 
now he also removed the variables for the subnets from the vpc file and paste them in the variables file 
so all the variableS are in one file 

also, for the output, he created a file , output.tf and pasted the output block

         
N0.12)      ****************************
     I ALSO NEED to create and output for my subnet, i need the subnet id bc when am creating this instance the argument that is passed is subnet id  so i need the id 
how do i get the subnet id 
  if i go to my vpc file, this is my subnet :aws_subnet" "main"

     output "subnet_id" {                                 
         value = "aws_subnet.main.id            ************ i want to get the id of this subnet after it has been created
   

NO.12a    ******************  now ill remove the output for the subnet id and paste it inside the output file 
  so ill get my output for my vpc and my output for my subnet

# VPC
    output "vpc_id" {                                 
         value = "aws_vpc.main.id 

  # Subnet
    output "subnet_id" {                                 
         value = "aws_subnet.main.id 

    
36:32   ************** so hv created this 2output for this 2resources
      with this am able to access these 2 output , bc ill need this subnet id to use it when am creating my resource


13) NOW THIS IS HOW OUR VPC FILE LOOKS LIKE

   resource "aws_vpc" "main" {
   cidr_block = "var.cidr"

tags = {
   Name = " var.tag"}
 }

}    
resource "aws_subnet" "main" {             
    vpc_id   = aws_vpc.main.id                       
    cidr_block = "var.sub_cidr"         

tag = { 
  Name = "sub_tag"
tag = { 
  Name = "Demo - subnet"


NO.14
 36:32   ********************      IMPLICIT DEPENDENCY 

      now let me go to my vpc and create this vpc first
by looking at the output which resource do you think will be taking first ?
 
38:41 
ANS: this is what we talked abt implicit dependencies 
so trefrm is able to look at your resources and determine which resources should be created first bc of implicit dependencies
but if we wnat to make it dependence explicit,  we use depends on
if  we ant to make our explicit dependency,  then we can pass a depends on meta argument here
we will say that the subset depends on the vpc and  bc we v explicitly declared that, it just means the vpc wil have to be created first  bc the subnet depends on it

  ******** but bc of how the subnet requires a vpc id, so this inherently is implicit dependency
                        so this is an example of implicit dependency in terrafrm 

so just understand the difference

   ALL THESE ARE INTERVIEW QUESTIONS
WHAT IS IMPLICIT dependency... ?
what is explicit dependency   ?
how does trfrm achieve implicit dependency  ... ?    it is just by how resources depends on each other 
how does trfrm achieve explicit dependency   ..... ?    you have to pass a dependency 


      *********** now that we have this, we can go ahead and create our vpc 


NO.15                        LOCAL BACKEND 

40:43  in mobaxaterm, watch how he arrived at the vpc dir 
inside vpc dir 
run terrafrm init   .....  to initialize the backend 
this backend that is initializing , its downloading pluggins and providers, basically what its doing, its downloading those particular providers pluggins in your local env
when that is downlaoded in ur local env, this becaomes a local backend 
inside of my vpc we see that it created for us this .terrafrm dir, it downloaded frm the registry, harshicop registry, it downloaded your aws provider, that is the version
of your provider 
                           
                             .TERRAFORM DIR

so that is the purpose of the .terrafrm dir, it downloads your provider pluggins and if u hv any module but it also generates for you this file called terrfrm log file
this is a log file that shows the provider pluggin that was downloaded
this ae the harsh keys of that particular provider/pluggin that was downloaded
 ***** so thats what terfrm init has done

NO.16

trfrm validate 
the configuartion is valid 

terrafm plan
we see the resoureces that wil be created
subnet and vpc 
we see the information (cidr block, tag) we passed as a variable has been extrapolated from the variable and interpolated into the resource 

terrafr apply -auto-apporve
it wil re run the plan first
then creates the vpc 
then crates the subnet bc the subnet depends on the vpc
once that is done
it also output the subnet id and vpc id, 
this is bc we declared an output 


46:50
 NO.17 ***********      BECAUSE IT HAS RETURNED THIS INFRORMATION, HOW CAN WE NOW USE THIS INFORMATION IN PROVISIONING OF OUR INFRASTRUCTURE

                   tERRAFRM.tfstate
  IN this inf that has returned, it has also generated a statefile 
the atatefile has the resources that were created
we see the specs too ( tag, attribute)
now if u had any sensitive inf bc as we said trfrm wil spit out everytin in plain text
so bc of that we seee that there is no senesitive inf that was passed so we dnt have anything to worry abt the vpc
     so this is our statefile

************* we wnat to get this inf,  we wnt to be able to read this inf and get our id for our subnet inorder for us to provision our ec2 instance 

   NO.18
48:11       HOW DO WE DO THAT???

          REMOTE STATE DATA SOURCE
 TRFRM gives you an option of a data source, u can use the data source to read a statefile called remote state data source
 CAn go to the documentation:
The terraform_remote_state data source uses the latest state snapshot from a specified state backend to retrieve the root module output values from some other Terraform 
configuration.

 so we can use the datasource to read our statefile and once that is done we are able to get the info that we need frm that particular statefile

for example:
in your work env as an engr u might be asked to provision
your netwrk will always be to provison first 
so your vpc wil be set, u go to work and your vpc has already been set 
bc your vpc has been created, ur told can u go and provison an ec2 instance in this particular vpc

  ********* NOW HOW DO YOU DO THAT ??????
you need to be able to read the statefile that manages bc evrytin is bein managed by terefrm
so u need to be able to read the statefile inorder for you to return the subnet, to get the attribute thata re captured in that particular statefile.

*************** bc this statefile is on your local env, it is local, so this backend wher terfrm is doing its operation is called a local backend
bc evrytin is on your local env 
therefore for us to read this statefile, we are going to , he closed the vpc dir 

NO.19
*********51:18   .... opened  .. data.tf file 
       AM using this data source :it is called "terraform_remote_state, 
this is the name that you must pass, this is the data source that is used to read statefile  
then i can give it any name, it doesnt matter, this is just a name (vpc) that wil be unique to terfrm

 ****** so if am calling this remote state called vpc, bc its goin to read the staefile of my vpc

data "terraform_remote_state" "vpc" {
  backend = "local"                                ********* the type of backend am using is local 
  config = {                                       what is the configuration ******** config here is the path, i need to tell tefrm the path wher to find that statefile
       path    = "../vpc/terraform.tfstate"         ******** the data.tf is here , bc the vpc dir/file is in the same dir as the data.tf file , am goin to give it a path
                                                        so it needs to go into a dir called vpc , while inside ther,you wil find a statefile called tefrm.tf
                                                     it is in the Present dir of a dir called vpc n inside of that particualar dir there is whta we call a terrafrom.tf state

 ************** so am using this datasource to be able to read this particular statefile
but once i read the statefile , am interested to get an output that was declared inside the atatefile, am interested toget an output of a subnet id

  54:08
********************************
     inside my instance resource block
main.tf  (the same file as NO.2 above)

resource "aws_instance" "my_ekl_instance" {
ami           = data.aws_ami.amzlinux2.id                            
instance type = var.myInstance                                                      we are passing the subnet id:
subnet_id        =data.taerraform_remote_state.vpc.outputs.subnet_id       **** my subnet id wil b read frm the remote state data source (vpc) n in the statfile, am      
key_name         = var. my_key                                      interested in d output, we always refer an output by its name (subnet_id) then trfm wil return the value
                                                                         so we are reading this subnet frm the statefile (frm our vpc module)

       ********* we are creating our resource inside of a custom vpc, our netwrk already exists 
  so we are creating this instance inside of this subnet id 

NO.20
***********now we are also passing a key 
lets say we hv this particular key, we wnat to pass the key, for us to pass the key 
if i look at my variables (No.3 above) i have passed my key (elk-instance)
again as we said last time, whatever key you pass needs to exist in the particular region u trying to creating your resource

    resource "aws_instance" "my_ekl_instance" {
ami           = data.aws_ami.amzlinux2.id                            
instance type = var.myInstance [1]                                                 
subnet_id        =data.taerraform_remote_state.vpc.outputs.subnet_id            
key_name         = var. my_key                         *************** key we are passing 



58:30 **************Also in NO.3 above (variable file), WE have a list of default values (t2 micro, t2 medium)
    if  we are to create a t2 medium, how can we reference it???
by indexing it, we are reading it frm a list:


NO.21
 **********  in the main.tf file, we are also passing a security grp , this is also an argument that we can pass 

vpc_security_group_ids = [
  aws_security_group.elk_sg.id,   ********** bc we nid this sg id, so it means this sg has to b created first before our instance can be created dats why we ar pasing
 ]                                                    depends on, if the instance creates first before the sg then the instance wil nt bootstrap well
]                                                    thats why we are doin an explicit depsncy so that terfrm orders hw d resourecs wil be created

  depends_on = [aws_security_group.elk_sg]    * we are also passing an explicit dependency using depends on  

NO.22
************ also, we are creating an elastic ip , an we wil attach it on our instance, so our instance wil v an elastic ip, it wil nt just be automatically assigned a
public ip bc we dnt wnat the ip to change so we are creating an elastic ip 

#EIP
resource "aws_eip" "ip" {
  instance = aws_instance.my_elk_instance.id     ....this is the instance id we are associating it with 

******** A backend is basically where terfm operates from, wher trfrm coammnds are executed frm, wit this particualr backend, we hv backend on our env so therefrer  this is
what is called a local backend , we are goin to refernce this 
in our code also we ar goin to have a provisiner, once we create that instance


 
NO.23   ******************************************************
null-resource.tf
#create a null resource and provisioners

 resource "null_resource" "my_null_resource" {
   depends_on = [time_sleep.wait_for_instance}       *********** the null resource depends on the time sleep (NO.26)
 # connection Block for provisioners to connect to the ec2 instance

connection {                        ********** we will connect to the instance by using ssh,we wil ssh into the instance
  host  = aws_eip.ip.public_ip     *********bc it is elastic, it wont change, it wil be d same ip that wil b attached on the instance, we wil us the elasic aws ip we cretaed
  type  = "ssh"             ** normally we wil pass a key to ssh into an instance, its d same tin we ar doing here,trfrm converted it to connection blk wen usin provisioners            
  user  = var.instance_user                                        e.g of the normal convention: ssh -i key ubuntu@76.89.56
 private_key = file    ("${path.module}/mykey/elk-instance.pem"}
                                      e.g of the normal convention: ssh -i key ubuntu@76.89.56
                                    ********* this is the user we ar connecting to : ubuntu@76.89.56, and our key is this particular key that we are using: ssh -i key
}                                       *********** the protocol we are using, the type is ssh     
                              terrfrm has converted this: the normal convention: ssh -i key ubuntu@76.89.56,  into connection blocks when ur using provisioners
provisioner "file {
   source    =  "script/elasticsearch.yml"
   destination = "/tmp/elasticsearch.yml"
}

provisioners  "file" {
   source  =  "scripts/kibana.yml"
   destination = "/tmp/kibana.yml"
}
provisioners  "file" {
   source  =  "scripts/apache-01.conf"
   destination = "/tmp/apache-01.conf"    **********  temporary dir
}
provisioners  "file" {
   source  =  "scripts/instalLELK.sh"
   destination = "/tmp/installELK.sh"
}
provisioners  "remote-exec" {
   inline = [
      "chmod +x    "/tmp/installELK.sh",     (i wnat to give executable permison to that script)
      "sudo sed -i -e 's/\r$//' /tmp/installELK.sh", #Remove the spurious CR characters. ( i wnat modify some chracters using some set commands)
      "sudo /tmp/installELK.sh",        ********** then i wnat to run the script
}

 1:04:16
    *********** in this particular case, we are also using what is called a null resource

   INTERVIEW QUESTION
 What is a null resource ??
this is just a place holder, its a dormy/empty resource, it doesnt create anything.. bt we can use it to enable us establish our connection n we ar connecting to this 
particular inastance we are creating :aws_eip.ip.public_ip

now when ur creatin g this particular instance, once we hv connection with it, we want to provision, we wnt to transfer a/some file , we hv some scrptt, the source is inside 
this dir called script, i wnt to connect to that instance and transfer this file 
the first file i want to transfer is elastic search
the nxt is kibana
3rd is apache configuration
4th is inatallation scripts  to install ELK 

              
              INLINE    ************* Explanation of the scripts we are transferring to the instance 

BUT the destination, its been transferred into an instance in a temporary dir, (tmp/kibana.yml) wit those particular names, so the names wil nt change, so once my instance
has created the provisioner will take over , this null resource wil be created to enable us connect to the instance and once we connect it wil transfer this files that ar in my 
local env to the instance , afer whic i wil use an remote exec provisiober , this is a provisioner that now runs commands on ur remote swerver, it wil run trfrm commands on 
the remote server, am goin to pass inline and LIline , basically just means the commands i wnat to be run 
so i wnat to give executable permison to that script then i wnat modify some chracters using some set commands inside of the script
then i wnat to run the script
once i run that particular script, this script 
it will do apt update
it will install elastic search, start it and we can access sit on port 9200
install logstash
kibana and start it 
install metricbeat n start the service            *************1:07:00
then it will start the service of logstash
this script once it 


****** this script once its transferred into the instance, the provisioner will run the script inside of that to be able to provison my ELK env
1:09:03
*****
i have my .pemkey compied here in his (#mykey file ), that wil be used for connection 
and obviously when ur using this code u hv to replace this key with ur own key or the code will nt wrk 
the key also exists on my AWS account... juts mk sure u copy the content of ur own key and replace it insid eof this dir
bc now how am referencing it, when u look at your null resource file 
private_key = path.module}/mykey/elk-instance.pem
am saying the connection , . private key is within the module, in a dir called my key and its called elk-instance.pem

*******and the user we want to connect to, I hv pass it as a variable in the variable file and the user/instance user is ubuntu

1:10:00
NO.24
****** and am also creating an output, its goin to output the public and private ip of the instance 
      (this file is diff from N0.12a , the vpc file for vpc output)

     output.tf
output "public_ip" {
 value = aws_instance.my_elk_instance.public_ip
}

output "private_ip"{
   value = aws_instanec.my_elk_instance.private_ip
}

NO.25
provider.tf

terraform {
  required_version = "~>  1.0 "
  required_provisioners {
    aws = {
       source = "harshicorp/aws"
       version = "~> 5.0"
    }
 }
                                  #### we comment the backend for now bc we havent used a remote backend yet 
# backend "s3" {
   bucket  = "landmark-automation-kenmak"
   key   =  "ec2/terraform.tfstate"
   region = "us-west-2"
 }
}
        let me declare my provider here
   #let me just put my provider 
provider "aws" {
   region = "us-west- 1          ************ am choosing this region bc this is where we created our vpc, we must be creating them in the same region
}

    ## so with that i have my vpc and i aslo hv my instance that i wnat to craete 


1:11:47
NO.21 .....  contd
 am also creating a security grp 
ill expalin to you whats goin on here

      sg.tf


bt here we are jst creating a security grp and we are creating it dynamically using for each , s
o this for each we hv created a locals blocks here n on the local block, we have declared an ingress config , which is a list, 
everytin is inside of this bracket, it is a list and inside the list we hv put whta we need to pass for elastic serach, the cidr blocks, the port, the protocol n description
and what we need to put for logstash and kibana as a map
so this is a list of maps , u see all these calibre,  this is a list of maps 
so we are usng for each to loop through
so for each of this map it is goin to loop through using the local.ingres 
as it loops through the description of the content will be this ingress which is calling this for ecah but we need the value
remember that for each uses each.value or each.key 
again, ill explain this when we are dealing with functions 
bt for now its just looping through all this ports then it wil dynamically create the security grp 
bc otherwise ill need to writebalmost like 100 lines of codes for each of this description/security grp
but now instaed  hv declared them as locals and am just looping through using for each meta argument and it will loop through this and create for me this ingress 
but then the ingress will remain the same 

so thats on the security grp


      1:14:36
NO.26
  ***********    tIME SLEEP
time slip is a resource that jsut runs time, its jsut like a counter,its jst counting down,i know taht when i create my instance, my instance wil take some time to bootstrap
for ssh connection to be available, if i run terfrm once my instance is created, if i try to ssh into it chances are the ssh might nt b up and so my connection wil fail so
bc of that am passing a time sleep resource just to wait for the instance to bootstrap first
hv passed 180s , this is abt 3minuutes, so once i start it this time sleep depends on the instance ie onsce the instance is careted then the time sleep wil run
have passed an explicit dependency , it depends on my instance , 
bt for the connection to happen, the null resourece depends on the time sleep 
so it means am ORDERING HOW  terfrm is goin to create the resources so it just means the instance wil be created first
then the timesleep , ther wil b time dealay of 3mins fo rthe instance to bootstrap after wich then my null resource wil start creating 
it can now ssh into it and provision the resources


  sleep.tf

 resource "time_sleep" "wait_for _instance" {
  create_duration = "180s"

  depends_on = [aws_instance.my_elk_instance]


#########################################################################################

   *********** 1:16:45 
let me now go into my env bc we have seen hw everytin is been configured and 
lets now create our resource
lets see how we can create our resources. 

***************1:17:00
now in i think mobazterm 

cd to the tf-file-provisioner 
terrafrm init 
trfrm validate
trfrm format   .... now all my codes hv been reformatted correctly 
trfrm plan 

the first thing that happens is the datasource , terAfrm remote state ,
it goes and read the state file of the vpc
data.terrafrom_remote_state.vpc: Reading
then
the data source for the ami , it goes and read and find the AMI and it returns the AMI id 
data.aws_ami.ubuntu: Reading 

once it does that what is been created is my elastic ip 
my instance the ami has been returned , that is the ami that will be created
the instance type t2 medium
the key name  elk-instance
its also returned our subnet id , ( ends wit 4e20)
if i scroll bk up where we created this 
output:
subnet_id = "subnet- ........ 4e20)                         .......... 1:20
so we hv used the datasource to read the statefile n return for us the subnet id wher we wnt to create our resource n after that the subnet id has been dynamically passed 
here and we knw that our resorce will be provisioned in that subnet 
we see the security grp
the null resource 
the time sleep

********* terrafrm apply -auto 


           **************************** 

NO.27
1:21:00
key refused
Not found key pair doesnt exists 
am trying to connect but bc i just changed my region to west, this keypair doesnt exist in west (in video 3), the keypair doenst exist in west
so lemme login in to my aws console n see what key pair i can use 
so he went to AWS for a diff key and change the name in variable file 
in mobaxterm, he jsut used the cp command to copy the key frm his downlaods to the pwd 
afterwhich we see the new key file in terrafrm and inside the file , the key content has been copied

       tf-file-provisioner cd mykey
       mykey cp -/Downloads/ansible-infra-test.pem
       mykey ls 
 ansible-infra-test.pem elk-instance.pem          ********** i can seee my key 

tefrm plan

terfrm apply

the first tin is creating ur instance bc w specifically passsed our depsndecy
then the time sleep bc it despend son the instance, it wil tk abt 3mins to provision
bt the API can create in parallel bc it doesnt hv any dependencies
bt the API needs the instance id and thats an implicit dependency
right now the time to slepe is happeing 
so if we go to our intances 
in this region we see thers an instance thats initializing
so this is the time that we are buying until our instance fully initializes b4 we can ssh into it
its goin tk abt 3mins to b on the save side , so its counting down 
once that is done the null resource will start proviosning 
bc the null resource depends on the timesleep , so the timesleep has to create first
after that creates the null resource will create 
it will do an ssh connection and transfer our files and start the configuration 
so right now what we are doing is provioning but once the null resource connects we now start doing configuration
we are configuring our instance by installing kiban, ELK, elatic serach on that particular instance
w eare using terfrm , we are using it with proviisoners 
provisioners are been used to do configuration
so this is another way we can configure our inatnces 
so we hv seen u can usee user data, which will just bootstrap 
but then if u want to ssh into an instance and taranser files from your local then it means we are goin to use a provisiner 


NO.27b
******** we have error : EIP

1:35:00    
                                           QUESTION
1)i was facinated on how you did the.pemkey cos i was wondering how we wil go and chabge the key bt thi sis really good
my quetsion is do we first go and create the key manually from our console is that what u did or is there a way we can automatically get the key pairs

ANS:
what v shown u is that that key already exists in AWS
 SO U can either do it either of the ways, u can either go on the console link a key that exists or u can create an ssh key
these keys that we use are jsut ssh keys 
so you can genertae your own ssh key on ur local env as long as you have your private and your public 
then in terfrm u are goin to use  , terfrm gives you everytin, u wil use AWs_key_pair (in google in typed it to go to documentation)
you wil use a resource called a key pair

                  (copied frm documentation)
 
    resource "aws_key_pair" "deployer" {       (you pass this key pair resource)
  key_name   = "deployer-key"            (you wil give it a name)   bt ther is a public key, so u wil copy d public key u generated using d ssh key gen command &paste 
                                          it here as a string, once that is done n u run/create this resource, dis key wil be ........
  public_key = "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQD3F6tyPEFEzV0LX3X8BsXdMsQz1x2cEikKDEY0aIj41qgxMCP/iteneqXSIFZBp5vizPvaoIR3Um9xK7PGoW8giupGn+EPuxIA4cDM4vzOqOkiMPhz5XK
0whEjkVzTo4+S0puvDZuwIsdiW9mxhJc7tgBNL0cYlWSYVkz4G/fslNfRPW5mYAM49f4fhtxPb5ok4Q2Lg9dPKVHO/Bgeu5woMc7RY0p1ej6D4CKFE6lymSDJpW0YHX/wqE9+cfEauh7xZcG0q9t2ta6F6fmX0agvpFyZo8aFb
eUBr7osSCJNgvavWbM/06niWrOvYX2xwWdhXmXSrbX8ZbabVohBK41 email@example.com"
}


********   bt ther is a public key, so u wil copy d public key u generated using d ssh key gen command &paste it here as a string, once that is done n u run/create this 
resource, dis key wil be sent into ur instance as ur public key but when you use ssh key gen , u wil get both the public key and the private key so in ur env u will be left
with the private but this public key wil be sent to ur instance then u will use this private key to authenticate with the public key that uve already sent into ur instance
then if u want to do it dynamically then u can use this aws key pair to automatically generate your keys but once you do that ull ned to generate the ssh key frm your local
env then u can send it 
so thats the 2ways that you can send it , either generate it on the console manually then just copy the name , download the .pem key, download it on your env then u can do 
that or you can dynamically use this resource to generate the key 

 
2)  1:41:00
       QUestion on referencing values in a map 

 in this variable file, he change dthe dfault to a map 
      varaiable "map" {
    type = map(string)
    default = [
      "dev" = "t2-micro"
      "stage" = "t2-medium" 

then in the resource blk )main.tf) , we pass the key : stage  and it will reyurn the value 

                       
                                   TERRAFORM CONSOLE

************how you can easily confirm that in terafrm there is what is called terrafrm console
       once you run that it gives a prompt >, helps you to quickly test to know what the output are 
       i can use terraform console to test my expressions before i actually commit my code 

    > var.map["stage"]          ************ so am testing what its goin to return for me 
  "t2.medium"          ******* the output
                              ie, this function:var.map["stage"]    evaluates  to t2medium

 > subnet_id  = data.terraform_remote_state.vpc.outputs.subnets.subnets_arn
  "it returns the subnet i"

    ********** so i can use terraform console to test my expressions before i actually commit my code bc i want to know what its gonna return
  with thi sma able to evaluate/check my function

   1:47:00
ALso,                          USING A LOOP   (showing you how to use functions)

                              (main.tf)
         resource "aws_instance" "my_ekl_instance" {
ami              = data.aws_ami.amzlinux2.id  
instance type  = [for s in var.myinstance : lower(s)][1]  ******** for is a loop, (s) is jst an abitrary number , i can use a,k etc 
#instance type   = var.myInstance [1]                                                 
subnet_id        =data.taerraform_remote_state.vpc.outputs.subnet_id            
key_name         = var. my_key
    

         showing you how to use functions)

            varaiable "myInstance" {
               type = list(string)
               default = ["t2.MICRO" , "T2.MEDIUM", "T3.MICRO"]    ******** usually in AWS this will give an error bc everytin needs to be in lower case 
              


*******  for s in var.myinstance : lower(s)][1]
 so this means that for , for any element in this variable (var.myInstance) am passing a function ; lower then the value of (s) 
so for every value in this instance that value theres a function whatevr is in the right of the column side, there is a lower function that is goin to be applied
so if the variable is capital "T2 MICRO" , then am goin to apply a lower function ie it will be converted into a lower case 
and when it converts it am goin to select the first instance [1]  ie t2.medium


     ******* now test the function 

   > for s in var.myinstance : lower(s)][1]
     "t2.medium"

therefore, this function evaluates to t2.medium

   > for s in var.myinstance : lower(s)][0]
     "t2.micro"

########   buT 
                  when we try 2 we get error 
  > for s in var.myinstance : lower(s)][2]
     in valid index



   *******so am just showing you that we can use a function to convert
this is been proactive as an engr to mk sure in future if someone who isnt an expert is e.g creating an s3 bucket name and we knw that by convwntion AWS doesnt allow capital
letteers in s3 bucket names and your instance type need to be lower, doesnt allow capital letters so bc of that u become proactive and making sure that whatever a user 
passes you are using a function to convert, so eben if thay pass a capital, you code will nt fail becauase am using a function to ensure that i collapse it/convert it to
lower so that once its converted its goin to read and pass the code
 thats exactly what this function was doing


1:57:20
  *********** contd  from
  NO.27b
******** we have error : EIP
************* during our break now illmodify my vpc code , ill share my screen but it basically wont be recorded
bc i just created a basic vpc bt runing terfrm apply we got an error, 
it looks like it needs an AN for a network for the vpc to attach, so am going to add more code to give us a more complte vpc
then once we do that we will us ethe same datasource to create our instance


   QUESTION
1) i can see in the variable file you have key name as a variable then in the null resource, why didnt we use the variable  when we were creating the ssh connection??

   ANS:       *********  bc we are using a file
 connection {                        
  host  = aws_eip.ip.public_ip     
  type  = "ssh"                      
  user  = var.instance_user                                      
 private_key = file    ("${path.module}/mykey/elk-instance.pem"}      ************ we are using a file , when you read at the function, u hv to give it a path to where the
                                                                    file is, it has to be either relative or absolute path, file function wil nt extrapolate like variables
                                                                 so u hav eto give it either relative or absolute path 


        WHAT IS THE part.module 

  ANS: 
i explained taht on saturday
its just a terfrm way, the syntax that they use saying that this is within the path of the module 
where we are here, the part of your module is your pwd , so when u evalute this (path.module) it always returns your pwd 
(path.module) this is your pwd 
 so u can easily pass as  :   file = ./mykey   .... bc it will evaluate to the pwd
OR u can pass it as : file = mykey/ansible

  ***************all these are the same 

   ********* but according to the syntax, harshicop configuration lanuguage they prefer to use this, path to the module (path.module) then the location wher rthe file is 
/mykey/elk-instance.pem"




  when w ereturn frm the break, we wil look at our backend 
we will create this 
we v already seen what a local backend looks like 
we have benn able to read the statefile here
but once we come back, 
once we create this ec2 module , we will create a backend remotely  and we will move our statefile to the remote backend and see how we can read a statefile from a remote 
backend 


    ANNOUNCEMENT
2:04:30 
prof said python will be covered during bootcamp

someone asked about promethus n grafana n he said its deployed with kubernetes 
someone asked for newrelic and he said we already hv a resource to that effect, its even on our youtube channel so that resource will be deplyed accordingly, once u look
at promethus and grafana, newrelic will just be anoda deployment in that category so you will not have any problem

we have people who have testified in the past who finished the course and its like they hv not had any mastery but in the bootcamp everything changed , 

once you fill the form we get it instantly 
 its cloud computing that we are leveraging on 


#########################################################
   
           CLASS CONTINUES

        Contd ... frm 1:57:20    above 
2:09:25
   we had ceated a vpc but because the vpc was very basic the only thing we created was basically vpc with one subnet 
  bc of one subnet it was failing so i went ahead and updated my code 

so now we have a new dir (my-vpc) with a new file for our vpc (vpc.tf) and the old dir (vpc) with the file we wont use bc of basic configuration (vpc.tf)
also , there are other new file in the new dir ( variables.tf, provider.tf, output.tf)
*********** and dont worry about the code  you will have the code and you will have all this code and will have time to go thru all this 

     2:09:40
   
   NO.28
new vpc.tf

    resource "aws_vpc" "main" {                ************ we are creating a resource vpc
   cidr_block = "var.vpc_cidr"

tags = {
   Name = " my-vpc"
  }
}  

#2  create IGW                        ******** when u craete a vpc u nid to craete an IGW for your vpc to be able to  have access  to internet, 
resource "aws_internet_gateway" "igw" {         
     vpc_id =aws_vpc.main.id

     tags = {
        Name = "igw"
  }
}

#3  create EIP                            ************** elastic ip that we will use for our natgateway, this is like a 3tier kinda infrastructure 
   resource "aws_eip" "nat" {   

      tags = {
         Name = "nat" 
    }
   }

#4  create NAT gateway                     
 resource "aws_nat_gateway" "nat" {
  allocation_id = aws_eip.nat.id                        ************* once this is created we will allocate our elastic ip to the natgateway 
  subnet_id   =  aws_subnet.public[0].id

     tags = {
       Name = "nat"
}

 depends_on = [aws_internet_gateway.igw]         **************** the natgateway depends on igw
}

#5 create private subnet                   ********** dnt worry abt this code, am uisng a lot of functions to make it very comfortable
    resource "aws_subnet" "private" {                                                              
    count              = length(slice(var.private_cidr, 0, var.private_subnet_count))   ***** count meta argument bc i wnt to knw d number of private subnet i wnt to create
    vpc_id             = aws_vpc.main.id                                           
    cidr_block         = elements(var.private_cidr, 0, var.private_subnet_count)), count.index)
    availability zone  = element(var.availability_zones, count.index)

    tags = {
      "Name" = "private"
}

  2:12:00 

   ****** am using a count meta argument bc i wnt to knw d number of private subnet i wnt to create
   and am using a slice function bc its reading my private cidr
when u look at what a slice functions does, it reads
when you give it an input like a variable and you give it like the starting index, i wnat it to start from index[0] when i give it a list then what is the end index?
so that slice is smt similar to 
e.g
 i have a pile of multiple elements, so frm the slice perspective, i just want to get a slice of this pile
i hv 9 cidr blks , now am making this flexible bc i want to get a slice of the cidr blocks, i dnt want to hv to use all cidr 
so am saying begining from the first slice on index 0 to a certain count , mayb i want 2, so frm o to 2nd slice
so it is going to slice the pile to the portion of the 2nd cidr and return just that portion as the length
that means the count will be 2 bc , although i have given it a pile of 9cidr blocks  but iwant it to start from 0 and go up to 2
so , 0 i sthe first index but i wnat 2 slices , ie 1 & 2
so count wil return this 2slices and that will mean that i am creating 2 subnets inside of that vpc   :
   create private subnet                  
    resource "aws_subnet" "private" {                                                              
    count              = length(slice(var.private_cidr, 0, var.private_subnet_count))

*********** so the same thing will happen for the element bc am using count, so it returns some element from that particular list 


#6 create public subnet 
resource "aws_subnet" "public" {                                                              
    count              = length(slice(var.public_cidr, 0, var.public_subnet_count))   
    vpc_id             = aws_vpc.main.id                                           
    cidr_block         = elements(var.public_cidr, 0, var.public_subnet_count)), count.index)
    availability zone  = element(var.availability_zones, count.index)

    tags = {
      "Name" = "public"



#7 create private route table          *********** am creating routes within my vpc 
 resource "aws_route_table" "private" {              route for private 
    vpc_id = aws_vpc.main.id

  depends_on = [aws_subnet.private]

  tags = {
    Name = "private"
  }
}

#8 create public route table
resource  "aws_route_table" "public" {     
  vpc_id = aws_vpc.main.id

   depends_on = [aws_subnet.public]

  tag = {
    Name = "public "
 }
}

#9 create public routes                               ********also creating routes within the route table
resource "aws_route" "public_internet_gateway" {

  route_table_id         = aws_route_table.public.id    ******** for this route table that is public the destination is all:"0..0.0.0/0" , bc its public then its goin to igw 
  destination_cidr_block = "0..0.0.0/0"
  gateway_id             = aws_internet_gateway.igw.id         ****** so all traffic to igw

  depends_on = [aws_route_table.public]    ************ it depends on the public route table above (NO.8)
}

 #10
  pivate routes
resource "aws_route" "private_internet_gateway" {             ******* then for the private route table am using the nat gateway, 

  route_table_id         = aws_route_table.private.id
  gateway_id             = aws_internet_gateway.igw.id       ****** all traffic should point to the nat gatway 
  destination_cidr_block = "0..0.0.0/0"
  
  depends_on = [aws_route_table.private]               ******  it depsnds on the private (NO.7)

                                           
*************  2:17:07


#11 private route association                *********** we hv to associate our subnet with 

  resource "aws_route_table_association" "private" {
     count              = length(slice(var.private_cidr, 0, var.public_subnet_count)) 
    
     subnet_id           = elements(var.private_cidr, 0, var.private_subnet_count)), count.index)
      route_table_id         = aws_route_table.private.id                                          ****** associating it with the private route table 


      depends_on = [aws_route.private_nat_gateway, aws_subnet.private]
}

#12 public route association

    resource "aws_route_table_association" "public" {
     count              = length(slice(var.public_cidr, 0, var.public_subnet_count)) 
    
     subnet_id           = elements(var.private_cidr, 0, var.private_subnet_count)), count.index)
      route_table_id         = aws_route_table.public.id                                              ****** associating it with the private route table 


         depends_on = [aws_route.public_internet_gateway, aws_subnet.public]
   

   ########### now this is a complete vpc that am creating 




2:15:00 **********************

 NO.29
     ********** variable.tf
                             ********* in my varaibles, i have all these cidr blocks, am defining this ....

    variable "private_cidr" {     
       type = list(string)
     default = [
          "10.0.1.0/24"
          "10.0.2.0/24"      ** but i just want to create subnet in just these 2, so am making it flexible if i need to make more subnets then i can just increase my slice
          "10.0.3.0/24"
          "10.0.4.0/24"
          "10.0.5.0/24"
          "10.0.6.0/24"
          "10.0.7.0/24"
          "10.0.8.0/24"
  }
}
variable "availability_zones" {
   type    = list(string)
   default = ["us-east-1a", "us-east-1b"]
}

 variable "public_cidr" {
       type = list(string)
     default = [
          "10.0.101.0/24"
          "10.0.102.0/24"
          "10.0.103.0/24"
          "10.0.104.0/24"
          "10.0.105.0/24"
          "10.0.106.0/24"
          "10.0.107.0/24"
          "10.0.108.0/24"
 ]
}

variable "vpc_cidr" {
   type    = string
   default = "10..0.0.0/16"
}

 varaible "private_subnet_count" {         ********* my private subnet count am just creating 2
   type   = number 
   default = 2
}

 variable "public_subnet_count" {    ************** my public subnet am just creating 2
    type = number
    default = 2
}

  NO.30
  provider.tf

provider "aws" {
   region = "us-west-1"
}

  
terraform {
  required_providers {
    aws = {
       source = "harshicorp/aws"
       version = "~> 5.0"
     }
   }
}

  

 NO.31
   output.tf
output "private" {                                  *** i want to return my private subnet
 value = aws_subnet.private.*.id
}

output "public"{                                   *** i want to return my public subnet
   value = aws_subnet.private.*.id                  ** bc  am returing using  * (splar) am creating 2subnets so am goin to return 2subnet ids n when i reference in my code 
}                                                                                                                         ***2:18:26                           (main.tf)

  output "vpc_id" {                                  *** i want to return the vpc id 
         value = "aws_vpc.main.id 

  output
    output "vpc_cidr" {                                   *********** and the cidr for my vpc
         value = "aws_vpc.main.cidr_block
}


           ********* but what am interested in is either this public or private subnet but ill create my instance inside ofthe public subnet 
  


  2:18:26

  
                           (main.tf)

         resource "aws_instance" "my_ekl_instance" {
ami              = data.aws_ami.amzlinux2.id  
instance type  = [for s in var.myinstance : lower(s)][1]  
#instance type   = var.myInstance [1]                                                 
subnet_id        =data.taerraform_remote_state.vpc.outputs.public[0]        ****** when i reference it in my code, am referening that public output wich returns 2 of them   
key_name         = var. my_key                                                

   bt i need the 1st one, am goin to create my instance in the first subnet on the list bc this
     wil return for me a list, a list of the 2 subnets, so it wil be subnet 1&2 bt i wnat the first 
      so am using the index[0] to get the first subnet, thats wher ill create my instance

   

meta data option {
   http_tokens      = "required"
   http_endpoint    = "enabled"
}

root_block_device {
  encrypted = true
}

 vpc_security_group_ids = [
  aws_security_group.elk_sg.id,   ********** 
 ]                                                   
]                                                    

  depends_on = [aws_security_group.elk_sg] 
}

#EIP
resource "aws_eip"ip" {
  instance = aws _instance.my_elk_instance.



2:19:25
    **************************#########################

 i blieve now in mobaxterm:

   my-vpc ls
ouput.tf  provider.tf   varaibles.tf   vpc.tf

my-vpc   terrafrm init
so here am recreating the vpc 
am no longer goin to us ethat vpc

terfrm validate 
successful

terrafrm plan 
      ********** watch      ............... 2:20:25

terrafrm apply .auto.approve 

   error:  vpc limit is exceeded
i can either go into my console    OR
  use IAC 
 cos i created the vpc, it already existed in that same region
my-vpc cd  ../vpc               cd and go to vpc
  vpc ls
outputs.tf   provider.tf     terrafrm.tfstate varaibles.tf       ****** so i seee i have the state file , so lll destroy it cos they are in the same region
vpc terrafrm destroy -auto-approve

   ***** somebody aked yetserday, can we destroy a vpc with a resource in it ??
lets find out 
we created a vpc and once it was created  we already created an instance in the vpc , so are we able to destroy it
so once it resfreshes the state, it starts destroying that one subnet 
its saying its still destroying 
uwil find out that it wil continue goin that way until it times out bc u are trying to destroy a subnet bc it has a resources in it 
so it will nt allow you 
so even on the console it will give you an error , u cant destroy it 
bc of time ill just stop the process, bt if u hv time u can try it, u can wait as long as you wnat, it wil nt destroy 
unless i destroy my instance first
ill just inter route , contrl c 

we can see  error:
this subnet has dependencies and cannot be deleted

  ******* 2:24:20




bootcamp 
i dnt wnat you to think that u dnt have live experience 
u were working in landmark , whatever we did we didnt do it from the classroom, we did it frm the workplace
what has helped landmark students over the years is confident
the entire programme is project base
 someone told me no prof i dnt wnat any experince on my resume, i just want to go in for interview n tell dem i just completed internship at landmark
and when she spoke at the interview she was told she was speaking from a professional perspsective and she was hired 
        ### this is what ill first try 

if u dnt knw that frm day 1 this programme has been project based then thats a serious problem 



















diff btw output and datasource
https://stackoverflow.com/questions/75246774/difference-between-data-source-and-output-block-in-terraform

data essentially represents a dependency on an object that isn't managed by the current Terraform configuration but the current Terraform configuration still needs to make
use of it. Mechanically that typically means making a Get or Read request to a specific API endpoint and then exporting the data from that API response in the resulting 
attributes.

output represents is one of the two ways that data can flow from one module into another. variable blocks represent data moving from the parent module into the child module,
and output blocks represent data moving from the child module out to the parent.

There is no strong relationship between these two concepts bt one way they sometimes connect is if you use the tfe_outputs data source belonging to the hashicorp/tfe provider,
or if you use the terraform_remote_state data source from the terraform.io/builtin/terraform provider. Both of those data sources treat the output values from the root
module of some other Terraform configuration as the external object to fetch, and so you can use these as one way to use the results from one configuration
as part of another configuration, as long as the second configuration will be run in a context that has access to the state of the first.





   
        




             




















































