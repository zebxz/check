

12:36 to 16:12


XPLAIN THE K8 ARCHITECTURE

k8 is a grp of servers that are working together to be able to ochestrate containerize applications, its made up of a control plane & worker node, the control planee comes with
components line the API server which is the main adminstrative point and the entry point into the cl8 & it does generally authentication & authoriztion & it ensures that whatevr
Req GETS into the cl8 is been made by an authorized & authenticated individual, apart of the API server, we hv the etcd that persists data in the cl8, it acts as a database ,
whatevr reQ is been made by whoever engr that inf is stored and persisted in the etcd and frm there we also hv the scheduler, which is incharge of scheduling  eg if ports are
been REQuested to be scheduled the sheduler will schedule that considering the nodes that hv available resources for such a port to be hosted and if thers any other constrain
all the constraint are been factored in
we also hv the controler managers that is able to ensure that at all times we hv a  number of nodes running , pods running , deplyments are runing as expected
we also hv the worker nodes comes with the kublets which is the pry node agent, we equally hv the kube proxy, which is incharge of netwrk 
also the container run time, there are diff types of container run time that you can use, docker used to be one of them , also container-D, container runtime is any software in 
your node that is able to create and start containers bc k8 is all abt managing containerized appl n in our env we use containerD as our container run time, we cud hv as well 
choosen other run time but we are using containerD

Also the k8 architecture is such that calls are made into the cl8 and that happens using the k8 client like kubectl or k8 UI form there we can mk certain API calls either to 
create containers, namespaces, security like RBAC and for any of these to happen, authentication must happen via the kube config file

so thats the k8 architecture



docker 7
your explanation when it comes to migration from monolecthic archited applications to micro services 

 how is your appl designed?? , what is the design of your application, in terms of architecture how is it designed
so we hv either a monolecthic design or a micro service design , 
fo a designed tha is monolized, u are working with an appl and all the components or modules are running as a sinle block of code so developers are working on an appl for 
e-commerce or ebay, that appl can permit a user to log into an ebay account, register , create a cart, select items, make payment etc...this is an appl
how is it designed, it cud either hv a micro service design or monolecthic design wher we hv a single block of code such that the same block of code will permit u to access
ebay, register , etc  thats a monolecthic design or aplication

PROBLEMS OF MONOLETHIC ....................... 20;11
if thers a spike  eg if 10million people are registering but only 1million is making payment, we will hv to scale up both the entire appl even though only 1m is making payment
so thers a lot of waste with resource usage in monolethic design 
also micro service appli are light weight but monelethic are larger and thats a problem

***** so that takes us to micro service applications, in our environment, we hv legacy appl that are running as monolectic which as a devops engr we are now decoupling 
monoletic appl into micro services

WHY DO WE NEED TO DO THIS  ? 
Again, we can run ., what we do is that if we hv an ecommerce appl, ebay.com/ebay.war we can break it down into smaller modules, where login is diff registration is adiff
so if thers a spike when it comes to registration, we will scale just registion .... we are goin to be runing this individual micro services as containers
we hv containers for registerin, container for ordering, container for cart, etc so if thers a spike for login, we increase the no. of login containers that we want so we
increase the no. of replicas for login , we dnt hv to increase that of payment bc we are running isolated micro services we hv been able to decouple our application .. 


24:50 
    hOW DO WE DECOPLE THE APPLICATION  ? 

as a devops engr its nt my job to code bc if an appl runs as a micro service or monolectic, it depends on how the codes were written n its the software engr/developers that 
write the code
so in the meeting we sit n infrm them we hv to decouple our ecommerce appli bc it has issues running it as a micro service eg
scaling issues, coding issues, develpment issues, security issues
so we hv meeting  with your team and inform the developers start wokring on decoupling the appl, it now becomes their job

  so experience

  TELL US YOUR XPERIENCE WHEN IT COMES TO MONONOLECTIC OR MICRO SERVICE APPLI

thank u for that question, 

in our env we mg8 federated micro service applications and for a while now we've principally been working on mirco service applications, hv been working on micro service 
applications that is easy to scale , it optimize the use of resources, it has higher level of security etc however, we equally hv some legacy appl in our env that we hv been 
able to successfully decouple them into micro services bc of the adv that comes with micro services 



               IS THERE ANY DISADV THAT COMES WITH  microservices

YES, for example the ntwrking within microservices , for example, how do you ensure that login container communicate registeration, registration with cart , how do u ensure 
that once ur done with ur cart  u click on pay now n payment is effected n u can place ur order, so that becommes a communication issue, netwrking issue 
how do we solve that ??????? 
in k8 we solve that via service discovery, we use the service name to permit containers or services to comm with each other so one service can carry out dns resolution to 
a grp of pods , n again we jst dnt do that we realise that thers a service match/mesh, hw we can enure that these services effectively commu with each other seamlessly that is
pat of k8




29:00
                 SETTING UP A CL8 USING KOPS 
   Walk me tru your kops kubernetes cluster setup

thnk u so much fo rthis question 
Kops is a software that permits us to deploy a production ready k8 cl8 in aws and other platforms
    ******* this is a generic definition, u hv to narrow down your explanantion to your environment 

in our env we hv setup our kops cl8 server using ubuntu   (( bc it doesnt mean that its only ubnuntu server that u can deploy kops on ) 
in my env i have been tasked to setup a kops cl8 on an ubuntu server. and for that to happen, the kops software needs permission to be able to create the entire cl8  ie 
the worker n the master node in aws, such that when we run the command:

 kops create cluster --$NAME

this will create worker node and master node 
creates VPC with all components
it creates auto saclling group (ASG) for workernodes and masternodes
creates ELB for the apiServer
Creates launch templates for workernode and masternode
creates dynamic storage classes
it uses s3 as a kopstatestore   ie kops state store is in S3

kops server needs to be authorised to be able to create and mg8 all these services 
and it is imp to note that the reason we call kops a production ready cl8 is that once it is deployed, it comes with other aws services like vpc, asg, ec2instance, ebs vol,
launch tmeplate, it can equally come with other storage category like efs, and S3 


but for this to be executed successfully kops needs to be authorized and this authorization can be defined using 2things : 
we need authoriz\tion and authentication using IAM in aws

what else do we hv for IAM apart from users,  we hv 
IAM = user/ roles/ groups/ policy           ****** so with the help of IAM, we can create an IAM user and attach the required policy that will permit kops to create all 
of this and attach it to our kops server and once that happens we are able to deploy our kops cl8 with relatve use
so we hv to create an iam suer , then attach the creadentials like the access code and secret access code to permit the resources to be created when we run kops create




42:34                     WALK US THROUGH YOUR ARTIFACTS MG8 WITH NEXUS 

   cAN YOU USE THE ANSWER TO THIS QUestion as a project your working on 
like tell us a project you are managing at the moment


ANS:

My project at the moment for the past 6nmths, i hv been tasked, am basically incharge of managing our artifacts 

is that a serious task to mg8 artcifacts 

what is the mg8 of artifacts ?? what does it involve 
walk me tru your artifacts management with nexux

45:40
thank you very much for that question
when it comes to artifacts, its very imp in the software development lifecycle and the way artifacts are managed bc artifacts are deployable  packages
packages that  appl servers  can understand, can interpret , thats what artifacts are all about

so in our env we use nexus to mg8 artifacts alongside our build servers which is jenkins on our pipeine 
so when artifacts acre created those artifacts are uploaded into nexux
so as part of my task, hv been able to setup a nexus server 
and in our env i was tasked to setup a nexus server on a redhat9 instance, i have done that before on REDhat8 and 7 instances , where ill donwload the software of nexus
and ill extract the software , when that happen, i hv nexus running on my pipeline , one hv installed nexus i ensure that nexus has started, its running afterwhic i go to 
the nexus url , nexus accounr and i create repositories/artifactories wherewher artifacts can be uploaded into and generally i create both snapshot repositories releases 
and releases repositories, the repositories is where il upload my artifacts into 
again for the artifacts to be creaed, it rQuires dependencies, it requires pluggins , so hv equally used nexus as my maven proxy refactory where artifacts are not directly
gotten frm the maven central repository , that is to say pluggins and depencies for us to be able to create artifacts can only be gotten into our build srver via the proxy
server which runs in neuxs
its also worth explaning that hv equally been able to upload diff classes of artifacts including:
jar/war/ear , npm ie for node js applictaion, dockerimages 




A) what PROBLEMS HAVE YOU FACED IN $tool and how did you resolve them 
  b) EXPLAIN A PROBLEM YOU FACED IN YOUR PROJECT AND THE STEPS YOU TOOK TO RESOLVE IT 

which of this questions will you choose, 
ANS: ill choose b, because its an open question, you can choose any tool to talk about 


    
*****************  ( JENKINS PROBLEM) 


53:00    problems arise everyday  , so u must not only get things fixed bc it happened when you werea junior engr , it cud happen while ur a director, while your a 
the vice president for engineering , cos u hv a jnr. IT or devops engr, a devops engr a senior devops engr, a devops manager, a devops director or vice president for engineering
wont u encounter a problem, problems dont arise just bc of one junior engr made it happen  .... NO 

ther can be a problem wher the server is down , lets assume your master server  for k8 is down , if our docker build server is down for conatineroztaion
what will happen if ther are some changes in API version and you are trying to use old manifest files , how will you fix such a problem. ther are many probelms that can arise
in your env
ther could be a problem wher pods are not running , we cud hv reosurces problem , we hv induffficient resources, so our srever cannot support a higher level of application 
deployment thats a big problem 
explain this problem and tell us how you fixed it 


55:28   ,, said he was using jenkins to do a build but was always having a fail

proff:
    if theres a problem ,you dnt just first dive into your pom.xml file
the first thing is to check the logs, if we are building in jenkins, thats what we call console output 
u go to the console output and try to identify what cud be the cause of the problem, if the cause of the problem will need that i get into pom.xml to check then il do that 
if the cause is for you to talk to dvelopers to inform them to check their code , it cannot runbc the compilers they hv defined is the wrong compilers they shud check
their pluggins , the pluggins defined in pom.xml are not th epluggins the job neeeds to run , so they shud wrk on it and define the correct pluggins , 
so if theres a problem check the logs 



58:00
    Thank you for this question

in my env i am incharge of manging artifacts , and as part of my job, i set up my nexus artifactory  by creating a nexus serevr, ensuring that nexus is fully installed, 
ensure thats its running as expected, i create artifactories, repositories in nexus n i use the artifcatory  repository url to modify my project file which is pom.xml,
this wil permit us to upload artifacts into this artifcatories, when we build frm the development branch, artifacts are uploaded into the nexus releases repository .. 59:00
when we build form the master or the relaese branch, artifacts are uploaded into the release repository
i was tasked to upload some artifacts into the release repository and i realised for some reason i kept getting build fail and when i checked the logs i realised i was using 
the wrong version in my pom.xml, instaed of ensuring that the versioning is tagged to releases it was tagged to snapshot, so i quickly went to my pom.xml modified the version
used the corret version which was snapshot and once i had to rebuld again via my pipeline that failure never existed because it was now uploading artifacts into the snapshot
repository that was expected.


SONARQUBE

      ANOTHER PROBLEM     ( ROLL BACKS, due to no code quality software )
we had a serious issue with one of our client where we managed a fintech appl, we kept having multiple rollbacks 
we will deploy the appl but the client will call back informing us that smt was wrong, there were multiple rolbacks , i was tasked to invetsigate what was the problem bc 
that doesnt give a good image abt our software cy, so i began researching, the build was successful, deployment has happend but thers still rollback
then i realise that in our pipeline, something was missing on the pipeline, a code quality checker, there was no tool that was been use to check for code quality to ensure 
that the applicatons we rae deploying ra deployed form quality sofware that the no. of testcases that developers are writing are commesorat to the no. of code that they are 
developer , so when i realised that was the problem , i immediately explained that to our team in one of our sprint review meeting and i instantly recommended that we shud
use sonarqube bc in my research that sonarqube will be a very good code quality checker and that was the problem we were facing and the recommendation was to use sonarqube 
so we use sonarqube .

and i was tasked again to know how sonarqube can be fully deployed in our env  and thats how i came up with the white paper on sonarqube setup in our env and frm that paper
i learned the steps on how to get sonarqube installed , whcih is very simple, u go to the sonarqube site, u download the latest version of the sonqrqube software via the wget
command and extract it and start sonar ,  sonar.sh start 
sonar starts,and once that is done we can now access it via the browser and frm ther we can now modify our project fie under the properties tag, we modify it with our sonarqube
aerver login credential details and frm ther sonarqube is now part of our pipeline, jenkins integrate with sonarqube for code quality analysis , we introduce sonarqube , we
strated setting up our own benchmark for code quality and as such today we dnt hv huge incidents where we hv to be rolling back on deployments bc before any deployment is done
we expect that the codes hv been qualified , its deployed from quality software, that is the problem we hv faced in our env and thats how we fixed it 


*********** this problem cud be explained form a diff angle
our answer cud be abt k8, which problem hv you faced in k8 and how did you fix it so pls take note, its very important


         

1:04                     


 they used dice, indeed, linkedin




as part of my job, i write pipeline scripts, i write jenkins file , i also modify existing jenkins file to be able to have this entire end to end process automated
you cud walk them tru your jenkins pipeline like that 
you cud also go ahead and tell them that ..:
its imp to note that jenkins is able to integrate with all the components highlighted bc of the fact that jenkins can extend its functionalities tru pluggins 













































