

  ************CHECK ALL THE TABLE OF CONTENT AND NOTE ALL THE TOPICS WITH troubleshooting....



kub1&2


kubeadm --> We can setup multi node k8's cluster using kubeadm.  ... kubeasm is a sfware that is used to launch a k8, both d control plane n worker node
    kubespray --> We can setup multi node k8s cluster using kubespray , it uses ansible playbook
     (Ansible Playbooks Used internally by kubespray).
  
first instal container-d n its dependecies bc our runtime (to b able to start&runour conatiners) is nt docker bt it is container
-d, once it is installed, we will proceed to start container-d  afterwhcih we wil instal kublet, kubeabm and kubectl,, after that we wil start the kublet
service i will run this as a script and i nid to be root user

Initialize Kubernetes control plane by running the below commond as root user.
sudo kubeadm init

run the 3commands as stated in the success notification in my cli  (mkdir -p $HOME/.kube .......)
we can cat .kube/config  file, we can see its content n this is d file authenticating us to carry out tasks and d  user now is the admin , so he has admin
access in d  cluster

we run : kubectl get node  or kubectl get pod
it shows the master node is not ready
7) so to ensure its ready we v to deploy the ntwrk plugging
kubectl apply -f https://github.com/weaveworks/weave/releases/download/v2.8.1/weave-daemonset-k8s.yaml
************now it has created certain components 
now if we execute kubectl get node .............. our master node is ready

lets check all the pods in the cluster ..... kubectl -A 





advantages of namespace
****clusterRole &clusterRolebinding is for the entire cluster 

***Docker is 'compose file'  deploy with command 'Docker compose up -d' WHILE kubernetes is 'manifest file' deployed with command 'kubectl apply -f pod.yml'


   TK NOTE OF THIS TREE
kubernetes:    kub has a cluster , 
   cluster: it is a grp of nodes
   nodes:  in the nodes ther are pods 
   pods:  in the pods ther ar containers ..  
   containers :  


        OBJECTS USED FOR DEPLOYMENT
kubernetes resources/objects used to deploy application include:
   Pod :
or    
 controllerManagers:
      Replication Controller
      ReplicaSet
      DaemonSet
      StatefulSets
      Deployment
      Volume
      Job       

****when u deploy appl in k8, u v to make the appl accessible ie exposing appl/accessing appl
Exposing/accessing applications = Service Discovery:
    Service Types:  it will route service to our appl n their replicas ,
    ClusterIP :  it performs LB  , its used for internal communication inside the cluster.
    NodePort
    LoadBalancer
    ExternalName  
  ingress 
  networkPolicy 




  KEY VALUE PAIR
hw do we consider keyvalue pair 
**************for e.g when u want to create a manifest file, it has this acronym, comes :   where 'comes' stands for kind, api version, metadata and spec
kind is a key value pair bc for example ; kind is pod , this is a key value pair, it has a key & a value  ,,, so key &value ,, kind:pod
for e.g , key value pair could be  name and the value is simon
key:value  pairs 
name: simon   



kubectl get namespace
  kubectl get ns 

 kubectl create namespace fintech --v=8      . V , MEANS   in verbose
 kubectl create namespace dev     
 kubectl delete namespace dev


How to deploy run/execute tasks/workloads in kubernetes??
   1. Imperative  approach 
        By using commands 

   2. Declarative approach
        By using files [manifests files]  

-# Create POD Using Command
kubectl run <podName> --image=<imageName> --port=<containerPort> -n <namespaceName>
kubectl run hello --image=mylandmarktech/hello --port=80 -n dev 


ubuntu@master:~$  kubectl get po    ...... ........      ****By default, it lists pods in the currently configured namespace.
no resources found in default namespace 
ubuntu@master:~$ kubectl get po -n dev
no resources found in dev namespace 

ubuntu@master:~$ kubectl get svc -n dev      .... to check for services
no resources found in dev namespace 

To deploy manifest file
vi pod.yml and paste the mainfest file 
kubectl apply -f pod.yml


kub 3&4

 MORE PODS COMMANDS ............7:25
kubectl get all
kubectl get events
kubectl delete po (podname)
kubectl delete all --all 
kubectl delete all --all -n dev     
kubectl delete pod --all                                                                                               interpretin , creatin &mangin d pod 
kubectl get pods                               Anotation is a metadata info abt ur pod that is set by d sys/k8 service n it is what d sys wil understan when it comes to
kubectl get pods -o yaml   ...   will present the pod in that are runnin in our clustera yml file, we can see annotation,bt when we made d file to create d pod der was no anotation
kubectl get pods --show-labels
kubectl get pods -o wide           **************** gives more inf abt the pods
kubectl get pods -o wide --show-labels
kubectl get node
kubectl get node -o wide    *************** we see d nodes we v , the k8 version, the kernel version and the runtime which is containerd and not docker .(tk note)
kubectl delete node node5   ******************* to delete node5

in docker we run: docker inspect  to get more info abt the container
kubectl  describe pod <podName>      *********to get more info abt the pod 
kubectl  describe pod <podName> -n <namespace>


kubectl api-resources   *********** to get the apiresources for our pod,, we can see so many api resources , ...
kubectl api-resources | grep pod      ....  so to specify n grep for pod , we see we can either call it pods or po and the apiversion is v1



We can check the service 
   Kubectl  get svc 

To get the end point 
Kubectl get ep

Kubectl  get svc –o wide

kubectl get svc -n <namespace>       (svc is service)
kubectl get svc -n dev  


kubectl get svc -n dev  
kubectl describe svc  
kubectl get ep      ... we can get the end point.. one/ A single service can route traffic/LB to multiple replicas of an appl  43:20
kubectl describe svc     gives more info abt the service
kubectl delete svc



FQDN
If one POD need to access service & which are in different names space 
we have to use the FQDN of the service.
******************Syntax: <serivceName>.<namespace>.svc.cluster.local
                 ex: myappsvc.dev.svc.cluster.local


creating static pod
sudo vi /etc/kubernetes/manifests/file.yml            ************we ar creating it in the k8 manifest dir


REPLICA CONTROLLERS
 kubectl get rc
 kubectl describe rc apprc       ..... to see more info     ***i bliv 'apprc' is the rc' label




 ##########more COMMANDS FOR REPLICATOR CONTROLLERS
labels:    app: web   = address: gra  
selectors: app: web   = address: gra  
replicas = 3  

kubectl apply -f <filename.yml>
kubectl apply -f rc.yml
kubectl get rc 
kubectl get rc -o wide  
kubectl get rc -n <namespace>
kubectl get all
kubectl scale rc <rcName> --replicas <noOfReplicas>   ..     **************** ..... WE CAN ASLO SCALE the replication controller 

kubectl scale rc apprc --replicas 4     
kubectl describe rc <rcName>
kubectl delete rc <rcName>



  CREATE SECRET
Create a secret that will authenticate kubernetes to pull images from dockerHub/nexus/jfrog  
dockerHublogin
kubectl create secret docker-registry regcred     ...****************** docker-registry is the name of the secret which we call regcred 
 --docker-server=<your-registry-server>  docker.io
 --docker-username=<your-name>  mylandmarktech
 --docker-password=<your-pword>   admin123
 --docker-email=<your-email>     ********************************can enter email but without email it will work

kubectl create secret docker-registry dockerhublogin \             **************      we called it dockerhublogin
    --docker-server=docker.io --docker-username=mylandmarktech \
    --docker-password=admin123  

ubuntu@master:~$ kubectl get secret
and now i can see the secret    .... now i can pull images
ubuntu@master:~$    kubectl describe secret dockerhublogin
i can also dercribe the secret



KUB 5 ... CLASS34

kubectl delete rs --all
kubectl delete svc --all
kubectl delete all -all

kubectl get ds       GET Daemon set

TAINTING NODE
ubuntu@master:~$ kubectl taint nodes node1 key1=value1:NoSchedule ...... am  tainting this node wit no schedule which means pod cannot be scheduled on the node  ...1:35:55
for  a pod to be scheduled on the tainted node we nid to add tolerations in the spec:



KUB 6 ... CLASS34
Deployment 

kubectl get deploy 
ubuntu@master:~ kubectl describe deploy   ..... we can see 1replica created and strategy type: RollingUpdate
ubuntu@master:~ kubectl get svc........we can see the appsvc service routing service to the backend application
and we can access the appl online 
ubuntu@master:~ kubectl scale deployment myapp --replicas 2    


kubectl scale deployment <deploymentName> --replicas <noOfReplicas>
kubectl scale deployment myapp --replicas 2    



# Create Deployment
kubectl create deployment <deployment-Name> --image=<Container-Image>
kubectl create deployment my-first-deployment --image=mylandmarktech/hello

##### but since we are using apply:  ** i bliv it means using declarative approach ie manifest file
kubectl apply -f deploy/app.yml  

# Verify Deployment
kubectl get deployments
kubectl get deploy 

# Describe Deployment
kubectl describe deployment <deployment-name>
kubectl describe deploy deploymentname    

# Verify ReplicaSet
kubectl get rs

# Verify Pod
kubectl get po

Scaling a Deployment
====================
# Scale Up the Deployment
kubectl scale --replicas=20 deployment/<Deployment-Name>
kubectl scale --replicas=20 deployment/myapp 

# Verify Deployment
kubectl get deploy

# Verify ReplicaSet
kubectl get rs

# Verify Pods
kubectl get po

# Scale Down the Deployment
kubectl scale --replicas=2 deployment/myapp  
kubectl get deploy


# Update Deployment -uusing set image  SHOULD WORK NOW
kubectl set image deploy Deployment-Name> <Container-Name>=<Container-Image> --record=true
kubectl set image deploy web helloworld=mylandmarktech/hello:2 --record=true

Rollback to previous version
============================
# Undo Deployment
kubectl rollout undo deployment/web  

# List Deployment Rollout History
kubectl rollout history deployment/web  


KUB 7b
AUTOSCALING
kubectl top pods    : to knw  hw much the pods are consuming , but we dnt hv any operator in aws that is able to check hw much resources our pods are consuming
kubectl top nodes  

to check if our metrics server is running;
ubuntu@master:  kubectl get po -A
********TO check the metrics of our pod:
ubuntu@master: kubectl top po 

18:36****************so all of this hv been created,der is s deployment for our metric server n this metrics server is functional and and it has been
deployed such that it is able to get into my cluster, we hv given him the permission using RBAC , we are permiting metric server to check all our node, all 
our pod and report the metrics.. so it can gather metrics and if u lok at some of the objects eployed, we v stuff like metric server can check ur node on 
yr pod 


         
                                         CREATE/ GENERATE A LOAD

TO CREATE A LOAD:
-# Create temp POD using below command interatively and increase the 
-# load on demo app by accessing the service.

creatin the pod in interative mode:
ubuntu@master:~$ kubectl run -i --tty load-generator --rm  --image=busybox /bin/sh
If you dnt see  a command prompt, try pressing enter
/#
......the pod has been created, w ewnt to access d service so that we can generate load on this pod

-# Access the service to increase the load.
/# while true; do wget -q -O- http://hpaclusterservice; done     (we ar executin a why lo...**** idnt knw what he said ..
**********.... load is been generted     (it was printing ...OK! OK!)
min replica is 2, max is 5  and now we hv 3replicas ... the replica was created tru an automated process,  this entire process was automated, load has been 
genertad, this is a test appl tha k8 provide for u to just run some testing on it.... so tk note thia ia a very imp aspect


KUB 10&11


                          OPTIONS FOR CREATING  CONFIGMAP:
1)Create ConfigMap Using Command:
  kubectl create configmap springappconfig --from-literal=db-username=devdb 
  kubectl create configmap springappconfig --from-literal=db-hostname=mongosvc 

2)
Create ConfigMap Using files/declarative approach


  OPTIONS FOR CREATING SECRET
***me
   1)Secret Using Command: 
kubectl create secret generic springappsecret --from-literal=mongodbpassword=devdb@123 

2) Create Secret Using files/declarative approach



                              GREPING FOR KUBERNETES RESOURCES
1)kubectl api-resources                         15.16
kubectl api-resources | grep -i configmap           .... to get a particular api version resource, to get extract it from this file, i can pipe it & grep 
                          this can be used for any kubernetes resource  

2) To grep for replica set
kubectl api-resources | grep -i rs



 KUB 12 KOPS

KOPS COMANDS
***kops doesnt have any commands perculiar to kops



KUB 13, EKS
 commands: to create cluster 
      aws eks create-cluster  
      eksctl create-cluster 

      aws s3 ls 
      aws eks list-clusters 



   KUB 14
 helm commands:
helm create myapp    = renders/creates manifest files/(helm charts)
helm install         =# will deploy applications
helm uninstall       =# will undeploy applications
helm upgrade   =# will rollout new versions deployments of applications
helm ls    =# List deployments


                                                      
helm repo ls                            ************to show our helm repositories
we have some helm repositories we can add
helm repo rm nginx
helm search repo nginx  # searches number of deploys/ we can check the  repo to see the chart that are in the repository
helm template nginx-stable/nginx-ingress    # review charts
helm show values nginx/nginx-ingress   # show values/varaiables/ we can check the default configuration in this repository by executing 
helm repo update
this wil get the latest version



KUB 16

What problems have you encountered applying kubernetes in environment?
we kn the k8 mg8 containerized appl, if ders a problem in the app 
How can you troubleshoot application related issues in kubernetes??
our appl are running in pods so if ders a problem, we v a few things we can do , we also saw dat when it comes to docker 
now if u look at k8 and docker, if ders a problem in doker in our container we can run the below , also for k8 we run the command below
kubernetes manages containerised applications:
  kubernetes                                                    docker    :
  kubectl get pods                                          docker ps or docker ps -a      
  kubectl describe pods podName                             docker inspect containerName/ID  
  kubectl get svc/service  
  kubectl get endpoint/ep  
  kubectl logs podName                                        docker logs containerName/ID 
  kubectl exec podName  
exec to execute command inside the pod ..... 24:00                       docker exec containerName/id 
  kubectl top podName                                            docker stats/top   
we can also pipe n grep for errors
kubectl logs app-(app name) | gre errors


#############more xplanation  .................13:05
kubectl get po 
he tried to access his kops cl8 bt it didnt wrk so  he said 
when we v dis rror msg   to get it fixed we go to our kops cl8 setup n export the kube config file that is the file we used for kops inatallation
kops export kubecfg $NAME  --admin
then run 
kubectl get pod 
so if ders a problmr in our appl we can run that and we can also describe the pod 
kubectl describe po (pod name)

 
 we can also get logs for the appl
kubectl logs app-(app name) | gre errors
if ders an error the error msg is able to tell us 


# error converting YAML to json
=============================

k8 manifest file can be written in json or yaml
bt when u run kubectl apply, it has to use the file 
e.g   ............. this is an error bc we dnt hv any kind as devops
kind: Devops
apiVersion: PODS    
metadata  
spec
kubectl api-resources | grep devops  
but no result
 bt grep for pod n we v result
kubectl api-resources | grep i pod



    

                                                  RANCHER
sudo docker logs  container-id  2>&1 | grep "Bootstrap Password:"
sudo docker logs  b3e4c58c646c  2>&1 | grep "Bootstrap Password:"
b3e4c58c646c



                          TERRAFORM
VIDEO1

terraform --version to know the terraform version

terraform init
terraform validate
terraform plan
terraform apply
terraform refresh
Destroy the infrastructure and all resources
terraform import
terraform taint
terraform fmt
terraform console

terfrm apply -auto-approve
**************if u dnt wnat to type yes , each time you run terfrm apply then u can automate it
especially when u run pipelines, u dnt wnt trfrm to stop, to interrupt , so that u enter yes to confrim, so u do auto approve


video 2

terfrm state list shows hw many resources i hv captured in my state file 


CLEAN UP     *** i got this frm the terfrm repo in landmark github
 Terraform Destroy
terraform plan -destroy  # You can view destroy plan using this command
terraform destroy

# Clean-Up Files
rm -rf .terraform*
rm -rf terraform.tfstate*

terfrm state list    ... shows all your infrastructure
terfrm state show   .. shows evrytin in the state file
if u want a specific thing frm the state file  , u run terfrm state show and the resource address


terrafrm destroy/ terfrm auto destroy
 terrafrm destroy -target=aws_s3_bucket.dev_env      .... to destroy the targeted resource
its gives u the destroy plan but if i use auto destroy, it will automatically destroy it
now its destroyed 
 
therfor if u cahnge ur provider version  or plugging but u hv run terfrm init before, to prevent it from failing u have to upgrade to upgrade ur pluggins ,

                                         MANAGING/UPGRADING PROVIDER PLUGGINS/VERSION
 run terfrm init -upgrade
therfor if u cahnge ur provider version  or plugging but u hv run terfrm init before, to prevent it from failing u have to upgrade to upgrade ur pluggins ,


PASSING VARIABLES AS A FILE  (the file must end with 'tfvars', pass it on the CLI uing '-var-file= 'the file name')
1) Named files
variable files are files that  starts with any name but ends with 'tf.vars , any file that has this convention u v to pass it on the CLI uing '-var-file=
eg terfrm plan -var-file=prod.tfvars' 
 terafrm apply -var-file=foo.tfvars-var-file=bar.tvars), ill lookout for this command, its frm the terrfrm repo in github

****BUT
2) TERRAFORM.tfvars/ AUTO FILE
this type of file is automatically loaded u dnt hv to pass it (the file name)on the command line , ie to deploy it, you
just run 'terfrm plan' without supplying the values.... you dnt have to run; 'terfrm plan -var-file=prod.tfvars' 





TERFRM4
part.module      ***HOW TO USE FILE FUNCTION/REFER TO THE PATH TO A FILE
eg a key file
we are using a file , when you read at the function, u hv to give it a path to where the
file is, it has to be either relative or absolute path, file function wil nt extrapolate like variables



thers a terfr command to taint a resource
  terraform taint 
terraform taint aws_instance.my_instance              .... so if youv created such an instance ,its in your statefile ,bt u wnat to terminate it or to dstroy it 
you can taint it, tainting just means u acn just mark it for destruction and when nxt you run terfrm aply, it wil automatically terminate it bc the resource is tainted
 


 terraform state pull ......... QUESTION 
1) IN the event that i start working in a cop and the have their statefile in the backend, and i wnat to start working in collaboration with th eother team, 
how do i migrate it to my own local env so that i can work with the statefile that is already in existence

   ANS:
that will not be the case because once you pull it , we only have 1 ststefile  
normally they prevent you form pulling unless you are pulling it and pushing it back
but theres a command for that :
 terraform state pull

 ********  it pulled our stsefile and you can tell by the lineage number , it doesnt change 
******* so if i wanted to inspect the ststefile, like what is there , then i can easily do a state pull
 then look at it, work on it then i can do a state push to push it back but i think its asking for a path  or u can use -force



 but basically you can use terfform state commands  
      terrafrm state -h
it shows you the sub commands, how to manipulate terfrrm state
 the state commands are only used when you are working with a statefile, but the statefile is very sensitive so you need to know what your doing bc if u mess up/corrupt 
the staefile then your entire infrastructure is corrupted bc the ststefile can no longer be used to compare what is desired and what is present
therefore thats why if you want to do anything on the statefile use the state commands , you dnt go on the statefile itself and try to edit/change it
if i need to remove a data source instaed of goin on the statefile to delete it ill use a state remove

subcommands;
list
mv
pull
push
replace-provider
rm
show


  *** STATE LOCKING/LOCKING THE STATE FILE
dynamond db table to lock our ststefile in the s3 bucket





                         ANSIBLE

VIDEO 1; CLASS 33
bc i did 'su -ansible, i exited the home of ubuntu and now am in the home of ansible 



VIDEO2; CLass 33

TO ping all the servers: 
ansible@ip-172-31-27-28:  $ ansible all -m ping 

TO PING THE SERVERS in a particular grp:  group name: web
ansible@ip-172-31-27-28:  $ ansible web -m ping 

COMMUNICATING WITH THE USER mark    -u  option  (user)
   ansible@ip-172-31-27-28   ansible db -m ping -u mark -k 
 hv nt exchange any key with mark so i hv to pass a - k option 


                             CREATING A USER
LETS create the user called mark
 ansible@ip172-31-19-131  $ sudo adduser mark
 new passwrd
retype password   : mark
   
ansible@ip172-31-19-131     $ cat /etc/passwd
now i hv a user called mark




                                          ESTABLISHING A PASSWORD SSH CONNECTION
         (-k option)       

*********** pass a -k option (small k) 
we pass this bc it prompts us for an ssh PW

  ansible@ip-172-31-27-28:  $ ansible all -k ping 
ssh password  : ansible , you cant see it i typed it 


CREATING HOST VARIABLE & SPECIFYING A USER TO CONNECT TO IN THE HOST FILE
 172.31.27.37  ansible_ssh_pass=ansible
172.31.19.131   ansible_ssh_pass=mark ansible_ssh_user=mark


                             TO CREATE A FILE 
module
$ ansible all -m file -a "path=test.txt state=touch"   **** command is 'touch' & the file name is 'test'
-a , means what argument am i passing, i want to create a file, am using -m to specify its a file module then what are the arguments,

while creating a dir , state = directory


PASSWORD-LESS  Authentication(This is with SSH Keys)
 ansible@ip-172-31-27-28: ssh-keygen
key is generated



 ADHOC COMMAND

This command will only have two parameters,
the group / target of a host that you want to perform the task and
the Ansible module to run.


this is default
********** ALL ansible command , for you to invoke wll start with the key word ansble
ansible all -m ping -u  
but the parameters thatu  are passing is your target which is your group (db, bc i hv a grp called db i  created in my host file), it could be an ip address or & the module (ping)
ansible 172.19.16.16    -    ** i could pass an ip addresss , that becomes my target 
ansible 172.19.16.16    -m ping                   *********** i can  passa amodule, mayb i wnat to ping that server 
ansible 172.19.16.16 -m  file     ***************   i can pass a file module
ansible 172.19.16.16  -m yum                  *********** mayb i want to install a package, i acn use a yum module
these are the 2parameters that an adhoc command expects 

all these are modules that we will see shortly, we will see what mosule sare 
but those are the 2 expected parameters


The basic syntax of an Ad-hoc command is:
$ ansible [ -i inventory_file ] server1:server2:Group1:Group2 -m [-a arguments]

bc now am nt using the default host , am using an inventory, a file that  has ip adresses of the server
or i can pass them like this, seperate them with semi colums  ; server1:server2:Group1:Group2 -m [-a arguments
-m  is for my module 

ARGUMENTS
- a is  for argument  , this just means if i passs a module like a file  what do i want to do, i can pass some commands 
so arguments are commands am passing on that particular module 


To list all available modules:
$ ansible-doc -l
,, we can see all the modules you can use/reference inside of the doc
a lot of modules to do diff things


COPY MODULE
a) From ansible control node to remote node
$ ansible group1 -m copy -a "src=/source/file/path dest=/dest/location"

b) From one location in remote node to another location in remote node
$ ansible db -m copy -a “src=/source/file/path dest=/dest/location remote_src=yes"

c) Change permission of a file in a remote node
$ ansible db -m file -a "dest=/home/ansible/hosts mode=0664"

FETCH MODULE
a) Will copy the files with a directory structure.
$ ansible all -m fetch -a "src=./hosts dest=./"

b)
To fetch the file without a directory structure, use the flat=yes option
$ ansible all -m fetch -a "src=./hosts dest=./ flat=yes"



                  ViDEO 2;Class34
1. Ansible commands:  
    ansible hosts -m module -a "df -f"
      -m=modules
      -a=arguements
  hosts: db / web / app / localhost / all     
      ansible all -m ping
      ansible localhost -m ping

 ansible web -m command -a "df -h"
 ansible localhost -m command -a "df -h"


 
to delete user   sudo userdel ansible 



