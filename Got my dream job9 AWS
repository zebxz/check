

LINUX , scripting, git , maven, tomat/ngnix tomcat, sonar, nexus, jenkins , aws, docker, k8, terraform, ansible, k8/helm 
In our env, we use LINUX OS for file,process,package,security mgt, GIT FOR VERSIONING, MAVEN FOR BUILD, JENKINS automates the end to end process, 
AWS for cloud computing services/resources, DOCKER for containerization, KUBERNETES for 










AWS COVERS 2 THINGS: .. so u can finish this course and work as any of this 
Cloud Engineering  
Infrastructure Engineering
so when we ar managing this resources thses ar all the infrat that nids to be managed:servers,
  - storage,  - databases, - networking,- software,- analytics, - and more
in managing infrastruture, we can :Infrastructure MGT [ create, view, update, delete, modify, grant access ] 
and dis can be done using GUI ... E.g chnaging the name of my server , vpc .. we ar managing dis frm the console n u realise when u do dis thers high possiblity of error
so apart frm using console we can use files 


***AWS8B***
2:07. one limitation of ntwrk LB is that it doesnt allow more than one traget grps to be added to a particular LB




****************************    SUMMARIZED FOR INTERVIEW********************************


*** NACL.. controls inbount and outbound traffic into the vpc
**NAT GATEWAY, its attached to the public subnet,allows the private subnet to get access to the internet but does nt allow traffic into the private subnet
         in the private subnet we place the appservers.
**IGW...   To ensure comunication btw the servers by creating a route table, wich detr hw service is routed from one subnet to d oda
IGW is attached to the vpc & then to the pub route table (so the pub route table ahs access to the internet) then the pub route table is attached to
the pub subnet. .. IGW is not attached to the private subnet 
in the public subnet we place the webservers, jumperservers & lb & for traffic to get to our appservers it has to go tru the jumpserver.
*********************************




in my env, AWS is our Cloud Service Provider we use aws services based on the needs of the company  
diff coy wil use asw services based on task they ar trying to accomplish
For our cloud solution which is Based on the need of our company , we thank advantage of the diff computing service/resources provided by AWS including; 
ec2 / eks elastic kubernetics serv / ecs elastic container services / IAM, identity & access mgt / route53 / elb , AWS STORAGE SOLUTION like ebs elastic block storage, and using the root file system we can create mount point and attach 
block storage to our servers to expand/increase our storage size as required (from my command line i can type "list block command" where we hv our root file system.), also; we hv / efs ie elastic file storage,
/S3 bucket ie object storage,data can be stored in buckets
IF YOU CREATE FILES AND and store it in EFS/EBS, the files cannot just become accessible online  but with s3, i can store a file and its immediately accesible by anybody around the world.
****ignore*** but s3 BUCKET CANT BE CREATED IN SUBNET (Because its a regional service, whose name must be globally unique.
Also we have /SHARED Storage/ LAMBA FUNCTIONS/
DISASTER RECOVERY; of which we carried out a project as a diaster recovery measure , where we have our database servers running in account one but backedup in account 2 ( which is our diaster recovery 
account, so our database servers are backedup incase thers a disaster.
 So what we did is We created a snapshot lifecycle policy using Lambda  which creates sonapshots from our databases from account1 in account2
snapshot is a replica of your database, its a backup therefore if account1 is hacked, we already hv everything in account2 so we are able to recover from account2 
SO WIT THE HELP OF LAMBDA & snapshot lifecycle policy, this entire process was automated
so am proud of this project
Also for our application servers wher applications ar been deployed  we v to do load balancing to we ensure that traffic is routed appriopriately, with ELB/NLB/ALB
WE require a software wich helps us achieve load balacing with relative like ngnix
LB is gud bc it does health check, security perimeter, accepts traffic or reject traffic & it spans accross an entire region cos with the help of route53, we can route to multiple regions & that means high availability is achieved.
Furthermore, security is inherent in our environment , WE DNT ALLOW DIRECT acces in our db server, if u wnt to acces it u v to go tru our 
jump sevrer. traffic goes to the jummpsever bc it has a security grp dat is permitting the trafic, it allows trafic on port22 so  in d
 SG 22 is open for members of the team & my vpc 10.0.0.0/24,i.e my ip. so my ip & port22 ar d two access  
the jumpserver acts as the entry point when it comes to ssh access,  frm d jump server u can access the app/ db servers,so any server in the vpc can be accessed
via the jump server
for more security, our vpc has some firewall ,2 types of firewall,
the 1st is the router for routing, wich permits traffic to be routed to the subnet bc if thers no route table permiting routing, the traffic wont happen
SO inside the vpc l create route tables, route table1 for the private subnet to support local traffic within my vpc, then route table2, i hv a public subnet 
wich is wher i place resources wich can be acessed externaly like the webserver,jumpsersers,lb & in the public subnet i also created the NAT gateway to
permit oneway internet traffic ie traffic can only go out but not into(the private subnet),therefore the app server can access internet externally, & this
is bc i decide that we can recieve traffic frm the internet but it can only happen frm/using the nAT gateway. 
the route table2 is permitting traffic frm anywher(ie 0.0.0/0), both local& traffic frm the internet..(I bliv that way endusers can access the resources in 
the public subnet)
Also with the help of internet gateway, i can ensure comunication btw the servers by creating a route table, wich detr hw service is routed from one subnet to d oda
 inside our vpc.  it will allow internet to flow into the vpc & it wil allow exteral traffic so if we wnt to acess resourcs out of our vpc, out of our,
netwrk , we nid to hv internet , using IGW... Its all about modifying the route tables accordingly.
the 2nd firewall on our vpc is the one that stands infront of the subnet, like a gateman,called netwk acess control list nACL... 
in naCL, we can create some rule e.g open port80 for inbound rules &for outbound open port80 aswell, on my NACL, trafic frm enduser can get to my subnet.
for  trafic to get to the webserver ,in front of my webserver thers another layer of security ie security group (this is also a firewall)therfore i 
also have to open (port80 , 443 )in the webserver security grp
****** in  all we hv 2 security parameter
the 1st is the router for routing, wich permits traffic to be routed to the subnet bc if thers no route table permiting routing the traffic wont happen
the 2nd is the firewall wich has 2layers of security,, security at the subnet level & security at the server level
As an additional layer of security, we use the IAM = identity and access mgt, for authentication & authorization.
also we can grant & restrict permission based on the based on the role of each member, i can use IAM roles, these are policies/permissions that can be 
attcahed to another aws resource..[ec2 Instances, eks, ecs,etc.]  
 Finally; SCALING IS VERY IMP BC BIZ NIDS CHANGES CONSTANTLY
So rather than manually adding some number of servers when there is a spike & removing severs when there is a down time. we automate the process, using amazon
Ec2 Auto Scaling, which ensures that for high availability,we always have the right number of healthy instances at all times & dynamically increase & decrease 
capacity as needed.our appl always has the right amount of capacity to handle the current traffic demand,  & this is cost effective because you only pay for
the instances you use & can terminated them when nt needed

****** so these are some of the ways we ultilize AWS resources based on the needs of our company.

*** showing us using the Udemy video***** 3.00.00 *****
let me show u guys what is included in the Awssolution architect course that you guys already have but we may nt hv gone deep into it bc this is not a full Aws 
course but if you look at intro to Aws solution architect, getting atarted with aws, IAM, EKS etc. we will also go tru EKS in k8
 you  can buy the video & go tru the services as well just to expand your understnading AWS services

****3.03.25 **** i agree with you guys that the information is much, there is more that you need to know, do i need to know all of these at this time? ofcourse
just make sure that as you are progressing, th ethings that we have highlighted you are able to add them periodically in your tool set.
but the Aws service sthat we hv covered, if i wewre u what i will do is go the Aws  sloution course, go can jsut go tru some of the services course again ie
what we have done already b cthose services is what we are going ot be using &what we use in our project
*****there are multiple aws services that we have seen no company uses all of them, bc you are not goin out there to interview as somebody who is writing 
an AWs certication exam & thats why what i will tell you guys is that you dnt need to ak any exam to get hired bc you deployed as someone who has been
working & those working dont have time to write exams. if you are are a student you should hav ebeen writing exams, most of the engr working out der if ther
is somt new the company invites expert from AWs to cm indicate & elborate on the new updates. 


********** AWS8B*****2:07. one limitation of ntwrk LB is that it doesnt allow more than one traget grps to be added to a particular LB
****** i bliv*** this will mean, thefore we use ALB, (application load balancer)




****************************************************** ENDS***************************************************************



AWS1
cloud computing, Cloud Service Models/ CSP; CLOUD SERVICE PROVIDERS, ADVANTAGES OF USING THE CLOUD 1:55:00 REQUIREMENTS OF owning a data center

Oluwafemi James
SRE || DevOps Engineer || Platform Engineer|| 
Cloud Engineer|| Kubernetes Engineer || BSc.


 
******from***** AWS10&11  *****    What is Cloud Computing ?
Cloud computing is the delivery of computing services—including 

cloud computing is very imp bc COMPANIES ar migrating very quick &fast from on-prem to cloud we'l be looking at hw aws helps us to manage our infrastructure

with CSP (Cloud Service Providers) like aws, GCP and azure we can pay only for used computing Services

userData - This is a script that can run while creating/launching the server  


, we'l be looking at hw aws helps us to manage our infrastructure
-- 1:28:30 .for our application to be accesed by cx,it nids to be hosted on some computer systems& for that to happen we nid an hardware,on the hardware the OS is instaled
we nid a piece of storage for our database & our appl is running, so we nid to create a data center
Datacenter:
   1. Applications [80%]   = 500MB    #### what is very imp to us is the appl, 1:34:05 our appl can only be held if we hv a piece of storage wich is adequate
   2. Database-storage     = 25000MB = 25GB   
   3. OS  -                = 5000MB  = 10GB .. 1:35:329 ubuntu is 4.6GB 
   4. HardWare
    a computer system comes wit a hardware system, an OS, a storage,IF the OS requires 500mb, we nid a disk space that has up to the volume of 500mb

###### hw do we deploy in tomcat, we copy to webapps .. the tomcat server nids to hv sufficient storage for us deploy the appl successfully
   tomcat = cp target/app.war  /opt/tomcat9/webapps/


Amaka Nwosu  wants to b supplying some financial solutions to cx around the world, for her to start dis coy traditioanlly,she has to buy a coy wit the ryt OS&
storage b4 she can start running her application... this is a challenge so we hv cloud solutions
         AmakaTech
           ---->  WE hv cloud solutions, wit cloud services like aws, we can pay only for what we use

with CSP (Cloud Service Providers) like aws, GCP and azure we can pay only for used computing Services.
Cloud Service Providers    - CSP =e.g  AWS / GCP / AZURE / alibaba/ etc.    
the main cloud service providers :AWS - Amazon Web Services , GCP - Google Cloud platform), AZURE Cloud
 Cloud Service Providers - CSP = AWS / GCP / AZURE 
they Provide computing services / resources like servers, network, storage, security, etc. over the internet from their Datacenters   
   pa

with CSP, we can reduce cost by:
  pay-as-you-go 
  pay-as-you-grow  
  pay-as-you-use

on-prem Datacenter:
     data centers, Own and manage by the user/client  .. #if Amaka acquires everytin hersef, that becomes an on-prem infrastructure bt we can hv some of this services provided to us by
    a cloud provider. 1:40 :48


REQUIREMENTS OF owning a data center:
Dedicated  space
ultra fast internet speed (in todays term)
High  bandwidth superfast INTERNET


 understanding cloud computing is very imp bc COMPANIES ar migrating very quick &fast from on-prem to cloud 
Cloud Service Models:
=====================
IaaS -- Infrastructure as a service  :   has components that is managed by the vendors & managed by us 
e.g ec2 instance  - ec2 
  - SonarQube

PaaS--  Platform  as a service  : aws container registry, aws kubernetes solution
  ECR / EKS / ECS / 




AWS 2
AWS Global Infrastructure; ADVANTAGES OF PLACING MY SERVERS IN DIFF AZS, EXAMPLES OF AWS SERVICES, WHAT TO CONSIDER BEFORE CREATING/HOSTING RESOURCES IN AWS & BEFORE CHOOSING A REGION IN AWS, EC2-Basics, EC2 INSTANCE PUURCHASE OPTION, 
INSTALLING WEBSERVER USING USERDATA ie script, INSTALL WEBSERVER, INF ABOUT METADATA:  HOW ARE WE CHARGED FOR EC2.  TRANSFERRING FILES OVER THE INTERNET, VPC


The AWS Cloud spans 102 Availability Zones within 32 geographic regions around the world, 
with announced plans for 12 more Availability Zones and 4 more AWS Regions in Canada,
Malaysia, New Zealand, and Thailand

what is a region? .... Region  are Logical names  =   
Availability ZONES - AZs   = Physical locations comprising of 
                            one or more ISOLATED Datacenters  

 Regions: us-east-1  = N-Virginia, us-east-2  = Ohio, us-west-1  = N. California , us-west-2  is  Oregon 


Regions: us-east-1  = N-Virginia, us-east-2  = Ohio, us-west-1  = N. California,   us-west-2  is  Oregon 

Regions covers: USA, Canada, Americas, Europe, Africa, Asia, Middle East, Australia, 

Can a Lagos based company serve clients around the world with the help AWS ? yes  

in each regon there are diff azs, the azs are engineered to be independent from each other , e.g us east1a is located independently from us east1b

Regions: us-east-1  = N-Virginia, there are 6 azs in this region
  Availability ZONES :  
    us-east-1a --- Arlington
        jenkins-master            9:20 place my jenkins servers in diff az

    us-east-1b --- Fairfax      us-east-1c --- Loudoun 
      jenkins-slave1               jenkins-slave2


11:00 ADVANTAGES OF PLACING MY SERVERS IN DIFF AZS
1) Availability zones - AZs are engineered to be independent from each other
2) A disaster in one cannot/shouldn't affect another AZ.  
   Floods
   earthquake 
   Network failure  
   wildfire


                EXAMPLES OF AWS SERVICES
 ec2 / efs elastic file sys / eks elastic kubernetics serv / ecs elastic container services / iam, identity & access mgt / route53 / elb  


            WHAT TO CONSIDER BEFORE CREATING/HOSTING RESOURCES IN AWS & BEFORE CHOOSING A REGION IN AWS

Regions covers: USA, Canada, Americas, Europe, Africa, Asia, Middle East,   
                Australia, 

Can a Lagos based company serve clients around the world with the help AWS ? yes  
for this to happen, This company will need server resources/services [ec2] from AWS
This company will need AWS container resources/services [eks, ecs, ecr, ] 
NB: Not all aws services are found in all aws regions.


1)Availability: elastic cloud compute [ec2]   Not all aws services are found in all aws regions, so we hv to mk sure its avail in the region b4 we launch it
              elastic kubernetes service = EKS 

2) High Availability:  having multiple servers for your applicaction to avoid application outage
  DEPLOY AN Application server  
   1 application Server  : architecture1  .... you can be a cloud architect, can advice the coy that we cannot hv one app server, so lets hv more than 1 app servers
   4 application Servers : architecture2

hIGH availability can be ACHIEVED BY:
      1. Multiple instances of the servers -- 4 = us-east-1a  
      2. Deploy using Multi AZs = us-east-1a, us-east-1b, us-east-1c, us-east-1f  
      3. Deploy using Multi Regions  = us-east-1, VIRGINIA, us-east-2, OHIO, af-west-1,   
      4. Multi-cloud -- AWS/GCP/AZURE

 Cloud Service Providers = 

3) Latency: -- TIME taken TO ACCESS A SERVER/application 
   us-east-2 = Ohio     --- 200ms to access    1
   us-west-2 = Oregon   --- 100ms to access    2   .. THE best
   af-west-1 = CapeTown  -- 500ms to access    3  

4) cost:                          latency              base on cost  
   us-east-2 = Ohio     --- 200ms to access    1    $4/hr  THE BEST
   us-west-2 = Oregon   --- 100ms to access    2    $8/hr 
   af-west-1 = CapeTown  -- 500ms to access    3    $6/hr 

5) customer Location: IF MY cx AR IN LOndon i will place resources to where the cx are
   Ohio           = us-east-2 = Ohio  
   London         = eu-west-2 = London 

6)Complaince / Regulations []: this cud restrict a coy,, e.g in china , chinese based coys ar adv to only choose datacenters within AS/china,, so u cant choose a dif location
when the govt regulations doesnt permit it

7)Security:
  Mosco /  
     

EC2-Basics
==========
  Basic Computer vs      aws-EC2 :
  OS     ----            AMI (OS + Additional Softwares) 
  Hard Drive             EBS (Elastic Block Store)\
  RAM                    RAM
  CPUs[1, 2, 16 core]    Instance type[t2.mirco, t2.medium]
  Network CARD           IP Addressing 
  Firewall               Security Groups

AMI = amazon machine image 

######                                              EC2 INSTANCE PUURCHASE OPTION, HOW ARE WE CHARGED FOR EC2.
  on-demand instances   = most expensive and very flexible, servers can be created & deleted any time, u pay for services whrn servers ar running
           this is gud for studies bc its d only option that supports for free tier bc u ar always expected to terminate ur instabce               studies 

  Reserved instances    =  ,, #####read note, u reserve inatance & u dnt use it u stil pay 4 it, cx can ask for instances to be reserved
this is gud for deploying to prodution    production 
  
spot instances - Bids =   AWS,, will provide based on avail instances so cx wil place a bid after AWS has placed the offer price
this is gud for testing, like high voltage application

AMI = amazon machine image 

                                       
                                                       HOW ARE WE CHARGED FOR EC2.
53:00 instance type is the power of the instance, the specks

e.g  Laptop1: 24 CORES / i9 / 4TB SSD / RAM 128GB  = $9,000 
  Laptop2: 2 CORES / i3 / 1TB HDD   / 8GB       = $700 

AMI = amazon machine image 
      comprises of the OS and other softwares and settings  
  Linux [redhat / centOS / ubuntu / amazonLinux2 / Debian 11 /etc
          Amazon Linux 2 / ]  
  WINDOWS

58:00####things to consider b4 choosing an AMI, THERE ar 3option to choose from
what is in the:
1)Community AMIs: comprises mostly the OS only  
                Generally free 

2)Marketplace AMIs: comprises of the OS and other Licence Softwares 
   splunk -- Amazon Linux 2 + splunk Softwares    
   openvpn --- Ubuntu 22.04.1 LTS + 
               Ubuntu 18 LTS

10GB/S   = 10,000MB/S  

3) my AMI = Golden AMIs  :
         
1:01:42 splunk enterprise is used to monitor our servers

1:07:14 t3.2xlarge up to 5 gitabit per sec for band width i.e the internet speed
   vCPUs          RAM      Bandwidth speed  
  c5.metal  96     x86_64  192G  - - 25 Gigabit/sec  
  t2.micro  1      x86_64  1G    - - Low to Moderate

security group is firewALL in front of the server
james an admin/engineer wil access/launch the server by ssh on port 22, while 
paul nids to acces some web content on the server by using http on port 80
for any of them to access this server on our firewall we hv to open http 80 and ssh22  

storage is called ebs volume, after security groups, we configure stored
the speed for hdd is 10 times slowervthan ssd
1:19:25  for volume type, magnetic is like a floppy disk wich use to be used many yrs ago, we dnt nid it,,, so we go for general purpose ssd .. gp3
then launch the instance


INF ABOUT METADATA:  
Metadata: Data about data/  data about the instance
- id         = i-08b0ba39aca738105, privateIP  = 172.31.27.50, publicIP   = 54.187.238.209, DNS-private= ip-172-31-27-50.us-west-2.compute.internal



When we stop a server the private-IP/DNS address cannot changed at restart 
When we stop a server the public-IP address will changed at restart ,,bc the ip address is released once we stop the server
  use an elasticIP to maintain a static public-IP even after restart 


########Ticket044 = Create a and install a webserver in aws...... webapp can be used to serve some web content
with the help of ec2 intance we are able to create servers and connect to them


userData - This is a script that can run while creating/launching the server  




  in answer someones' question as seen below **********   TRANSFERRING FILES OVER THE INTERNET      
therfore i can transfer files over the internet that is found in a particlar server, when a file is found in my server it is diff for individuals to be ble to access the file 
we hv http & https 
 31.00 after installing webserver were endusers able to acces my text  .. yes ( on the internet, using the ip address we could see "Devops is good )

HTTP = hyper text transfer protocol      i can transfer files over the internet in the webserver in CLI so long as the file is in  ( i bliv my server)    
34:00  i can transfer files over the internet in the webserver in CLI, E.G redirecting contents frm one file to another, or changing or adding to my web content
HTTPS = hyper text transfer protocol Secured   = listens on port 443  


the diff btw the http & the htp secured protocol 

http://35.92.51.2/    
https://mylandmarktech.com/      
              http           https  
Data          insecured      secured  ... secured transmission of data
Transfer      clear text,  data is transfferred in clear text     encrypted  .... WHEN IT GETS to the user its is decrypted
certificate   not required   required    
portNumber    80             443  

password:  admin123,     */cxx5%%$#@!fdytdcxsfdsyfdiuoiodofsdcp  but paswd can be easily hacked ( during transmission)

   

**********************       20.36, very soon we will be doing virtual private cloud (vpc)

lets assume we hv THIS VPC called tesla vpc 
####21:00  in AWS we hv tesla vpc its a larger netwrk with 2 smaller networks (so we call this subnetworks)
sutnet1 is public  (with a webserver1) and subnet2 is private with an (app server1).... both in the same ntwrk,, for both to communicate with each oda they can use the
private ntwrk address
*26.00    ..... we hv another engr chidi in a diff ntwrk, he can access the webserver wit the webser pub ip
also if we hv another webserver2 & appserver in another netwrk, for them to communicate with appser1 & appser2,, they wil use the public ntwrk address



****35.00 we wil see the diff classif of aws RES
we hv resources that ar availa zone specific ..ie their scope is within an availa zone 
we also hv resources that their scope is regional and resources that their scope is global





AWS3

AWS STORAGE SOLUTION (THE DIFF TYPES PROVIDED ebs/efs/S3), LIST BLOCK COMMAND(root file system) Create/attached & mount ebs, creating my AMI(amazon machine image) =GOLDEN AMIS, CREATING A LIFE CYCLE FOR MY INSTANCE,
CREATE A lifE cycle TO CREATE SNAPSHOTS FOR MY JENKINS INSTANCE, EFS; file storage examples / SHARED Storage, LAMBA FUNCTIONS, DISASTER RECOVERY


There are 3 diff storage solutions; 

ebs is block /efs is file/ s3 is object storage

4.45  storage solutions:
 1) ebs volume  = Elasticblock store
       Required mounting    
       
 2) efs  volume =  Elastic file storage
       Required mounting 
       sudo yum install nfs-utils
AWS4; ********* #21:24 u nid to be authenticated/permited to write data , port 2049 must be open to write data, if port is nt open , we cant write data
when efs is created we hv to make sure we modify the security grp to permit data to be written and in all the client server we hv to open nfs port 2049

     
3)  s3 bucket   = object storage 


EBS
When a server is created, ders a piece of storage attached to it, wich is mounted on the server n its called ebs , block store n the only advantage is that the ebs is elastic, so we hv an elastic block store
 therefore if you are launching webserver2 we need this bolck storage
when we launched this webserver2 for eg, we hv a public ip address for eg , most likely its aredhat9 os, it means that this ebs is going to bbe mounted among others within a root file system., 
7.20; heres a mount point on our server
the block storage is unique, bc the ebs on webserver1 cannot be transferrd to webser2 bc they ar blocked/tied to each of the servers   

11.13,   if need be this ebs1, root file system, now this is 14G, can i decide to create another mount point? mayb i want to create anoda mount point point /app , 
yes i can create a mount mount, i can create anoda block storage here



 Root [/] directory has other sub-directories  
what are some of the sub directories we saw in the root dir when we did linux
bc we are mounting on this root file system
we have; /bin,  /home,  /etc/, /var,  /opt / ... this is a root file system
so we are creating a mount point 
for eg, i hv the ticket below 


Ticket0048:
  Create, attached & mount 5G to the /tesla directory    (assume we hv a project for tesla)
20.40  CAan we decide to have  a seperate dir , lets assume this ticket has 2types
  Create, attached & mount 7G to the /var/lib/jenkins directory   (/var/lib/jenkins is the home dir of jenkins and i can decide to create a mount point for myself)


EFS
efs : file storgae 
Amazon Elastic File System (Amazon EFS) provides a simple,
 scalable, elastic file system for general purpose 
 workloads for use with AWS Cloud services and on-premises resources.
  https://youtu.be/AvgAozsfCrY     ... to get some direct inform from aws talking abt efs

efs  volume = file storage / SHARED Storage.. can be shared by one or more srvers or devices
     Requires mounting & we can use a software like netwrk file system
     sudo yum install nfs-utils 
       sudo mount -t nfs4 -o nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport fs-0027f3e4b8f8187ee.efs.us-west-2.amazonaws.com:/ efs



exmaples of file storage 
google drive-has a file storage of 400G = legah@gmail.com  
in the drive , i have files: documents, pictures, videos 
mounted on: phones, tablets, computers  
after it is mounted, so all i nid to do is login to my email then i can access the files.... therefore it can be called a shared storage
we can snap pictures with our phone and acces the pictures on several devices due to shared directory& its possible due to elastic file system

NFS = Network file system(traditionally)  = self managed   
EFS = Elastic File system  = managed by AWS , therfore u hv more time to focus on ur applications
so nowadays managed solutions is what is driving many companies


*****************************
AWS4.., efs is also/can also be called "nfs" managed by aws called efs ***19.17
efs is a managed system bt if u dnt wnt to use efs we can also use another software system called nfs,, nfs is manged by aws  
efs &nfs are performing the same task
18:14  nfs managed by ourselves/self managed is not scalable
    (when we create an nfs server by our selves thats self-managd but when aws manages it for us its efs)



THE only diff btw EFS & NFS is , now lets assume that we hv 3dbase servers
  if we want data to persisst 
12:56 if we wnt our data to sychronizse in our 3 databases, if we wnt the data inputed by endusers to syn in all our 3db server, we can instal another server called an  
nfs server, inside it i wil instal nfs software, then in all 3databases il v nfs client installed. then ill create a mount point caled e.g/data, il mk the mount point to be 
shared to mk data to syn.. ie ill create the same mount point/dir in all 3db servers.... once its done, its my responsibility to ensure that the nfs server is up&running. so 
once data comes into any of the servers, it syn in the other servers as well. i am the one managing the nfs servers ,, bt if the nfs server goes down data wont syn any more 
this is a limited solution and is used by most coy oovertime... also if the data storage size for our mount point is 20GB,its nt scalable bc the 20GB limits our data storage 
size data,,, these are drawbacks of this system....this whole structure is self managed, it is can be called iaas , we hv see saas.,paas

18:14  nfs managed by ourselves/self managed is not scalable

18:58 but with nfs it provides paas... the structure is no longer managed by us,it is a manage platform the nfs is then replaced by efs & so we dnt need servers or masters
we only nid to cretae our efs, we dnt bother abt the mount point for the efs, bc aws in the backend ar doing the mounting for us, we  also dnt nis to bother abt the storage 
size bc it can start from 0 and it is growing, it is higly scalable, if more data is needed it increases, it increases base on our nid to inifinity

********* #21:24 u nid to be authenticated/permited to write data , port 2049 must be open to write data, if port is nt open , we cant write data
when efs is created we hv to make sure we modify the security grp to permit data to be written and in all the client server we hv to open nfs port 2049

  storage  solutions:
   1) - Elastic Block Store       ebs   = block storage   
  2)  - Elastic File system EFS / NFS= file storage
    - nfs port = 2049  

  ebs and efs required mounting   but s3 doesnt nid mounting, we use s3 for options e.g log files, images,videos
##28:00 in ebs files cannot jst become accessible online bt wit s3 i store files and its immediately accseesible by anyone around the world

when efs if created a security group is attached to it , we ar going to modify that secyrity to permit data to be written & in all the clients servers we v to open port 2049
*************************


  LAMBA FUNCTION
but the interview question is what hv you done when it comes to AWS services, thers a service in aws called lamba
Lambda functions:
=================  
  If we have upto  75% volume usage increase vol by 20%   
  
in my envi in one of my projects, i was able to use the lamba function, which was written to expand my project by 20% whenevr usage is 75% 
### 1:54so if  df -h / 100G/75G  ie avail 100 and used 75, increase by 20% --  so we then hv 120G
so we can write a lamba function to achieve this process

DIASTER RECOVERY
we can also  write a lamba function , lamba function has what is called diasaster recover
if u work for landmark and we hv aws account1, & aws account2. in account1 we hv a database servers running ,  for account 2 (diaster recovery account, for our database servers backup)
because diaster can occur , eg if someelse is able to access d email&paswd & log into aws wit root access, thers a possiblity of a disaster bc dats a serious issue bc they wil hv 
access to all my servers bt wit account 1 & account 2, our disaster recovery is accont 2, wit our database serververs running in account 1, we back the databases in accout2
by creating a snapshot lifecycle policy using Lambda





AWS4
BROAD CLASSIFICATION OF AWS RESOURCES, s3 buckets/STEPS TO CREATE S3 BUCKET, IMPORTANT TO TAKE NOTE OF IN S3; Permissions/POLICIES,
AWS ACCOUNT:Global resources  
Glacier; this is used to store archival data e.g zip files, tag file, mayb data that is no longer accessed like non critical data e.g tax docs ,, we can store them under glacier/deep
glacier

AWS 10&11  What is Cloud Computing ?
Cloud computing is the delivery of computing services—including 

1) compute
  in compute service we hv; server & serverless
   for server; we have "ec2 instances, ie your computer in the cloud, meaning that aws is providing server resources
   serverless; Lambda(run code without servers) / Beanstack / farget profile
                 Container( ECS ie elastic container service/EKS ie k8 service)
  2) storage ; EBS/ EFS/ S3
  3) databases : when we get into conatiner     = rds,relational databases e.g [ mySQL, mariaBD, posgressSQL, arura,  ], nonRDS[ dynamoDB,  ]
  4)networking :  vpc, creating private ntwrk in aws
  5)software,   to create ec2 instance we nid a sfware to create the server resources = ami, SDLC, hw to automate task in aws
  6)data anylytics    hw to analyze waht is happening in aws = CloudWatch, 
  - and more  
  - security     =aws security services 
we use aws services based on the needs of the company ,coy wil use asw services based on task they ar trying to accomplish

  Netflix = entirely run on S3  bucket, jst one service of aws is makn the coy a multi time billion coy
wit the help of cloud computing u can easily become a millionaire frm the comfort of ur room if u understand a few of these services


*********meeeeeeeeee ****we continue with s3 from video3


 S3 (Simple Storage Service):
*** 27.27... IF YOU CREATE FILES AND and store it in EFS/EBS, the files cannot just become accessible online  but with s3, i can store a file and its immediately accesible by anybody around the world
so its a very serious solution that most companies are now using it to achieve a lot, and its very good for business
meaning that by the end of this course you can use s3 to generate some income as well.



  object storage 
Highly Available, Redundant. 
Basically data loss is not possible bc
aws guarantess (99.999999999% durability, 99.9  uptime SLA)
29.20 SLA = in Service Level Agreement , aws guarantees 99.99% availability  of your data.. for all aws services, ders 99.9 assurance in terms of availabilty & security 






AWS5
to refresh my mind*****from tomcat1&2
WHAT IS WEBSERVER?    eg  nginx , apache 
A webserver is a program that uses HTTP (Hypertext Transfer Protocol) protocol to serve web content (HTML and static content) to users.
                                                                          static content & images 
Examples;
Apache HTTP server
Nginx (pronounced engine X) 
haProxy
IBM HTTP server (IHS)
Oracle iplanet web server
Internet information Server (IIS)
*******************************************************



 VPC, SUBNET/ CIDR BLOCK/ ADDRESSES, S3 BUCKET CANT BE CREATED IN SUBNET, Internet Gateway (IGW),ROUTE TABLES, NAT GATEWAY, NACL, LAUNCH JUMPSERVER, LAUNCH DBSERVER, FOR SECURITY CONNECT TO THE APP/DB SERVERS VIA THE JUMPSRVER,
LAUNCH WEBSERVER(install ngnix) 
 

when i practice ill hv to tk note of the connection btw the jumpserver & the webserver& the db/app servers (like why the diff subnets & which subnet has the IGW attached to it)
*** 1.04.44, in the diagram i see the jumpserver & the webserver in "subnet public us west-2a &  the dbserver & appserver in  "subnet2 private us-west-2b
am not sure there was a vpc peering bc thats was treated in the next videO "AWS6"


VPC
frm pg 80,    virtual private cloud

vpc is my isolated ntwrk within aws that i can control
subnets are created inside our vpc
am able to create an instance e.g a web sever in my subnet 
vpc is a regional service in aws
i can create my subnet in us west-2a  avai zone 
subnet is an avail zone resource
vpc ar global reource
its nt advisable to launch all my subnets in the same avail zones
 i needed a vpc so it can enable me to create other subnets wher i can place my resources

when i hv a vpc i hv to create a cyber block
we wnt to det hw many subnets can a vpc hv
when we created our resources wit aws it came wit a default vpc created by aws
so we hv:
aws default vpc created by aws .. its nt adviceable to launch my servers in the default
17:20 aws custom vpcs created by the user.. this has more security and more contrl over my resources
so far we hv been using default vpc, the vpc we are creating wil be a regional service


in aws we have:
1 global resources
2 regional resource
3 avail zones resource 
subnets

 AWS Regions: AZs  each region has avail zones

AWS ACCOUNT:
1. Global resources    
2. Regional  resources
     vpcs---
        aws default vpcs created by AWS 
          ec2 instances [jumpserver, appServer]
        aws CUSTOM vpcs created by the user   
          [secured and gives users more controls]  
          ec2 instances [jumpserver, appServer]    

3. Availability zones resources  
      subnets  

  AWS Regions: AZs 
    us-east-1 =6 [ us-east-1a, us-east-1b, ... us-east-1f  ]  
    us-east-2 =3, us-west-1 =3, us-west-2 =3





 SUBNET/ CIDR BLOCK/ ADDRESSES (I bliv thats like the private/public ip)

###pg 80 Subnets -200 user-defined subnets up to /16, a vpc can hv up to 200 user define subnet
the max no. of addresses a vpc is able to hv
VPC -User-defined address space up to /16 (65,536 addresses)

27:56 ###pg 83 what deters the no. of resources that can be placed within each vpc is the cidr block / the no. of addresses  a vpc can hold 

Create a VPC for paypal client with the capacity of 200 resources
29:47
Ticket0011:
  Create a VPC for paypal client with the 200 addresses   
  cidr block: has a preface wich can range from  0 - 32 

Ticket0011:
  Create a VPC for paypal client with 200 addresses in 2 subnets  


S3 BUCKET CANT BE CREATED IN SUBNET (Because its a regional service, i can create it inside my VPC)
1:03:22 my s3 bucket cannot be be created in a subnet, e.ginside us east2a subnet ..bc its a regional service whose name must be globally unique
i can create it in the us region inside my vpc e.g us east,us west   ***me***but not inside the subnet, remember subnets are created inside the vpc
****meeee***** its like the s3 can be created inside the compound but not inside the house/rooms



**online***   IGW & NAT GATEWAY
In AWS, both Internet Gateway (IGW) and NAT Gateway (NGW) are used to enable communication between instances in a Virtual Private Cloud (VPC) and external networks,
but they serve different purposes and have distinct functionalities

An Internet Gateway is a horizontally scaled, redundant, and highly available VPC component that allows resources within a VPC to communicate with the internet. 
It acts as a bridge between the VPC and the internet, enabling bidirectional communication. An IGW is essential for instances in a public subnet to access the internet and for the internet to access those instances.
The IGW translates private IP addresses within the VPC to public IP addresses.

INTERNET GATEWAY; to ensure communication btw my jumpserver & my webserver or webserver & appserver 
1:04:for e.g, if i v app server1 and app server2, to ensure comunication btw the servers, i can create a route table, wich detr hw service is routed from one subnet to d oda
 inside our vpc we nid internet gateway  it will allow internet to flow into the vpc & it wil allow exteral traffic so if we wnt to acess resourcs out of our vpc, out of our,
netwrk , we nid to hv internet , using IGW , ders a kind of internet gateway, it is associated wit our vpc.


ROUTE TABLES
1:07:00 inside the vpc we'l create route tables, route table1 for the private subnet to support local traffic within my vpc, then route table2, i hv a public subnet 
wich is wher i place resources wich can be acessed externaly & the route table2 is permitting traffic frm anywher . ie 0.0.0/0, both local& traffic frm the internet..


NAT GATEWAY
**Online**
A NAT Gateway is a Network Address Translation (NAT) service that enables instances in a private subnet to connect to the internet or other AWS services while preventing the internet from initiating connections with those instances. 
It translates the private IP addresses of instances within a private subnet to public IP addresses, allowing outbound communication
1:34:00 if my private app server is trying to access data online e.g ping google.com, il modify route table1, create a NAT gateway  to permit oneway internet traffic,therefore
the app server can access internet externally, i decide that we can recieve traffic frm the internet but can only happen frm the nAT gateway.
 the NAT will be created in the public subnet wich hv internet access,, from der, the private subnet is permitted to access internet via the NAT gateway


NACL 
***online
A Network Access Control List (NACL) is a security feature provided by Amazon Web Services (AWS) that acts as a virtual firewall for controlling inbound and outbound traffic at the subnet level within a Virtual Private Cloud (VPC). 
NACLs provide an additional layer of security to your VPC by allowing or denying specific traffic based on defined rules.
1:12:24 vpc has some firewall ,2 types of firewall, the first one is the firewall that stands infront of the subnet, like a gateman, called netwk acess control list nACL... 
in naCL, we can create some rule e.g open port80 for inbound rules &for outbound open port80 aswell, on my NACL, trafic frm enduser can get to my subnet
for  trafic to get to the webserver ,in front of my webserver thers another layer of security ie security group (this is firewall), but lets say i also hv port 443 open in my NACL, traffic still cant get to the webserver 
therfore i also have to open port80 , 443 in the webserver security grp
****** in  all we hv 2 security parameter
the 1st is the router for routing, wich permits traffic to be routed to the subnet bc if thers no route table permiting routing the traffic wont happen
the 2nd is the firewall wich has 2layers of security,, security at the subnet level & security at the server level
 *****mee** therfore; NACL has 2 security types or parameter ( routing table & firewall) & the firewall has 2layers (one for the subnet & one for the webserver)



LAUNCH JUMPSERVER

1:55:00 launch jumpserver- create instance- name- linux-micro-create key-edit ntwrk settings: select the vpc created:select public sn, d server nids internet-
auto assigng pub ip:enable-security grp to alow ssh frm my ip or anywher &ssh custom 10.o.o/24, alowing ssh trafic frm within my vpc
so dat servers in my vpc can communic, instances can communi wit each oda via ssh- launch ... we opened http 80 for nginx

1:58:50 the private ip  10.0.0.244 is deter by my cyber block which is 10.0.0.0/25 



LAUNCH DBSERVER
launch dbserver -name-t2 micro-ntwrk:select vpc created:privatesn-AUTO ASSign:diassble- SG - ssh tcp22, cutom:10.0.0/24 to alow ntwk witin my vpc-launch 
to access dbserver i must connect to my jumpsevre before i can access the dbsever 



FOR SECURITY CONNECTING TO THE APP/DB SERVERS VIA THE JUMPSRVER
 2:00 security is inherent in our environment , WE DNT ALLOW DIRECT acces in our db server, if u wnt to acces it u v to go tru our 
jump sevrer. traffic goes to the jummpsever bc it has a security grp dat is permitting the trafic, it allows trafic on port22 so  in d
 SG 22 is open for members of the team & my vpc 10.0.0.0/24,i.e my ip. so my ip & port22 ar d two access  
2:02:13 . security grp in frnt of the db server is only local so u can only access db server via the jumpsevr, the jumpserver acts as 
the entry point when it comes to ssh access,  frm d jump server u can access the app/ db servers,so any server in the vpc can be accessed
via the jump server. does d seceurity grp in my db sever permit trafic frm the jumpserver. if am outside the ntwrk of the vpc,to access
the jumpsever i nid the publicip of the jumpserver.
2;05:00 to access my jumpserver,ssh jumpservr in mobaxterm.
2:11:50 we can also aces the jumpserver wit the private ip if we are inside the vpc,e.g i can ssh to the jumpsevre frm my app server if my firewall permits it&dat is local 
access, bc they ar all resources witin my vpc



2:14:00 to connect to my dbserver, inside the jumpserver in mobax, vi dbkey i.e create a file&paste the dbkey, if i ll ,can see the key has read&write access so i v 
to chmod 400 dbkey to change it to read only .. then when i run ssh -i awskey33.pem ec2-user@10.0.0.54 ...v been able to ssh frm my jumpsevr to my dbserver
2:16:10 frm d dbserver when i ping google.com, it doesnt allow but when i ssh into my jumpserver again in mobx i get a response when i ping google.com
for my dbserver to be able to commu with google we hv to create a NAT gateway
2:18:50 create NAT GATEway - vpc- NATgateway- name-publicSN-connectivity:public- click allocate elastic- create
we go back to the private route table -i wnt my private subnet to access internet, so via the NAT one way internet traffic -edit routes-add route:0.0.0/0/NATgateway:select
the NATgateway that was just created- create
so my private subnet now has internet traffic via the NATgateway & my dbserver is able to access internet via the NAT gateway.



LAUNCH WEBSERVER
2:25:00 
OUR WEBSERVER is found the public subnet,we hv 2layers of security in front of the webserver, the 1st is NACl.. ntwk acess contl list wich wil control the whole ntwrk, 2nd 
layer of security is the secrutity grp ,, when end user traffic gets to the webserver running in my public subnet, it means the req port has been open , so in my NACL
inbound rule il open: rule1 port80, port443 for http&https respectively, in my Sg il ALSO OPEN PORT80 &443. so traffic comes to my webserver bc webser is listenig on those
port number, port80&443... frm here, my appserver runs in private subnet &also my dbserver
2:28:42 also for my appsevr i hv 2layer of security, one in front linking frm the webservr & one behind linking the dbserver

2:29:18 launch webserver - linux-micro- select VPC created- publicSN-auto:enable- SG:ssh tcp22/custom myip & ssh tcp22 custom 10.0.0.0/24 &ssh orhttp tcp 80 bc users can 
cm frm anywher &https 443 frm anywher- launch  ......correction.... publicSN...... not privateSN
since it is within my netwrk , i ssh with my private ip, i use my prive bc i wnt to ssh bt if i wanted endusers to access the webserver, il give them public..

users access our webseevr via ---->http/80, https/443 webserver [13.59.100.138]    
  admin ---->ssh/22 .. can use either of private or public.. he can use both 

2:38:25 our webserver is running in the public subnet which has route to the internet via the internet gateway
i think its bettr to use the same key for all the jump,db,&webserver so that  no nid to chmod 400 multiple times,, if i use the same key, once i chmod once for dbserver,
i dnt nid to chmod again when i ssh the webserver





AWS6
HOW TO ESTABLISH VPC PEERING, MODIFY THE ROUTE TABLE SUCH THAT DER CAN B A PRIVate ntwrk established, SANDBOX/ FRM THE JUMPBOX EST PARING CONNECTION ie
FOR THE SANDBOX WITH/VIA THE JUMPSERVER


HOW TO ESTABLISH VPC PEERING, 
this can be achieved in the same region and across regions 
23:25 

CHECK tELEGRAM FOR steps in the handout ... aws vpc27 pdf
Step 1)Create 2 VPCs - VPC-A and VPC-B with non-overlapping CIDR range
e.g of overlapping, is when the 2diff vpcs both v severs with the same ip address as illustated below.. its nt gud when they overlap bc when i ping the ip adress, the 
broadcast wont know if its searching for appserver1 or appserver2 
VPC-1 - 10.0.0.0/16......... cIDR blocks 
   appServer1 [ 10.0.0.66 ]...... ip address
VPC-2 - 10.0.0.0/24  ...... CIDR block 
   webServer1 [ 10.0.0.66 ]..... ip address

##### e.g2, without overlapping
vpc peering connection
======================
VPC-1 - 10.0.0.0/24
   appServer1 [ 10.0.0.66 ]
VPC-2 - 10.10.0.0/24  
   webServer1 [ 10.10.0.66 ]



WE V TO MODIFY THE ROUTE TABLE SUCH THAT DER CAN B A PRIVate ntwrk established.. 

in virginia, select peering conection- name- selectvpc to pair wit:project pair-..thers anoda option to pair vpc with- rgion:another-go into d other region, copy d vpc id 
paste it-create- go into the other region in action:accept the connection, meaning we can peer vpcs in d same aws acct or in an anodaaws acct,.in this case we wnt to 
do it in the same accoutn bt our 2nd vpc is in another region... the pairng vpc cud be in the same region or anoda region 

41:15,, modify the route tables of VPC1 -selsct route tables-tick publicSN of the created vpc:-edit: add 10.10.0.0/24- peer connection-save ... do the same in the privateSN 
 of the same vpc....TO est conection wit VPC2 via the pairing connection
46:50 we also go to the other region, the receiving vpc and modify the route table for vPC2- add 10.0.0.0/24 for both the publicSN and privateSN .... so we hv created route
for secure access by modifying the route tables so that we can v a private secure connection.. by default, the route table will permit local route frm 10.10.0.0/24 local
& 0.0.0.0igw to permit access tru the igw,, we also v 10.0.0.0/24pc.. this is establshing a private connection uisng the vpc peering connection,by virtue of this modification
we attaching these to our publicSN 0.0.0 igw &privateSN 0.0.0.NAT.the access To the internet is oneway via the NAT  & we v a pairing connection, this is what we v been able 
to establish. 



####51:15 ... SANDBOX .. 
A sandbox is a test server , the server can be used for testing...
the envirn wher we perfom testing is called sandbox server, we first deploy in the sandbox if it wrks well then we deploy in the right environ
.yes since we hv done the peer connection, we can connect to the sandbox from the jumpserver privately, we can est a private connecion.

****** ONLINE ...A sandbox is a secure, isolated testing environment used in cybersecurity and software development
to safely run and analyze untrusted or suspicious applications, files, or code without risking harm to the host system


 CREATE & DEPLOY IN SANDBOX/TEST SERVER


Ticket0013
 ===========
Deploy applications to production for paypal client.   
e.g, i hv 
  1. 8 production appServers with [ 192G RAM / 900GB SSD ] each

For best performance ensure that adequate testing is done  
  2. first, deploy in your sandbox/test server


step1
###55:20 to create a sandbox
launch instance- linux-micro- pem key- select the created vpc-prvateSN- ip:disable-SG:ssh  custom 10.0.0.0/24, so dat resources in the vpc can comm wit me via ssh, i also
wnt wnt an ssh connection est in this sandbox so:ssh custom 10.10.0.0/24, so frm both vpc am able to ssh privately- launch
the sandbox doesnt hv any public ip, its running in the privateSN
***meeee*** so we hv to est a peering connection using the jumpserver


step2
PAIRING CONNECTION  (To est a private connection for the sandbox with the jumpserver) 
1.04.15 we establish a peering connection with the jump server, connecting through the jumpserver ie  *****meee***, inside the jumpserver we create the sandbox key, change the permission  & run 
  ssh -i "aws33.pem" ec2-user@10.10.0.134       AWS 8B*****mee**** make an ssh call to the server ..
the private connection will be established so long as you modified your routing table accordingly for you to connect to the sand box using the private ip


ssh sandbox in mobaxterm
1:1:18 to acces my sandbox in mobaxterm
ssh -i "sand.pem" ec2-user@10.10.0.139

in mobaXT ,in my jumpser,creating a new key,-vi sand.pem :paste- bc my key is open, chmod 400 sand.pem, to change d key permission, then my key is secured- 
ssh -i "sand.pem" ec2-user@10.10.0.139 ..


sandbox is running in vpc2:
  privateIP  =  10.10.0.134
  chmod 400 aws33.pem
  ssh -i "aws33.pem" ec2-user@10.10.0.134

jumpserver is running in vpc1:
  privateIP = 10.0.0.54  
  publicIP  = 18.191.89.63
  ssh -i awskey33.pem ec2-user@18.191.89.63
  ssh -i awskey33.pem ec2-user@10.0.0.54



1. By default, from the jumpserver we can ssh 
   into the sandbox using the publicIP    

2. To est a private connection   ***1.06.49
from the jumpserver we can ssh into the sandbox using the privateIP 
   via vpc peering with route tables modified accordingly     



*****everything ended here with the sandbox


i think NLB was treated in video 7/8 & 8




AWS 7/8                                *****HOW TO  AUTO SCALING GRP & NLB, was treated in AWS9,i think NLB was treated in video 7/8 & 8
Elastic Load Balancers& AUTO SCALLING GRP, LISTENER, (NLB)NETWRK LOAD BALANCER*** Meee (LAYER 4 support),  DIFF BETWEEN NLB & ALB,
(ALB)APPLICATION LOAD BALANCER, GATEWAY LOADBANCER, USERDATA to install tomcat & docker for the APPSERVERS TO ACCESS THE APPLICATION VIA THE LB

   ******* AWS9*****  load balancers can be either netwrk layer4 or application load balancer layer6

*****1.05.16.. our main target is to acces our application via the lb

tomcat script didnt install the tomcat, engr francis helped me resolve it 


to refresh my mind*****from tomcat1&2

WHAT IS AN APPLICATION SERVER?

An application server is a container upon which you can build and expose business logic and processes to client applications through various protocols including HTTP in 
a n-tier architect

                        Examples of servers
Apache Tomcat - Apache
Jboss/wildfly - Redhat
WEblogic - Oracle 
websphere Application Server - IBM 
Websphere liberty profile - IBM
Galssfish
EXAMPLE OF WEBSERVERS/LB SOFTWARE
nginx
httpd
*********************************************************************************


START
13:30

Elastic Load Balancers = ELB:
  rules   
  Listeners 
  target groups with targets   
  health check on the targets  

  LB & elb 
Create your Load Balancers in an aws Region:
  aws will create 2 instances in 2 AZs  
  aws will install/configure a Load Balancing sotwares   

lets assume you are managing a FB appl with 4B endusers
FB have some app servers, meaning that traffic is coming frm the users and when traffic leaves the users it wants to access the FB application
eg we hv FB app server 1, FB app server2, FB app server3

13:40 its nt a secured practice to allow direct traffic to app servers so we create a web server 
once you create a webserver, it can now mg8 hw traffic is routed, routing traffic to the backend app servers
the webserver has what is called target, so there is a target grp, this target grp is my FB  app, so i hv a target grp for my fb app, so in total we hv 3target grps 
bt in a situation wher the webserver breaks down that will be a problem 
***20.04.... bc traffic will nt get to the backend server.


EXAMPLE OF WEBSERVERS/LB SOFTWARE
nginx
httpd


LISTENER
16:00 After installing, we v to configure & the configuration has certain parametrs
this webserver has to listen to traffic form this number of users thetfore we hv to talk about the listeners 
it has listeners to traffic using http 80 protocol or https  443, 
webserver has listerners and once it listens to traffic, it has backend servers, now you are configuring your webserserver & in the webserver we have some backends
lets assume ( our target grp FB) this guy face bk is 10.0.0.7/anoda guy 10.0.08  & the app listens on port 8080, this is the configuration
what happens is that your webserver is routing traffic so it reccives traffic; source(no. of users **me**8**ie the ip addresses stored in the backend) & destination (target grp) 
bt in a situation wher the webserver breaks down that will be a problem 
***20.04.... bc traffic will nt get to the backend server.
the webserver is a self managed solution & we can hv a situation where we hv backup webservers to cover up when webserver1 is down
but all the configuration constitute a very tidious job


therfor; AWS has provided us a manged srvice
so we can go with a managed service ie paaS...  
WE JUST CREATE our elb ... then aws decides the kind of software to install .. whether ngnix, https, they are incharge of that,, 
in the background, aws will create 2webservers in 2aZs for availability, so u dnt bother whether the server wil fail or not
so ur tassk is jst to create/config ur listeners/target groups
thats whAT elb IS ALL ABOUT




23:37 ... 1)THERS ALSO NTWRK LOAD BALANCER /    *** Meee (LAYER 4 support)
it deals with source and destination, &when it comes to d target grp dey ar created using TCp id or protocol & a trget grp can v up..
to 1000 targets and we will do all the config ..tcp= source &destination..video 8a (1:11.. d protocol here that it suport, the listener is tcp got to do wit source& destinatn 
this falls under layer4support..... ntwrk lb is faster than ALB BC NTwrk is source to destination bt for ALB when it receives a trafic it has to filters the tarfic to knw the
the right target to route the trafic to .... also it has multiple target grps wjile ntwrk has one target grp... ntwrk LB ia faster bc its routed on layer4 of the osi model &
its the transport layer dedicated for transport so by default for transmissn data layer4 is super fast
layer7 the application layer, route trafic base on content of the trafic.


 APPLICATION LOAD BALANCER
24:25.... 2)  thers also application load balancer(AIB)
IT will use the http/https protocol,, in dis case , we can v multiple target groups/ diff target grps
the applications are grouped with the help of a target grp
the AIB falls under layer7 support.


GATEWAY LB
3) thers also gateway LB , a new option which AWS now hv

interview: do u v any experience with layer4 support, nterk load balancers 
cos once we get into kubernetes, its going to be abt routing traffic to multiple backend application ... . 



STEPS FOR THE APPSERVER TO CONNECT TO THE LB *****1.05.16.. our main target is to acces our application via the lb


 step1
           USERDATA to install tomcat & docker for the APPSERVERS
38:00 APP SERVER - name -linux- micro-SELECT created vpc:pubSN-key-ENABLE AUTO- advance deatails:user data:paste d tomcat instalation script,to instal &start tomcat- launch
SG: SSH TCP 22  0.0.0/0, HTTP TCP 80 0.0.0/0, SSH TCP22 from any

create docker-app.. everytin is the same as aPP SERVER THEN PASTE the simple script for instaling docker .. they must be in the same VPC
SG: SSH TCP 22, HTTP TCP 80, ALL TCP , TCP from anywher 0.0.0/0

##### we can hv up to 1000 targets in a one target group ... 1:31:55



                         ****In this video, i bliv when he says 'LB' he was referring to  'ELB' 
                  'LB' means we are creating how service is routed by ourselves but 'ELB' is the manged service by AWS
               ******* AWS9*****  load balancers can be either netwrk layer4 or application load balancer layer6
            based on the AWS9 info, when am practicing hw to create LB, i see if its the same steps in both AWS 7/8, 8 & 9 videos to knw if its Nlb or ALB
                  *****HOW TO  AUTO SCALING GRP & NLB, was treated in AWS9,i think NLB was treated in video 7/8 & 8

step2:
CREATE LOAD BALANCERS 

49:30 CREATE LOAD BALANCER- name-internat facing(means it cn receive trafic frm ext sours &route d trafic-ipv4-the same vpc as docker&app-same vpc-pubSN- SG- add 
listenr 80-create target grp:instances-name- TCP:8080 .(we chose tcp/UDP bc its a ntwrk LB)-IPV4-HEALTH:tcp: we can also click adv:3,3,10,10...ie if the LB Ping the target 
server 3times &ders no response, it wont route traffic to the target-NEXT-select D required apps-portnmber it listens to e.g8080or 80 for deocker-tick include as pending-
create target grp-go back to the load bALancer being created &select thetarget grp-create load balancer... we can also add up to 50 listeners


step3:
1:02:20
TO ADD A TARGEt to an existing LBT:CEATE LOAD BALANCER- name-internat facing-ipv4-the same vpc as docker&app-same vpc-pubSN- SG- add listener-create target grp:instances-
name- TCP:80-IPV4-NEXT-select the required apps-portnmber it listens to e.g8080or 80 for deocker- tick include as pending-create target- THEN CLICK Target groups-register

so if we are trying to access our application, we will access it via the LB,

we can check online to see if our servers were installed 
publicIP:8080
56:50 we v to be able to access our app server & docker server directly or our LB wont be able to route traffic 

1:03 we can now copy the dns name of our lB to access our app or doecker server and it is more secured accessing our application via the LB 








AWS 8B
                                             i think NLB was treated in video 7/8 & 8 & ALB was in video 9
WHAT DETERMINES HOW TRAFFIC ARE ROUTED AND WHEN SHUD TRAFFIC BE ROUTED, CREATING LOAD BALANCER;(HEALTH CHECK, LISTERNER/ TARGET GROUP)
CREATE MAVEN & TOMCAT SERVERS FOR DEPLOYMENT IN THE SAME SERVER, HOW THE LB WILL BE ROUTING TRAFFIC TO THE BACKEND APPLICATION  ie the servers, USERS ACCESS OUR BACKEND
APPLICATION, DNS RECORDS, CREATING DOMIAN  NAME, BENEFITS OF LB


the course to knw hw to manage the resources hosted by AWS ,, understanding the process of managing the computing services in the AWS environment
aWS cloud architecture/ aws solution architect

2:25:40
in nxt class .. HOW TO USE LB to route traffic to multiple regions bc LB is works very well in a single region but with the help of route53



cloud computring engr takes care of the infrastrure in the cloud, establishing the right security for you vpc
its all building infrastruture in the cloud and managing it, like EC2 and other required resources
7:51 PROFF: for any org to operate they nid to manage their applications in a container, we call the containers computers  and the computers can be owned by the company 
or 3rd party, if its owned by the cop ,its called on prem infrastruture bt if  they choose to rent servers, an entire networking envi , data bases etc then that is what 
cloud computing  is all about, so if the cop decides to rent, u nid to v an indept understanding of hw all that is able to work 



we hv application servers wher applications ar being deployed
18:49for traffic to be routed appriopriately, we v to do load balancing, it can be a load bal or ELS
WE require a software wich helps us achieve load balacing with relative ease e.g ngnix or h ah proxy
the LB does 2 tins , it either accepts or rejects the REQ.. .. 
*********meaning tht LB ARE impoertaNT BC IT ACTS As A security measure.. e.g someome trying to access the server wich
we dnt want, it will reject the reQ.... SO if it accepts it will route tracffic to the app servers running in the backend.


WHAT DETERMINES HOW TRAFFIC ARE ROUTED AND WHEN SHUD TRAFFIC BE ROUTED 
inside the LB, WE DETERMINE How traffic will be routed .. we can create some rules, so if it accespts traffic it will route traffic based on the rules e.g if it has this 
options route it to this particular target.......  for the lb to knw the target grp to route to , :
rules will be deinfed, e.g we can config our backend instructing the lb dat if someon types this ip addresss on our listenere port route the traffic to the backend target grps
it will run health cheack on the tagerts
target groups with target 
REQ/traffic frm users goes tru the ELB, and for the it to receive the trafic it listens with its listeners  , it listens on some ports and protocols 
34:45 lb is like a server with  some sofware installed in it e.g if u install an ngninx software in a software in a server its an ngnix webserver, ha proxy installed in the
the server, its an ha proxy LB 
servers listen on protocol and ports
48:20  we v to mk sure the webservers and app servers are up/running and healthy




the OSI model 
different layers   read power point script



****In this video, i bliv when he says 'LB' he was referring to  'ELB' 
                  'LB' means we are creating how service is routed by ourselves but 'ELB' is the manged service by AWS
           ******* AWS9*****  load balancers can be either netwrk layer4 or application load balancer layer6
            based on the AWS9 info, when am practicing hw to create LB, i see if its the same steps in both AWS 7/8, 8 & 9 videos to knw if its Nlb or ALB
                                          i think NLB was treated in video 7/8 & 8 WHILE ALB was in video 9


1:04:50 for us to hv content base routing, that wil tk us to application LB 
1:24:00 CREATE LB AND THE MAVEN/TOMCAT SERVERS FOR DEPLOYMENT


         TO ACCESS THE APPLICATION
2:05:30 now we can access the application via our application LB.. by clicking the LB dns ,, we ar no longer using the ip add of our appserver
when we copy this information wit the context path (maven-web-app) am able to get a respnse ie 

LB DNS:   nlb1-7f9e896ea7e69c2b.elb.us-east-2.amazonaws.com
LB and the context path;   http://nlb1-7f9e896ea7e69c2b.elb.us-east-2.amazonaws.com/maven-web-app/


2:07. one limitation of ntwrk LB is that it doesnt allow more than one traget grps to be added to a particular LB

users trying to talk to ----> app-Servers
it goes tru the lb
   users ---> elb --- > app-Servers   



one of the tins that happen is DNS lookup  .. domain name servise
the traffic frm the access by the enduser is transmitted using the elb ie elb does a dns resolution, resolve the reQ and forwards it to the right appserver
with the dick or nslookup command i can know that if i type the LB url i can knw what the LB wil be searching for 
e.g nslookup realfinal-cc4b5a5307424ced.elb.us-east-2.amazonaws.com ... but it didnt wrk in mobxterm .. he ran it successfully in  windows ssh client ... 2:14:00

but it is not good practice to use the dns long detail information,, so we have to create a hostname called dollarways.net
create hostname =dollarways.net
ceate dns records: 
so such dat anyone trying to access our lb will type dollarways.net and it will route the traffic to the appserver



DNS RECORDS; we have
a records :hostname  matches to ip adresses
e.g phone contact record : simon .... o7034729002
PTR records : this is the reverse wher  id addresses matches hostname
c-name records ( are aliases)
e.g  landmark  and the alias name is mylandmarktech



2:19:50  CREATING DOMIAN  NAME
route53- reg a domian- click get started- it prompts to search for the name u want to create-select it- checkout-next-contact type:person-name, billing info- continue & pay


2:25:40
in nxt class .. HOW TO USE LB to route traffic to multiple regions bc LB is works very well in a single region but with the help of route53, we can route to multiple regions
2:28:00, LB are used to rote traffic, does load balancing , health check, security perimeter , accepts traffic or reject traffic and if it accespts it based on some
software routing rules whic are made possible bc of the inherent webserver sofware wich ar configured either by me if am deploying a self mgd webserver/LB bt if its ELB ,  
am deploying a serbice that is partly controlled by aws & by myself and its a paas, bc we dnt worry abt the underlying infrastruture ,e.g  AWS decides whether it nids a window infras or
 a linus infrast  and whatever software it nids, aws manages that ,,, so we can now focus on the type of backend target to be attached , listeners  ,, we  deter them



      BENEFITS OF LB

1) LB is gud bc it spans accross an entire region bc it spans across an entire region and that means high availability is achieved bc i can hv my target in diff azs , ie if on 
az is down the other ones can sustain the az that is down 
2) LB comes with addistional benefit like redundancy bc aws creates 2servrs in 2 az  so e.g if one server goes down its automatically replaced without ur knowledge
*********** LB are used to rote traffic, does load balancing , health check, security perimeter , accepts traffic or reject traffic






AWS9
CREATE REOCORDSET/HOSTED NAME USING DNS, TO ACCESS THE APPLICATION, CREATING APPLICATION LOAD BALANCER, CREATING ALB,HOW TO ACCESS OUR MULTIPLE APPLICATIONS 
 CREATE A RECORDS & DEFINE RULES, HOW TO ENCRYPT DATA, REQ CERT FRM AWS/TO VALIDATE THE CERT, SSL REDIRECT, STICKY SESSIONS, CONFIGURING SESSION TIME, 
HW CAN WE AUTO SCALE TO ACHIEVE FULL AUTOMATION, TO MK A SERVER HIGHLY AVAILABLE, CREATING A LAUNCH TEMPLATE FROM THE SCRATCH WITHOUT AN AMI, 
SECURITY OF VPC/ROUTE TABLE ACTS AS A SECURITY MEASURE 


video9,,  READ UP ADV OF LB,HEALTH CHECK , SECURITY
####1:54:56 by default, LB route traffic to a single region, so for it to route traffic to multiple regions we v to INTEGRATE ROUTE53



ELS is better than LB because we dnt bother abt the conf, avil,,, someone manages that for u 
ELS falls under Paas,,, routing trafic to backend application servers, we dnt v to worry abt installing softwares, load balancing softwares etc
load balancers can be either netwrk layer4 or application load balancer layer6
with the help of the target grps we ar able to route traffic to the applica
the loasd bal runs /performs health check
LB makes use of listener,, LB is all about ports,, it listens on ports/protocols
users makeS rEQ like http get reQ, post reQ, delete  REQ




CREATE RECORD SET/HOSTED NAME  USING DNS
16:20   dominionapps.net --- myALB-178479865.us-east-2.elb.amazonaws.com/
this is creating  record set using DNS, wich means that  .. webapps.dominionapps.net equals  --- dominionapps.net = nlb1-7f9e896ea7e69c2b.elb.us-east-2.amazonaws.com 
NLB:  nlb1-7f9e896ea7e69c2b.elb.us-east-2.amazonaws.com 
sub domian : webapps
this is domain name ---    dominionapps.net

************** steps- create domain name - create hosted zones- then access it on the browser


we search for the dns name in the region it ws created
******17:57 TO CREATE RECORD SET/hosted name
Hosted route -create record-recordname:to create a sub domain if u like e.g if u chooose a sub name as pay then uLL v,:pay.dominion.net-alias:select alias to 
netwk-select NLB region- select dns- create.


TO ACCESS THE APPLICATION 
the application we cloned is /maven-web-app  so , ==http://webapp.dominionapps.net/maven-web-app/ 

22:17 CAN WE USE ONE NLB FOR MULTIPLE APPLICATION ? ... NO
NLB goes with tcp protocol and its layer4 support also it  has one/single target grp



                               
**** 27:17 CREATING APP LOAD BALANCER .. protocol is http or https
 

        CREATING ALB
****** With the step below indicating 'select ALB,  Bliv he's creating ALB

he used only / ,, bc it wasnt accepting /maven-web-app
32:12 all our applications are running in virtual private cloud ,, just a free comment
**select ALB- name-internt facing- ipv4-select vpc: az- SG:443,80, ie the ports users can access our appserver frm,outbound:all traffic- listeners 80- create target grp:name-
protocl:http or https 80-select vpc-version:http1- health check :http- heath path : /maven-web-app - tick targets-8080- inclue-create-back to creating NLB: select target-grp
41:39 we can add anoda listener e.g 8080 & create anoda target grp for the listener- create 
 ie /, makes,  ..webapp.dominionapps.net/ .. the root path to access d application and we can run health check on the root path also webapp.dominionapps.net/maven-web-app, 
37:00 so we can run health check like dis " /maven-web-app, checking if the application is running 
further explanation, when we run curl -v localhost:8080 , this is d root path bt we can stil do dis curl -v localhost:8080/maven-web-app,so we can do/add dis /maven-web-app
when configuring the health check and it will check it when we run it .... he used only / ,, bc it wasnt accepting /maven-web-app

**** 42:53 create more target grps- now we hv multiple target grps, 1st  port80, targets: app1/jump, 2nd port80, app2,  but 3rd was 8080 all 3targets, 
the target grps
webappTG]
 tdapp              
 myApp              


***45:13 back to Alb. copy dns we can add /maven-web-app ,,when we paste it in D browser, we can see it routing traffic& when we refresh d browser we can see dif ip adreSes

we cant give cx the NLB dns so to use d domian name created go to 
*******route53-hosted names- recordname or leave it blank- select alias to appl & classic-region-select Alb dns-
createthen with the name created we add the pathh to the application ie /maven-web-app and when we paste in the browser, we can access the application


53:45  HOW TO ACCESS OUR MULTIPLE APPLICATIONS 

OUR APPLICATIONs & target grps 
applicationS        TargetGroupS
 maven-web-app      [webappTG]
 tdapp              [TDappTG]
 myApp               PayPalappTG


CREATE A RECORDS & DEFINE RULES
so we can create a-Records and define rules 
e.g if someone types dominionapps.net ,, then ...
Rule: .. bc ALB gives us this option  AND WE can route traffic based on  host and path  but we are using host here 
 HOST
dominionapps.net          ---Forward TO: webappTG
  td.dominionapps.net       ---Forward TO: TDappTG
  pay.dominionapps.net      ---Forward TO: PayappTG

we are using the same ALB to route traffic to all the domain
**** CREATE 2recrd setsthey are ALB plus the NLB we created earlier so dats 3 in total - region the same 
WE CAN ALSO EDIT Record set e.g for the NLB  record set where we selected "alias to netwk, we can change it to alias application by ticting the record set n edit it
*****TO decide how traffic shud be route

leave this,, (go bk to LB- SCROL DOWN & click view/edit - (GROup level stickyness is off) we can up click edit - also we can add a rule 
click on + -ADD conditios-drop box:hostheader and paste :td.dominionapps.net -tHEN:select D target gr :TDAPPTG & save ,now if trafic comes to td.dominionapps.net it
wil route d trafic to TDAPPTG we do the same for all 3 
(#### we were getting 502 bad gateway when we paste the domain hosted name in the browser: if its not working, confirn that the targets created in the target grps are healthy

continue here .. #### he went back to the ALB, deleted the listerner and click add listerner-http 80-add action:forward- select all the target grps- add 
*****go bk to LB- SCROL DOWN & click view/edit,,, 
1:18:00 here we can insert 2 types of rules : either the host header or the path 
e.g if we v multiple application, using path option :td.dominionapps.net/pay  or td.dominionapps.net/td or td.dominionapps.net/maven-web-app
########the rules didnt work,when he typed the rule in the browser it was 502 bad gateway - only the routing done by adding all the targets grps in the  listeners worked.. 
when we typed the domain hosted name in google 


MAN IN THE MIDDLE ATTACK someone was asked in an interview... the protocol we use to access information is very  imp
1:19:12 when tryig to route traffic, in the browseer, it says ur connection to this site is nt secure...  we ere using http protocol
he typed td.com and we could see the lock bc it is https ich is secured
1:20:4 when e type https, it gives us option for what is called ssl, secured layer, or tls ,ssl& tls termination 
for secured protcol, port 443 is used for https, cop dnt use http to transmit their content bc its nt secured n ALB supports ssl & tls termination.
data/inf from endusers wil go tru encryption process, it wil b encrypted or coded



HOW TO ENCRYPT DATA
by using some sf  called certificates, it hides the data, so if someone trys to hacked the account he wil only get garbage.. 
issued by certified certificate authorities, certificates are used for ssl termination
when users type info its encrypted bt when it gets to the coy its decrpted.... just free talk .. lb is part of our internal infrastruture
traffic frm users to the LB is encrypted therefore, so we nid to configure ssl termination for secured trafic using certificate.. we nid ssl/tls certificate
der sr some many certificate issuing coy we can use, we can use multiple csertifictae isung coy
e.g aws certificate manger to create certificate
when the info gets to our LB its decrypted by the LB, so we nid to ensure that the by users access our website via a secured protocol using certificate mangers
1:27:0 in aws, we hv AWS certificate manger
certificates from other coy can be imported and used in aws

***********1:27:3 REQ CERT FRM AWS.......... it will reQ for a domain name, it has to be ur coy domain name that u hv access to 
seach- certmanger-req cert- req pub-next- domain name: we can list the domain name,or \the sub domain names e.g  dominionappas.net,pay.dominionapps.net, or*dominionapps.net
and * represents all the sub names we v- dns validtaion-req. 

********* TO VALIDATE THE CERT  if ur the owner create(cname record set)
tick the cert domain name n click on it - creatre record in route 53-create

**** add listener- https:443-default cation:we can select redirect or forward, we selected forward- select target grp-we can add action bt he didnt -default ssl/tsl: 
we can import, or select ACM,iam,, we select ACM- selsct the certificate we just created in AWS-add- view listeners
now we can see the certificate routing traffic to our webapp
now we can move  http://dominionapps.net/ to https://dominionapps.net/..... this is now a secured way of transmitting our data ,, this is ssl termination
*******is asked in INTERVIEW TO ,,, EXPLAIN UR XPERIENCE WITH SSL/TLS CERTIFICATE
BY USING AWS MANGER, WE ENSURE THE TRAFFIC WE TRANSMIT IS HIGHLY SECURED 


********* SSL REDIRECT
IF ENDusers are try to access application from an unsecured protocol ie http
we can do ssl redirect ie http to https by adding condition/rule
1:40:55 ******** (go bk to LB- SCROL DOWN & click on http:80 rules -view edit rules- edit, it the pencil upthen edith one of the rules  -ADD conditions-drop box:hostheader
and paste dominonapp.net -action:redirect:443...convertin an unsecured traffic to a secured traffic, so if u type http://dominonapp.net , it will automatically redirect d 
traffic 

PLACING LB in the frontend gives more security to the backend & we also mk use of managed LB services in AWS like ELS which gives us more options to integrate in our process
of application deployment 

ASG, auto scaling grp /LC, LAUNCH CONF/LT, launch template


STICKY SESSIONS
48:12 TO ENSURE A CX FINISHES HIS TASK ON THE SAME SAME BACKEND SERver
1:45:25 ensuring that cx are only logged out in idling time and not at all times, we can use sticky session/stickyness to prevent that 
when hes asked for his login details again bc he has been redirected to anoda server , it means stickyness is off

******CONFIGURING SESSION TIME ,, when a user connects 
click target group-attribute:edit-tick stickness:we can select 5min,meaning if u ar on dat server u cant be moved to anoda server during dat time,bc u ar actively connected.
to that backend server, save changes - it refused to save , so he - go bk to LB- SCROL DOWN & click on http:80 rules -view edit rules- edit, it the pencil upthen edith d rule 
assocated with the target group we are enabling stickness for - delete d previously created rule- add action:forward to- grp stickness:5miden-update ..we do the same for all 
the rules associated with the target grp e.g if we created hhtp:80 or https:443 rule for the target grp we ar enabling stickines on..

####1:54:56 by default, LB route traffic to a single region, so for it to route traffic to multiple regions we v to INTEGRATE ROUTE53



####1:56:18  HW CAN WE AUTO SCALE TO ACHIEVE FULL AUTOMATION
ALL ALONG WE V BEEN creating our target grps manually, for e.g if ders a spike in one of the target grps and the targets can no longer carry d load and we nid nid to add 
more targets , we can add manually but we can also automate the process,, equally, if der is downtime, we can also deregister some targets .
**** we can automate using autoscaling
2types.. horizontal & vertical scaling
******e.g of horizontal ,,we v a t2 large server dat has 8GB & WE convert/change it to T2XLARGE ,,, now d T2large disappears completely &we ar left with T2X ,
ALSO, if u had 2 t2large servers 200GB each, then u add another 2t2large servers with 500GB ,, it is also horizontal scaling 
 e.g of vertical scaling .. from T2 large with 200gB to T2large with 500GB.. MOVING TO LARGE CAPACITY SERVER, its the same sever bt increased in size
2.03.30...  SCALING IS VERY IMP BC BIZ NIDS CHANGES CONSTANTLY
So rather than manually adding some number of servers when there is a spike & removing severs when there is a down time, we should automate the process, because
the reason you are a devops engr is bc you can automate. If you cant automate theres no need hiring you as a devops engr.

when u manually provison ur infrastructure without any autoscaler, the tendency is dat u wil spend more..... read it up

2:03:53 BENEFITS OF AMAZON EC2 AUTO SCALING 
1) Better fault tolerance; 
Amazon Ec2 auto scaling can detect when an instance is unhealthy, terminate it & launch an instance to replace it.
you can configure amazon ec2 auto scaling to use multiple availabilty zones. if one avail zone becomes unavailable, amazon ec2 auto scaling can launch instances
in another one to compensate.
2) Better avialbility
amazon ec2 auto sclsing csn help ensure that your appl always has the right amount of capacity to handle the current traffic demand.
3) Better cost mgt
amazon ec2 auto scaling can dynamically increase & decrease capacity as needed. because you only pay for the instances you use & can terminated them when 
nt needed

********HW auto scaling works ...... was able to see the auto scaler creating instances when we deleted some instances, its using the launch template
in ths appservers u creat saling policy , u ar saying u nid a minimun of a appservers,max100
appServers:
Scaling Policy
  Minimun  = 2
  Desired  = 2
  Maximum  = 100

we can increasr our server base on either CPU usage or men usage e.g 
 add instances if:
  cpu usage > 75% or    
  mem usage > 80%

**********1. Create a Launch configuration  ..............  readup all the script
   Create a Launch Template , dis is  anew generation of launch configuration 
2. Use your Launch Template to create your Auto Scaling Group  [ASG]
3. The auto Scaling group will create the Desired/required number of servers 
   using Scaling Policy and the Launch Template 
##### this policy wil create the minimum number of severs ie 2


2:17:00  TO MK A SERVER HIGHLY AVAILABLE
*****instances- select server- OPEN IT;ACTION:IMAGE& TEMplate:create template- nameversion:1- tick providing guidance, he unticked it,he wil do d autoscaling later-broese
more amis-tick the machine image used to ccreate our server-confirm changes.-manually select instance type-(d key,SG, everytin has prepopulated)-tag-create launch template.
2:18:33 in action of the template we jst created, i can select create auto scaling grp, 
also i can go to auto scaling grps-create auto scaling grp- name-launch template:select the template we created/want-nxt- the same vpc-select all d AZ, ie d autoscaler can
launch server in any of the AZnxt- we can attach to LB- it can also perform health check-nxtgrp size 2,2,200 - scaling policy:target tracking:70 ie if d avg cpu utilization 
exceed 70% it shud either ad more inatances or reduce instances- nxt- we can do sms notification -nxt add tag-nxt-create- 
2:23:21 the launch template has been created
now the auto scaler is updating capacity,and when we shut down the instances we already created, we can see that the autoscaler hv created instances to replace the one we 
shut down.

*****2:27:32  CREATING A LAUNCH TEMPLATE FROM THE SCRATCH WITHOUT AN AMI... (we wnt to use it to create and launch tomcat)
I nid a launch template bc when d autoscaler is been trigger the launch tem conatains default confi, the way i wnt d instances cofigevrytin is defined in the launch template

********LAUNCH TEMPLATE-name- vers:1- can use or nt use source template-machine - browse:redhat linux8-iam freetier-t2 micro-key-ntwrk can be included or nt-SG-
Advance:paste script-create- auto scaling grp- name :tomcat app ASG-launch temp-
select temp- vers:1- select vpc- all AZ-NXT- we can attach LB & if we do, we v to choose Targt grp n he did- nxt- 
1,1,1- policy:appl load targ REQ, IF the target value is 5000 ie if our target is receiving an avg of 5000 req add more instances-scaling policy:none-nxt- creat autoscaler.
so when we check, we can see the autoscaler creating the tomcat server
*******2:34:37  when coy ar creating their autoscaling grp they mk use of golden amazon machine image  ... AMI
WE USE AMI to launch inastances and it comes with operating system like ubuntu,redhat,windows but
AMI conatins the default AMI plus other configurations like e.g the configured  



security of VPC........ ROUTE TABLE ACTS AS A SECURITY MEASURE 
2:46:30 route tables det hw traffic flows and in the route table we can v a local route e.g our vpc  10.0.0/24 SUBNET1has 10.0.0.0/25 , & Subnet2 has 10.0.0.28/25 , in the 
route table i want to define hw traffic will flow in sub1 so i v a rout tbale that wil route local & internt traffic and anoda table dat route only local traffic.. sub1 
WHER we v ELB/webser is permited to receive trafic so it has local traficfic 10.0.0./24 ^ internet traffic 0.0.0.0/0 ,, sub2 with app serv is nt permited to receive intent
trafic dat means the route table hasonly 10.0.0/24 .. therefor the ROUTE TABLE ACTS AS A SECURITY MEASURE ,,.. BC since this subnet is assocaite with the route table without
internet, thers no way it can receve internt traffic .... now for internet to get into sub1, we v to create igw and attached to the vpc,, also we creat the NAT gateway in the
public sub. ie sub wit route to d internt,, with d NAT, resources in the private subnetcan v internt access.. bt since we ar mostlt launching servers we nid ELB, Auto scaling
grps, launch template even targets and we provison our resources inside our vpc/netwrk 
also a coy can v more than one vpc so to est a private connection btw 2vpcs, we can use vpc peering 
for multiple vpc and unprem/insiteinfrasture, to ensure 
unprem servers ar able to taklk with our servers in the cloud, we can use vpn, or aws direct

??????#### some said he was askeD in the interview hw he (d interviewer) gave e.g of xray hw do ur private subnet to d outside , hw do u configure that& he told him vpn bt
at the end he asked the interviwer what he wud do and he told him endpoint 
*** prof wil xplain hw to use vpn endpoint and relational endpoint e.g when a database is crsated ina  private subnt and u wnt ot access it in a dif envir like a kubenetes
cluster then u nid the endpoint of the database

????if i create an account in a server n der are many servers and nxt time am in another server, is der a way to replicate all the data that is on the first server to this 
present server, ie concerning LB.... prof yes ders a replication process , once an application ar captured,once u access an applica u v d option to write data into the
application n ders  genearallyy a data base stuff we look at once we get into docker , hw to use databases n mk our life a little more easy.






AWS 10 & 11

didnt practice this video

IAM USERS , POLICIES , MANAGING INFRASTRUCTURE, HW CAN THESE RESOURCES BE MANAGED, CREATING A VPC USING Terraform, Access management, CREATE IAM USER,  RUN TASK IN CLI, GRANT & RESTRICT ACCESS, 
I MANAGE MY AWS RESOURCES DIRECTLY WITHOUT CONNECTING TO ANY SERVER THAT HV CREATED IN AWS, USE CLI TO LIST CONTENT OF S3



UDEMY VIDEO


video 10&11
if u are to xpalin cloud computing and ervytin dt is involved to it , wev bin able to realisee der ar certain elemrnts to that effet wich we can discuss wit relative ease when
cloud computing is involved...also talking abt cloud and their terms of org or levaraging their resources by a 3rd party ie using a 3rd party infrastructure and those 3rd parties
in computing languages we call dem  called cloud computing providers and dey can provide ntwrking sevrvices, database services,server services,compute serv... & dis ser ar imp
to tk note of when it comes to the diff element of cloud computing  our converstion v genral tailored towards that direction n all wev delibrated on is to ensure that end
to end exercise is been achieved seemlessly wit relative ease. 


"###############the diff aspect we hv been able to cover.......... read up cloudcomputing script

21:19  ...IAM = identity and access mgt
=====================
e.g if u wrk for netflix
Netflix ---   
   DevOps Engineers   
   Developers .. all these pipo ar granted access to aws resources, therefore who shud access these resource is very imp
so the serVice that is used to decide who access aws resources is called IAM among others, 

AWS COVERS 2 THINGS: .. so u can finish this course and work as any of this 
Cloud Engineering  
Infrastructure Engineering
so when we ar managing this resources thses ar all the infrat that nids to be managed:servers,
  - storage,  - databases, - networking,- software,- analytics, - and more
in managing infrastruture, we can :Infrastructure MGT [ create, view, update, delete, modify, grant access ] 
and dis can be done using GUI ... E.g chnaging the name of my server , vpc .. we ar managing dis frm the console n u realise when u do dis thers high possiblity of error
so apart frm using console we can use files 
===========================

########## HW CAN THESE RESOURCES BE MANAGED???????
generally WE CAN use 
CONSOLE  = GUI   e.g creating servers, vpc in aws :
   Prune to errors 
   Time consuming 
   Visibility is challenging  
   limited automation - 5%  

also using Commands = CLI  = aws s3 ls :
   Prune to errors 
   Time consuming 
   Visibility is challenging  
   limited automation - 55%  
   It cannot be easily replayed or redeployed
   it can't be version controlled  


 ########## THE BEST OPTION .....we can also use IaC and we r going to see d dif level of automation it brings to d table  = codes    = files  = IaC / Terraform  :
   IAC wil cover terraform, we can use a tool called terraform, wit terform i can create a file,, e.g i can wrote  asimple teraform code to create vpc
   It is not Prune to errors 
   saves time  
   Visibility is very easly  
   great automation - 99%  
   It can be easily replayed [dev/stage/prod]
   it can be version controlled   
****** IN OUR ENviron, we use all GUI, CLI and IAC, BUT WE  mostly manage infrasture using infrastructure as a code 

34:25 #########CREATING A VPC USING Terraform but he didnt really go deep 

resource "aws_vpc" e.g i want to create a vpc for tesla  "tesla-dev" {
  cidr_block = "10.10.0.0/24", i wnt to crate a vpc wit 200ip addreses
  instance_tenancy = "default"
  tags{               ie creating a tag name e.g tesla-fe
    Name = "tesla-be"
    Environment = "dev"
  }
}
  

THE QUESTION IS 
if u have a terafform like dis , can i use the same file to create vpcs in other environments ?????
i can easily use dis same file in d stage environment, it can be easily replayed or reployed in the dev,stage &prod, i can version control the file using git wit dif branches
ie in the script ill change the environ from dev to stage or prod

resource "aws_vpc" "tesla-stage" {
  cidr_block = "10.10.0.0/24"
  instance_tenancy = "default"  ... hw do we wnt the tenancy to look like , it can be default or dedicated bt if u dnt put default, its going to still choose default
  tags{                    
    Name = "tesla-fe"
    Environment = "stage"
  }
}
=========================================


Team members can manage resources using the console, cli or IaC.
However for that to happen  there must be authenticated and authorise    

IAM: in AWS , This is a key security service in aws used for  
     authentication  and 
     authorisation for Engineers and other team members to run different tasks. 
 aws-account: U CAN ACCess aws account as a :
   root-User =   
   IAM-USER  = 
changing from vpc to the IAM  dashboard it changes frm ohio to global

vpc= regional and IAM is global 


ACCESS MGT
Access management: can be accessed to 
  IAM User groups = we can hv a grop for and assign policies to grps
    managers [AdminAccess] , ie managers can do evrytin
    developers, [VPCREADACCESS, S3FULLACCESS, EC2READACCESS ] therfore e.g he can launch ec2 instances ,so d developer must conact the manger or james bc they hv full access
    Engineers [VPCFULLACCESS, S3FULLACCESS, EC2FULLACCESS]   
  IAM Users       = simon [VPCREADACCESS] , class33, James[VPCFULLACCESS]   
  IAM Roles
 policy is an object in aws that define permission
  IAM Policies - are Permissions that can be assigned to users/groups/IAM-Roles
               e.g of policy can be : 1. VPCREADACCESS / 2. VPCFULLACCESS  

Ticket00133:
  Create iam user account access for; Class33, Simon and James  
  Create user-group access for; managers and developers & Engineers
  Assign admin access to the managers group    
  assign VPCFULLACCESS, S3FULLACCESS, EC2FULLACCESS to the Engineers group
  Add Simon to the manager's group  
  add james to the developers group  
  Assign EC2READACCESS to class33 user   

*******59:000 CREATE IAM USER
****IAM create user-name -provide access:if i dnt tick it d user cant come to aws axccount, he can only access aws resources tru the console or cli ,iaC- USER TYPE:IAM -
CUSTOM pass-user must neww pss:untick-nxt-add uyser to grp- CREATE
when we logged the user in he it indicated u are nt authorixed to....

***** name:class33-tick provide acess-pass-nxt-add user grp-create

********for anoda user james .. name - unctick provideb console accss-add user grp- we can also attach policy directly-nxt-create
*******user grps-name:managers-,add usr:tick simon- tick admin aces- creat
now simon is authorized bc he has been added to the managers grp wich has adim acess but he still doesnt hv acess to billing even as  an administrator
create new grp:develop- add james-ec2 read only aces- creat
create grp of egineers- no uswrs for now- ecc2 full-s3 aces-vpc acess create

3 INFORMATION needed
IAM-USER  = 
   https://287784533479.signin.aws.amazon.com/console
    userName = simon  
    password = Admin@123 
    accountID= 287784533479

aws-account: 
   root-User = 
      root-email =  landmark@gmail.com 
      root-password = admin123@001  
 

  AdministorAccess  -- ec2, s3, vpc, route53  
  EC2FullAccess     -- 
  EC2ReadOnlyAccess -- 
Security is inherent in our environment 
we use the principle of least priviledges 

IQ: Which tasks is an IAM user with admin access unable to do? Billing  

********1:15:19.. it is imp to knw that Users can have either:
  console access [userName and password and accountID]  or 
  programatic access using [accessKey and secretAccessKey]
  to aws resources    

*******prOGRAMMATIC ACCESS ... the keys gives us programmatic access, we can mk API calls 
******IN MOBAXT- JUmpserver sudo hostname js , sudo su - esc-user- aws s3 l3 : it says unable to locate credentials, by running aws configure. 
**** in aws: global- iam or security credentials of simon- create aces key- command- i undersand -nxt-create - copy
1;19;18 

   accessKey      =  AKIAUGAPXTS7AGZNQ600
   secretAccessKey=  0OeifliOM4J0lUbOLPvDFDP/Vb4QNwN6haIxyI24



*****1:24 RUN TASK IN CLI.. MOBAX 
in windows system ,when u run aws s3 l3 it says command nt found so ...install aws cli in windows system (in google seaRCH aws cli install and download n install).. 
then run aws s3 ls & now we can run aws configure, it wil ask for the keys then paste acess key id and secret acces key id -defaullt region :ohio-default output:
we can choose table or jason-, run aws s3 ls and we can see/list the  s3 bucket ,, wwe can also try the same in the jumpserver and get the same result 

##### the keys gives us programmatic access, we can mk API calls .,, with d keys u can acess n mange resources in my account  
 if we say ...sudo yum remove awscli and run aws s3 ls , it says no such file
sudo yum install awscli ... aws  --version   .. 


  GRANT & RESTRICT ACCESS
*****we can grant and restrict access.... if we remove simon frm the mangers grp if he run aws s3 ls, he  cant get a response bc d acess keys are his n hes removed 
## we can go to iam,-users- simons- permission: we can add him to a grp , or we can attach policies directly :amazons3readonly-add 
now if he run thwe command again , he gets a response
**** ** aws s3 mb s3://class33 ... name is class33....he trys to create bucket bt he cant bc he can list but not create 
to grant his accress to craete : add permison: attach: s3 full access- add ..... (the action for s3 is *) and now hes able to craete
when we are creating a bucket, we start wit the url ..s3://
to list aws s3 mb s3://class33

1:40:30 we cant list the content of a bucket we dnt own 
we can use permision to ensure that users can be able to perform specific tasks


1:42,, 
*****yes ,,,,   CAN I MANAGE MY AWS RESOURCES DIRECTLY WITHOUT CONNECTING TO ANY SERVER THAT HV CREATED IN AWS  

google, aws ec2 command line list instances, ,, all the commands are availble online, i dnt v to cram dem,, 
https://docs.aws.amazon.com/cli/latest/userguide/cli-services-ec2-instances.html

still using simon credential who doesnt v ecs instance permisison
i  bliv dis comman is to describe a particular instance
1:45:50 ******aws ec2 describe-instances --filters "Name=tag:Name,Values=MyInstance" now we can replace my instance with 
aws ec2 describe-instances --filters "Name=tag:Name,Values=webserver" ,, we can decribe inrances like dis
now paste in mobaxterm ,,unknown output type: jason ... then he typed aws configure and  json for default output format   
then paste... : aws ec2 describe-instances --filters "Name=tag:Name,Values=appserver" ,, so all d instances wit d name appserver is what ill want to see
but we got unauthorized creditials, so 
i have to go bk to add permisison and grant him ec2 full ec2 intsance permission and also add him to managers grp
so nnow in mobaxterm we can see all d instances wit d name appserver, all their details, parameters 

##### we can also terminate instances from the command line ,
jst copy n pate this command with the ipadresses attached  
aws ec2 terminate-instances --instance-ids i-5203422c



aws ec2 describe-vpcs | jq -r '.Vpcs[]|.VpcId+" "+(.Tags[]|select(.Key=="Name").Value)+" "+.CidrBlock'
to describe vpc ...aws ec2 describe-vpcs

we can also search... show aws vpc commands,, we can also create Ebs volume
https://www.bluematador.com/learn/aws-cli-cheatsheet

we can from the command line n with the iac

2:00 aws eks get-clustters
aws eks list-clusters

**8***88  I DNT understand ,,  then below i understood
2:06:00 I CAN PERFORM MY TASK DIRECXTLY ON MY WINDOWS SYSTEM WITHOUT CONNECTING TO MY EC2 INSTANCE

WHEN am working frm gitbash am working directly on my windows system,, am using my windows system to manage aws resources
with an ssh either mobx or gitbash install in my computer i can connect/acess my server wich is in aws cloud, to manage my task in aws account i can use commands or 
console ... to use commands i can connect to my aws instance n use commands or i can jst run directly using gitbash or mobaterm
..my understanding,,i bliv to use commands, i dnt v to ssh into my server, i jst v to run aws configure and authenticate with my keys 

apart from simon being authentictae with the keys he is also authorized via these policies
2:06:37 if i ssh into my server (using mobaxterm) then am manging my aws resources frm d ec2 instance (i bliv dats the console option)
at work dis 2scenerios wil playout, wher ucan either shh into my server to perform task or i can perform it directly on my windows or
mac system

USING jumpserver for dis illustration
**** when i run aws configure, it creates an account, it creats  afile called : .aws
ll .aws/to see who owns the file
cat .aws/config to see the configure file inside it 
cat .aws/credentials
we can delet rm -rf .aws/
ls -a to check the list of files that starts wit a ,,,, now ders no .aws
if we run aws s3 ls .... itv says no credentials 

*********but is der anytin i can do to b able to acess these resource.... ie attaching Iam roles
yes i can use IAM roles, these are policies/permissions that can be attcahed to another aws resource..[ec2 Instances, eks, ecs,etc.] 
to permit the resource manage other resources based on the Policies attached to the role
iamRoles are Policies/Permissions like [ VPCFULLACCESS, EC2FULLACCESS ] 

******* 2:12:50 TO ATTACH IAM ROLES TO MY JUMP SERVER
select the server-action:secrity:modify iam role-create IAM role-aws service-ec2-nxt-tick any permission- nxt-name of role- create
we can add more permissions if we wnt- create anoda role   .. roles-create role-aws-use case: select e.g eks-nxt-nxt-rolename-create
back to the server -select role frm drop box-update 

******** back to my jumpserver, when i run aws s3 ls ,, now we are authenticated

to install aws cli software
https://docs.aws.amazon.com/cli/latest/userguide/cli-usage-help.html
https://aws.amazon.com/cli/

Identity providers ... ther arev other identity providers we can use wit aws to mange more access 
Account settings

ASSIGNMENT
Ticket00148 - create a vpc in us-east-1 using:
  1. console  - netflix-1c
  2. cli      - netflix-2c
  3. IaC - Terraform   - netflix-3c 
terraform codes are written in HCL - HASHICORP configuration lanaguage   
terraform codes has .tf extentions  
   .sh[shell script] / 
   .java[java codes] / 
   .py [python codes]
   .tf [terraform codes]


QUESTION
diff btw s3 bucket and ebs ,,, check the storgae part of the power point 
check frm pg 34...s3 buckect is na object storage n it doesnt require creating any mount point,, while ebs volume is a block storgae requiring a mount point
if i share a mnovie in my s3 bucket the whole class/ a thousand plus can can watch it at the same time,, dats why it has multiple gigabyte per sec

ebs is block 
efs is  file
s3 is object storage


25:34:00 i v a server hosted in aws, inside the aws account at the global level i v some users, all iam users ,,, in the same account i v created my ntw so now i 
v my vpc in the vpc i aslo created subnetwrks, in aws we can create resource and to be able to create resources, u v to be authorized like creating an instance.. that
way not evryone can ,, creating the infastruture itself, u v to be authorized to crate or provisoin the server,, anoda person can be assigned permission to carry 
out task on the server , now he can try to ssh  in to the server so to get access theres firewall so i hv to open port22,, b4 it is routed , inside my vpc v been able
to create route tables attached to my subnet which allows routing to take palce inside my vpc within the subnet bt my firewall has to permit the trafifc  to get to 
wher its going to , bc if the route tabe is nt created n my ports ar open i stil wont b able to route traffic...its like a virtual touter permiting trafic to be 
routed...then we v another fire wall infront of the server called security grp and once port 22 is open then traffic will be routed to the person to carry out the
task assigned.


USE CLI TO LIST CONTENT OF S3

2:24:15 ???? yes...... can we use the cli to list the content of s3 bucket
aws s3 ls class 33 willl list the content
to upload content to my s3 bucket 
aws s3 cp aws33.pem s3://class33b
to download  aws s3 cp s3://class30 /Dockerfile .  ( the dot means am copying to my pwd),, so we v copied the docker file frm the s3 bucket to the pwd
we can also run.. aws s3 cp aws33.pem s3://class33b/jenkinsfile /home/ec2-user/
to copy frm one s3 bucket to another s3 bucket
aws s3 cp aws33.pem s3://class33b/jenkinsfile s3://class33a



s3 bucket commands 
 32  aws s3 cp aws33.pem class30b
   33  aws s3 cp aws33.pem s3://class30b
   35  aws s3 cp  class30b/Dockerfile .
   36  aws s3 cp  s3://class30b/Dockerfile .
   37  ls
   38  pwd
   39  aws s3 cp  s3://class30b/Jenkinsfile /home/ec2-user/
   40  ls
   41  aws s3 cp  s3://class30b/Jenkinsfile  s3://class33aa
   42  aws s3 ls class33aa



to tk my aws study to the nxt level
===================================
Terraform and other IaC tools to manage aws resources
=====================================================
Terraform
CloudFormation 
Ansible  
Terraform:
=========
- support Multiple clouds [aws, GCP, Azure]
- codes/files are used   



18hours to cover terraform:  


 

************************** DNT PRINT

we use aws services based on the needs of the company ,coy wil use asw services based on task they ar trying to accomplish
For our cloud solution, we have diff cloud providers like  Cloud Service Providers - CSP = AWS / GCP / AZURE 
they Provide computing services / resources like servers, network, storage, security, etc. over the internet from their Datacenters 
  cloud computing is very imp and you can see a lot of COMPANIES ar migrating very quick &fast from on-prem to cloud to take advantage of cloud services
We have Cloud Service Models like :
=====================
IaaS -- Infrastructure as a service  : e.g ec2 instance  - ec2, SonarQube
PaaS--  Plat 
the main cloud service providers :AWS - Amazon Web Services , GCP - Google Cloud platform), AZURE Cloud
The AWS Cloud spans with over 102 Availability Zones within 32 geographic regions around the world,
EXAMPLES OF AWS SERVICES includes
ec2 / eks elastic kubernetics serv / ecs elastic container services / iam, identity & access mgt / route53 / elb , AWS STORAGE SOLUTION like ebs elastic block storage, and using the root file system we can create mount point and attach 
block storage to our servers to expand/increase our storage size as required (from my command line i can type "list block command" where we hv our root file system.), also; we hv / efs ie elastic file storage,
/S3 bucket ie object storage,data can be stored in buckets
IF YOU CREATE FILES AND and store it in EFS/EBS, the files cannot just become accessible online  but with s3, i can store a file and its immediately accesible by anybody around the world. Also we have /SHARED Storage/ LAMBA FUNCTIONS/
DISASTER RECOVERY; of which we carried out a project as a diaster recovery measure , where we have our database servers running in account one but backedup in account 2 ( which is our diaster recovery 
account, so our database servers are backedup incase thers a disaster.
 So what we did is We created a snapshot lifecycle policy using Lambda  which creates sonapshots from our databases from account1 in account2
snapshot is a replica of your database, its a backup therefore if account1 is hacked, we already hv everything in account2 so we are able to recover from account2 
SO WIT THE HELP OF LAMBDA & snapshot lifecycle policy, this entire process was automated
so am proud of this project

 

