******** explanation on how traffic is routed is in nginx tomcat & kub 10&11


kubernetes 1&2


SOMEONE ASKED how many pods can we create in one node ???????????????



lets look at k8 BEST PRACTICES FOR LARGE CLUSTERS     *********** so if u have a very large cluster you can click on this link, u wil get more info
https://kubernetes.io/docs/setup/best-practices/cluster-large/
For very large clusters NB: dnt create :
   No more than 5,000 nodes
   No more than 110 pods per node
   No more than 150,000 total pods
   No more than 300,000 total containers


IQ: what is Static Pods ?
    Static Pods are controlled by the kubelet service  




KUB 6  .. Class33
what is the default deployment strategy?
  RollingUpdates  


  QUESTIONS
QUESTION......1:24:35
1) can a file be use to taint a node or must it be only commands in the CLI
ANS : anyting can be done with a file ,,,, i will have to check it up and you can check it up too

2) WHAT IS THE MOST used type of deployment
in k8 we can deploy with our containerized appl directly in a pod or we can use controler Managers like RS,RC or daemonSet bt most importantly we can use deployment and we 
use deployment it gives us the option to use diff deployment stragey like recretae, rollingUpdate and part of the deployment strategy we can use deployment techniques like
blue green OR canary deployment and that is you makingyour application available and infact deployment is maeking ur application available
once the applictaion has been made available the nxt quetsion hw wil the appl be discoverable ,hw wil ur cx discover and ultilize the appl , hw wil it be useful to them
there services need to be created, we need to expose the appl using services and der are diff services categories :
cluster IP permits you to access the appl within the cluster ,, so it exposes the apl to objects insid ethe cluster bt if its an appl that end users nid to access clusterIP
wont work therfoer wil use nodePort service or LB service to make it accessible  bc deployment makes your appl available bt  hw to i access it : service discovery


3) CAN deleted replicas be retieved  ,, bc you say we can delete it bt then hw do we roll back if for e.g a junior staff deletes it
we cant retrieve a deleted replica , once its deleted its gone
*the fact i sthat someone doesnt jst cm to ur offic eand u give him access bc in ur wrk env, we will use roll base access control like if u ar new we can permit you to hv 
access only to pod and since our pod are behind a controller managers and when the junior staff delete a pod it will be recreted again so u shu dbe senesitive enough nt 
to grant him mangers access...

4) for best practice what is the recommended number of replicas to keep  ie replicas of diff versions 
we cud keep a max of 5replica sets bc it will mean you have deployed about 5versions and the cx is happy with new verion 
bt its also subjetive to the client , some may decide to keep up to 10 replicas

5) when we rollback wnd then rollout again are new pods always created or the pods are reserved when thay are inactive
when you store those inf k8 will store the data in etcd , so it knows that version6 has the version6 of the image so when you roll back to version6, it goes back to that
particular image that was in version6 , thats what happens 
you can also rollback to a particular version choosing the version you want so when u run kubectl rollout undo deployment/web, u can choose the exact version ur rollin bk to

6) when we deploy w ecan choose for e.g 4replicas  bt when we scale to 2 is there any prefeernce in the pod that are created
d pods are identical in everything,its nt a matter of  no preference ,if you are updatingnscaling frm ur manifest file it will wrk inline wit d latest version ie d number of 
replicas u hv defined in the file bt in terms of if it will chooose which pod to create it wiill bring down all the pod wit the old versionof the imgea n bring up the pod 
wit the new version u now want and in terms of number of replicas its goin to be a function of what is defined in the manifest file 

5) when we taint a node and its undergoin an upgrade when u pass a toloration will pods be schedued on that node?
what is the rationale behind tainting a node , u taint a node bc u wnat to upgrade the node so if the node is already under upgarde ders no nid to be assigning toloration
that wil still create a pod on the node right,, we only do that in rare cases .. so toloration is now that pod is nt schduled on dis node bt i am tolorating that to happen
bt that shud only happen if the node is nt under any maintenance, if its under maintennace u wont want to do that bc what is the rationale

6) hw do we rollback to a specific version???  ..
. go to k8 and check it out so that  in the  nxt class u can give us a briefing on that
kubectl rollout undo deployment hello --to revision=1 OR revision2 n so on   ..... class33 video 5&6


class33 video5&6
1) when we create toloration, can we create it so it doesnt create pods in the master node??
ans: YES, we can do that, ther are many other options when it comes to toloration, which means we have  diff operators and diff keys and wil look at that when we look at
scheduling, how pods are scheduled on a node.

2) why will we want to schedule pod on a tainted node
e.g we want to  ensure a particular pod is scheduled on all nodes including master bc the pod wil be gathering logs on the master node to tell us if the node is healthy or nt
the master node for e.g is tainted by default but we can use toloration to allow a pod to be scheduled on the master node probbaly bc the pod will be gathering logs on the 
master node

3) what is the actual function of the selector support function of the replica set bc when we were doin the controller managers we had the replication controller n u then
showed us the replica set and u said the replica set has a selector support but when we did both of them the only diff that i notice is in d format we wrot e our API veerison
ie in the replica set and also that match label key that we used
ANS:  

we hv equality based selectors and it is used for what?  
   ReplicationCOntrollers
key:values       ********** eaulity based selectors talk abt equal conditions like key:values
app:myapp
Set base selectors: is used for ;
  Deployments
  Replica Seta
  DaemonSets
  StatefulSets
  NodeSelectors
  NodeAffinity
key: app                    for set base we can have key , value in .. lets assume the key is app , value in:javawebapp could be my app
value in:                            so 1key can hv multiple value , dats why we say setbase selsctor and it basiclaly comes wit stuff like daemonset,RS, deployment etc
   -javawebapp                     its jst that all the examples we hv done so far we v not needed to get to get into set base selector bt as we progress, we are going to
   -myapp                          look at set base selector and if u hv any problem jst wqually go to the k8 official documentation
                                    kubernetes.io abi na oi

4) is der any scenario that will rEQ us to create stactic pods manged by the kubelete service as opposed to using the controller managers bc static pod itself has healing 
capabilities ACTIVATED 
ANS: YES , BT Static pod cannot scale, so if it created a pod is just a single replica
2ndly, static pod are used to create components that manage k8 like kube proxy, dns, all of those pod that manges your cluster, we use that pod to create them so that they 
will always be recreated even by the kublete service.

5) what det the object we use in deployment, is it coy base ??/ wxcept daemonSeT cos i understand its used for e.g logmgt
so what det the obj w euse for deployment
ANS:
the obj to be used depends on the diff/other components that obj will bring to the table 
deployment is said to be the recommended object for deployment in k8 or for running/deploying workload in k8 bc when u create a deployment, it creates a replica set so
it records whatevr u created such that if anything is wrong it can always rollback, thats why most of the time we use deployment bc deployment will rollout a replica set
u can rollout n rollback ,,, so from a very strong perspective we use deploymentas the recommended obj to deploy workload in k8
****************************************************************************************************




class33 video7a....1:17:10)
hw is trafic manged wit canry is dis  solely on the k8 side or we are goin to be depending on the cloud provider like aws to manage the taffic
ANS;
for canry we are goin to be use what is called a k8 operator  der are k8 operator like estil that wil enable us to deploy canary so its nt abt cloud side or whatever, u jst 
need to deploy a particular operator or an add on to your cluster that wil permit that to happen.

2) is there a duration for wich blue green deployment can last 
ANS: for blue green, its nt very wide, u cud hva testing period for mayb 7day or 30day bt that may
nt really detect all the problems bt with canary we cud run a canary deployment for asl long as 6months so at a higher level of security we cud want to consider more of 
canary

most critical appl, we use blue green to deploy them e.g u want to test a vaccine , in this type of scenario we use blue green bc we cant be carrying out n operation on a
client and then realise that ther is a fault, the new version is nt as gud as the previous one and you need to roll back , that rollbk cud be diasterous, so w edeploy a 
blue green env and run a test on maybe guinea pig etc , we observer hw itruns and if it is very sucesful, we deploy to production knwing thta it shud nt fail
even wit tha ther cud stil b afailure bc the tasting period is nt like inifinte for blue green, its nt very wide, u cud hva testing period for mayb 7day or 30day bt that may
nt really detect all the problems bt with canary we cud run a canary deployment for asl long as 6months so at a higher level of security we cud want to consider more of 
canary

1:21:30
is it that each time you refresh it takes you to a diff replica set???
ANS:
************here is our cluster ,, whta is manging this pod manifest????
we are using deployment as the object. .. our deployment is hello , this deployment is manging this 2pods , bt it doesnt manges the pod directly, it manges it via ,
bt it doesnt mange the pod directly, it manges it via a replica set so when u rol out this deployment, it creates a replica set, SO FOr each version that is rolled out it
creates a replica set for it and the previous replica set becomes 0  bt they stil exists such that if you want to roll back its done with relative ease.

if am logged in and an upgrade is done will i be logged out such taht i hv to login again into a new replica set
ANS:
if its a 0downtime technique that we are using , you wont be logged out



KUB 8&9
IQ: How can scaling be automated in kubernetes? 
    By installing a guage API [ metric-server ] in our cluster and using 
       1. HorizontalPodAutoscaler[HPA] for pods   
       2. VerticalPodAutoscaler[VPA] for pods 
       3. CUSTER Autoscaler[CAS] for nodes  


CAn we use NFS TO scale inorder to meet the wrk load??
if u are refering to hw to hv multiple read replicas 
we wil be seeing hw to replicate the db so we can hv multiple read replicas

***mee** when we do, i will confirm if we introduce the nFS vol or any type of vol first before we replicate/autoscale or replictate/autoscale first before
introducing NFS 
in Kub7, in the HPA illustration, he autoscaled a diff application but when he started kub vol concept in kub8&9, he didnt continue with the same application
from kub7


KUB 10&11

  KUBERNETES DISCUSSION POINTS
    2:05
 IQ: Explain your experience in kubernetes? 
  **2.15.40.. take note about all these key points, these are discussion points....
I have over 6 years experience in kubernetes performing the following;
- setting up a multi-node self managed kubernetes cluster using kubeadm    ,kubeadm this is self managed
- setting up a multi-node production ready kubernetes cluster using  kops     ,, kops is also self managed bt it comes wit other aws services
- setting up a single-node self managed cluster using minikube and Docker Desktop for testing. (if u want to test certain appl you can deploy them on a single
node cluster
- setting up a multi-node managed production ready k8s cluster
  using amazon eks  ******* may in a video i can show us how to
*****if ther are ant issues in these appl am i able to fix them? 
- troubleshooting issues from k8s setup/configuration or installation. ,, so v been able to trpubleshoot issues like trying to stup my kubeadm n its failing,
or cant add worker node to master node, v had issues like tht n hv been able to fix it by creatin a token in the master runing in the workernode n having them
join the cluster
- maintaining, monitoring and upgrading the cluster components E.G   :
  scheduler, etcd, controllerManagers, kube-proxy, kubectl, kubelet,
  container-D, Kubernetes-cni[weave, flannel], kubectl-csi, apiServer    ***2.08.50,, these are cluster component 
  kops export kubecfg $NAME --admin 
- deploying applications and workloads using kubernetes objects:
    - pods/ReplicationControllers/ReplicaSets/DaemonSets,
      Deployments/StatefulSets/PersistentVolume/ConfigMaps and
      secrets
- using deployment as a choice kubernetes objects for stateless apps  
- using replicasets, volumes with persistenvolumes for Stateful apps  
- using statefulsets to deploy Stateful applications  
- rollouts and rollbacks of Deployments  ********** we can deploy new versions of the appl bc we knw what to do
- deploying applications using controllerManagers [RC/RS/DS/STS/deploy]
- setting up Jenkins-kubernetes integration pipeline for full automation ,,. 2.15.30... very soon we wil also look at this, i think we hv a video for it as well
- deploying both Stateful applications and Stateless applications  
- making use of objects like; PV,PVC and dynamic storage classes to 
  persist data for Stateful applications [mongodb/ES/prometheus/jenkins]
- using configmaps and secrets for a secured application deployment   
- using probes for Health checks configuration in our deployments     
- using RBAC/namespaces/IAM for a secure access in the k8s. 

#### these are some few things i shud be able to talk about ..........



 HOW DOES TRAFFIC GET TO THE PODS/CONTAINERS RUNNING IN KUBERNETES; FROM AN INFRASTRUTURE PERSPECTIVE

 1:36:00  .....   frm an infrastruture perspective
How does traffic get to the PODS/containers running in kubernetes.
we v 50m users whaen they try to access this appl, they are typing the lb dns name , based on our deployment we v deployed a cluster wich has private n public 
subnet in our public subnet der is an Elb , SO endusers are trying to access the appl tru the ELB guy. insid ethe cluster we v node1 and 9 , frm an infrastruture 
perspective, we v the frontend and we hv the backend , now  when ensuders tyep the lb url in the background a command wil be executed, the reQ  frm endusers wil 
query global dns servers searching for the nameserver so in d background nslookup is searching for the nameserver, this is taking mini seconds, some of d 
global dns service providers it wil check is godaddy, google,aws route53, once nslookup is executed it wil immediately route traffic  via the ELS url n then 
traffic gets into our cluster  .........1:56:00 (&inside our cluster we v a service called springSVC
n its routing traffic to backend pod , now any service u create in k8 must create a cluster service ip as well, he ran kubectl get svc n we cud see a clusterip
attached to the loadbalancer service that was created when we deployed the springapp service above,) so frm the elb, traffic gets into the cluster n for it to
get to the cluster it wil hv to get to the node n since its now in the cluster it wil identify which service the traffic is meant for n via the service traffic
gets to the pods, bc traffic cannot go to the pod directly the pods are discovered via the service n as such traffic wil get to the backend pod accordinly and
as part of the spring app  we also deployed a database pod , for the db we hv another service.. .. all our servers are runing in private subnet master n worker
while ELB is in the  public subnet

**mee** enusers traffic (they type lb url, the REQ, queries global dns & in the background, nslookup searches for the nameserver in eg godaddy,google, aws
route53) once nslookup is executed, traffic is routed via the elb (clusterip)into our cluster to the backend pod (appserver/db), inside the cluster the elb 
identifies which pod (app or db) the traffic is meant for & the pod is discovered via service discovery

52.30 Nginx/tomcat
WHAT HAPPENS WHEN YOU TYPE  app.com or google.com    (domain name service)
54:30
  once you type google.com it going to query global DNS searching for the webservers that are associated to this hostname and once it locates the server, immediately traffic
will be routed to that server

for example, why you type www.landmark.org, what happens is that in the backend you are going to query global DNS(global Domain name service) and there is a command is the 
backend called NS look up, it is going to be searching for the server.

eg    if i run nslookup www.landmark.org shows the address of our ngnix webserver




2:36:35      QUESTIONS

                 KOPS SERVER DIFF FROM MASTER NODE
1)FROM THE CL8 WE created using kobs i unsderstood it but, i knw we shh tru d ec2 insatnce, the server wher wecarried out the whole operation is der a way we 
can ssh into the master node using mobaxterm or vscode remote host
****ANS: we did nt nid to sh into the master node bc we created a kops sever bt tk note that the kops server is nt our k8 master node, so frm the kops server
we cud jst remotely mange our kops cl8, we did nt nid to ssh into the kops bt if we had to do that then we can stil do that


    SSH KEY & SECRET
student : cos i knw we did nt create a key pair dasts why am asking, hw do we then do it ?
ANS: WE did nt nid to create a key pair bt we craeted sssh keys while deploying our kops command , when we ran the ssh gen key command and we had exported that
key into the kops as a secret n we can use the key.


                 COMMUNICATION BTW APP & DATABASE
 2) when u tal abt hw the appl comm in the cl8 like d springapp n the dtabase,, hw does dis comm is it tru the programm that mayb the springapp like the  one
we were using like when u put ur data automatically u see it showing in the database,,,,, is it the programmer that do the database that wil create the 
interface?   
ANS:  
the fact is that we are using k8 to orchestrate containerized appl,in our team we v programers who are writing code they hv written d software that wil permit
users to write their name , dob number ,, they hv done that in the backend, we as devops engr we hv been able to build that code, create pipelines n we v been
able to containerize the appl by creatin an image and pushin the image to dockerhub,, in k8 we can pull that image n deploy the appl, onec it is deployed we v
an appl that is running which reQ usr to enter their inf and thos info needs to be captured in a database ..... how can it be captured ina database???? that 
becaomes a serious issue that is why we are now deploying a db appl called mongo in this case,,, 
HW DOES THAT APPL COMM WITH EACH OTHER IN K8 ??? it is done via service discovery and within the cl8 we use the cl8 ip service.

STUDENT: so frm what ur saying, ders a reference in the code that will link the info straight to yhe database ryt
ANS: .. of course


                        CONTAINER-D
3) i nw for k8 our container runtime is containerD, is ther  a particular reason why we using it,, is der a preference??
ANS: 
we learnt docker bc we use docker to containerize appl , once we use docker, we write the docker file, with the help of the file, we build images, the images
are our appl that have been packaged, now these packages we hv shared n distributed them to our image registry like docker hub for example, now der are 2tins
involved here: containerizin and deploying the appl ,, for u to deploy the appl it means that u hv to create the conatiner n start the container.. so the 
containerD in k8 is simply doing 2thing: it create and start the container that is all bc thats why containerD is running in the workernode that create n 
start the container so in the past we used to use docker to achieve that purpose but k8 has deprecated dockcer tahts why we no londer use docker, we sue 
conatinerD

  ***mee** so does this mean we longer need docker at all?... bc i was thinking that we will use docker to containerize then use k8 to manage the containers.


                UBUNTU USER PW
4) when u ran kops u put a pW, HW do u knw the PW to use 
ANS:
when i was creatin my kops user , user add kops
when u craete a user with ubuntu, ubuntu wil request for u to assign a PW to the user automatically , so when u ar createin a user, it wil REQ for u to assign
a PW as well

5) whne u use kops to provison ther was an autoscaling grp that was craeted , hw does the autoscaling grp works, how is it dif frm the k8 horizontal pod 
autoscaler
ANS:    
...... very imp question, i thin i missed that when i was explaining.....let me go bk and explain that
how is the autoscalin grp diff from frm what we did When we deployed a self managed cl8 with kubeabdm  that did nt cm with any autoscaler ??????


                  KOPS INSTALLATION CREATES AUTOSCALER/ PRODUCTION READY
now if u look at our ec2 instances lets observe smt  ...... 2:44:41
now am in west virgina, ther are 2worker nodes, if i delete this worker nodes what will happen?
ok , am deleting the 2instances .. obsever what happens when we shut down the instances, now lets check (in the ubuntuserver, he switched to kops user)
unbutu@master:~$ su - kops
;we can see only the master is ready , the 2worker nodes shows not ready bc we are shutting down the other2 nodes 
when we run kubectl get node : we see the 2nodes are now completely offline bc they v beeen terminated
bt now if i check my ec2 dashboard 2nodes are running and a new node is coming up (wit a diff ip address) bc we v an autoscaling grp taht was created wit min
and max and it is what is managing our node lifecycle.
we v an autoscaling grp for the master node that says hw many master node must be ther at al times, so if u delete the master nod ethe auto sacling grp wil 
craete anoda one and we also hv an autoscaling grp for worker node it works the same way .. thats why we call it production ready k8 cluster.


                          UPDATING AUTOSCALING IN KOPS
unbutu@master:~$  kubectl get svc
we hv a (springapp)lb that was created in aws
i can delete it in aws , i  can als run cli command to delete it 
kubectl delete svc springapp
once it is deleted , checking in aws  we see it says (ur resources cud nt be retrieved bc the lbwas only created when we created a type loadbalancer ssrvice
kubectl get service : but we c\nt see the (springapp)lb service again
if we run kubectl egt node, we see the master node n the 2nodes are all running now but if i want to remove the nodes completely, the only thing i can do is
to wrk on my autoscaler  .... he went to autoscaling grp in aws and he changed the desired min to zero, max to 0 and update .... the autoscaler will 
bring/shut down the nodes like ryt now we hv only the master running
*****so if u wnt to delete/stop/reduce your node just go to ur autoscaling grp and update it bring it down to zero
the same applies to the masternode .. u can udate the autoscaling grp for master

### bt am just doing it for e.g bc ,u cant be working for bank of america n just go n bring down their server bt since we ar just practising n i wnt to reduce
my cost i can do that


CONFIGMAPS & SECRET
6) where do we store the configmap and screts
ans; 
we store them in our local env nt in the scm


          EXTERNAL & INTERNAL LB
7) i need clarity for the internal n external lb, wher dey are placed cos frm the diagram u ilustrated above, u said we place the lb in the public subnet pls
xplain more

ANS\;
if u hv an internal lb u can put it in the private subnet that is ok n the external wil be in the public bc the external is internet facing so all those that
wnt to access ur env frm the internet they go tru the external


