******** explanation on how traffic is routed is in nginx tomcat & kub 10&11 & KUB 12; NGINX

KUB 14 HElm
**meeee** WHY do we have more than one cluster in kubernetes  ????
why is helm characterized with using just one cluster?????
**online
Helm is not restricted to a single cluster, but it is designed to manage one specific Kubernetes cluster at a time through a direct client-API server interaction. 
The perception of it being single-cluster-only stems from its fundamental architecture as a package manager rather than a multi-cluster orchestration tool





kubernetes 1&2


SOMEONE ASKED how many pods can we create in one node ???????????????



lets look at k8 BEST PRACTICES FOR LARGE CLUSTERS     *********** so if u have a very large cluster you can click on this link, u wil get more info
https://kubernetes.io/docs/setup/best-practices/cluster-large/
For very large clusters NB: dnt create :
   No more than 5,000 nodes
   No more than 110 pods per node
   No more than 150,000 total pods
   No more than 300,000 total containers


IQ: what is Static Pods ?
    Static Pods are controlled by the kubelet service  




KUB 6  .. Class33
what is the default deployment strategy?
  RollingUpdates  


  QUESTIONS
QUESTION......1:24:35
1) can a file be use to taint a node or must it be only commands in the CLI
ANS : anyting can be done with a file ,,,, i will have to check it up and you can check it up too

2) WHAT IS THE MOST used type of deployment
in k8 we can deploy with our containerized appl directly in a pod or we can use controler Managers like RS,RC or daemonSet bt most importantly we can use deployment and we 
use deployment it gives us the option to use diff deployment stragey like recretae, rollingUpdate and part of the deployment strategy we can use deployment techniques like
blue green OR canary deployment and that is you makingyour application available and infact deployment is maeking ur application available
once the applictaion has been made available the nxt quetsion hw wil the appl be discoverable ,hw wil ur cx discover and ultilize the appl , hw wil it be useful to them
there services need to be created, we need to expose the appl using services and der are diff services categories :
cluster IP permits you to access the appl within the cluster ,, so it exposes the apl to objects insid ethe cluster bt if its an appl that end users nid to access clusterIP
wont work therfoer wil use nodePort service or LB service to make it accessible  bc deployment makes your appl available bt  hw to i access it : service discovery


3) CAN deleted replicas be retieved  ,, bc you say we can delete it bt then hw do we roll back if for e.g a junior staff deletes it
we cant retrieve a deleted replica , once its deleted its gone
*the fact i sthat someone doesnt jst cm to ur offic eand u give him access bc in ur wrk env, we will use roll base access control like if u ar new we can permit you to hv 
access only to pod and since our pod are behind a controller managers and when the junior staff delete a pod it will be recreted again so u shu dbe senesitive enough nt 
to grant him mangers access...

4) for best practice what is the recommended number of replicas to keep  ie replicas of diff versions 
we cud keep a max of 5replica sets bc it will mean you have deployed about 5versions and the cx is happy with new verion 
bt its also subjetive to the client , some may decide to keep up to 10 replicas

5) when we rollback wnd then rollout again are new pods always created or the pods are reserved when thay are inactive
when you store those inf k8 will store the data in etcd , so it knows that version6 has the version6 of the image so when you roll back to version6, it goes back to that
particular image that was in version6 , thats what happens 
you can also rollback to a particular version choosing the version you want so when u run kubectl rollout undo deployment/web, u can choose the exact version ur rollin bk to

6) when we deploy w ecan choose for e.g 4replicas  bt when we scale to 2 is there any prefeernce in the pod that are created
d pods are identical in everything,its nt a matter of  no preference ,if you are updatingnscaling frm ur manifest file it will wrk inline wit d latest version ie d number of 
replicas u hv defined in the file bt in terms of if it will chooose which pod to create it wiill bring down all the pod wit the old versionof the imgea n bring up the pod 
wit the new version u now want and in terms of number of replicas its goin to be a function of what is defined in the manifest file 

5) when we taint a node and its undergoin an upgrade when u pass a toloration will pods be schedued on that node?
what is the rationale behind tainting a node , u taint a node bc u wnat to upgrade the node so if the node is already under upgarde ders no nid to be assigning toloration
that wil still create a pod on the node right,, we only do that in rare cases .. so toloration is now that pod is nt schduled on dis node bt i am tolorating that to happen
bt that shud only happen if the node is nt under any maintenance, if its under maintennace u wont want to do that bc what is the rationale

6) hw do we rollback to a specific version???  ..
. go to k8 and check it out so that  in the  nxt class u can give us a briefing on that
kubectl rollout undo deployment hello --to revision=1 OR revision2 n so on   ..... class33 video 5&6


class33 video5&6 (1)
1) when we create toloration, can we create it so it doesnt create pods in the master node??
ans: YES, we can do that, ther are many other options when it comes to toloration, which means we have  diff operators and diff keys and wil look at that when we look at
scheduling, how pods are scheduled on a node.

2) why will we want to schedule pod on a tainted node
e.g we want to  ensure a particular pod is scheduled on all nodes including master bc the pod wil be gathering logs on the master node to tell us if the node is healthy or nt
the master node for e.g is tainted by default but we can use toloration to allow a pod to be scheduled on the master node probbaly bc the pod will be gathering logs on the 
master node

3) what is the actual function of the selector support function of the replica set bc when we were doin the controller managers we had the replication controller n u then
showed us the replica set and u said the replica set has a selector support but when we did both of them the only diff that i notice is in d format we wrot e our API veerison
ie in the replica set and also that match label key that we used
ANS:  

we hv equality based selectors and it is used for what?  
   ReplicationCOntrollers
key:values       ********** eaulity based selectors talk abt equal conditions like key:values
app:myapp
Set base selectors: is used for ;
  Deployments
  Replica Seta
  DaemonSets
  StatefulSets
  NodeSelectors
  NodeAffinity
key: app                    for set base we can have key , value in .. lets assume the key is app , value in:javawebapp could be my app
value in:                            so 1key can hv multiple value , dats why we say setbase selsctor and it basiclaly comes wit stuff like daemonset,RS, deployment etc
   -javawebapp                     its jst that all the examples we hv done so far we v not needed to get to get into set base selector bt as we progress, we are going to
   -myapp                          look at set base selector and if u hv any problem jst wqually go to the k8 official documentation
                                    kubernetes.io abi na oi


                REASONS WHY WE USE STATIC POD
4) is der any scenario that will rEQ us to create stactic pods manged by the kubelete service as opposed to using the controller managers bc static pod itself has healing 
capabilities ACTIVATED 
ANS: YES , BT Static pod cannot scale, so if it created a pod is just a single replica
2ndly, static pod are used to create components that manage k8 like kube proxy, dns, all of those pod that manges your cluster, we use that pod to create them so that they 
will always be recreated even by the kublete service.

5) what det the object we use in deployment, is it coy base ??/ wxcept daemonSeT cos i understand its used for e.g logmgt
so what det the obj w euse for deployment
ANS:
the obj to be used depends on the diff/other components that obj will bring to the table 
deployment is said to be the recommended object for deployment in k8 or for running/deploying workload in k8 bc when u create a deployment, it creates a replica set so
it records whatevr u created such that if anything is wrong it can always rollback, thats why most of the time we use deployment bc deployment will rollout a replica set
u can rollout n rollback ,,, so from a very strong perspective we use deploymentas the recommended obj to deploy workload in k8
****************************************************************************************************


class33 video5&6 ANSWERS(2)

KUB 5&6 class33 answers (2)
Kubernetes objects used to expose/discover applications:
or kubernetes ServiceDicovery objects:
   ClusterIP   
   NodePort  
   LoadBalancer
   ExternalName   
   ingress 
   networkPolicy

                         REASONS FOR TAINTING NODE
1) what are the circumstance for wich we can taint a node and then tolorate the scheduler for pods to be scheduled on the node 
when will a node be tainted?
e.g we v a k8 cluster running with abt 11worker nodes, and it is runnin a particular version of kubectl bc kubectl is a software, remember when we configured 
our k8 cluster we install a lot of packages in the cluster, like kubectl was insatlled kubelete ,API server, etcd, scheduler, controller managers ,all of these
are conrainers that have specific versions or software, now want to recommision this server which means that we wnt to remove d current version of any of the
software that is runnin and replace it with a current versione.g kublete service from version 1.9 to version 1.11, now the process of recommissioning the server
it wil nt b gud to allow pods to be scheduled on that particular worker node so we are going to taint the node so once you taint the node ,it means you are
instructin k8 scheduler nt to scheudel aNY POD DON THE node, you are also instructing k8 to evict ANY POD that is currently runin on the node, so if der were 
any pods currently running on the node they wil be evicted and probably rescheduled on another node.
also, THE NODE COULD BE HAVING MEmory leakage , ders a problem with the node so we need to troubleshoot and resolve the problem so before we start to TS we 
will taint the node so that no pod shud be scheduled on the nodde
also generally, the amster node is tainted by default bt we hv a particular logmt appl that we want to deploy which shud gather logs even from the master node,
so we need to use toloration to allow pods to be schedule on the master node 
ALSO, we can taint a node to keep it on reserve, such that we could have some redundancy bt whenever we decide to assign node to the pod, we now use toloration,
ie torqtaing k8 scheduler to stil schedule a pod or pods on the node
if you are done recommissioning a node a simply remove the taint

2) When we use tolorations to shedule pods we can still acess the pods,, when nodes are tainted they are nt fshut down e.g master node


3) what is the default deployment strategy in kubernetes??
RollingUpdates is the default deployment strategy in kubernetes

                                          WEBHOOK/ PULL SCM
5) INORDER FOR US to update the new versionin on the deployment session on k8, that is done by webhook or pull ACM 
*************SOME ONE SAID ,, with the help of the webhook created in github wich is triggered when thers a new comit, github  then notify jenkins to do a
build ...32:17
 ans : 
another tin u shud knw is that our jobs are trigered frm JENkins, jenkins is our CI/CD pipeline, so frm jenkins if u are runin job1 , we can pass the job 
number to become the default version number of the image that is goin to be pushed to dockerhub such that when k8 is goin to pull, it is goin to dynamically 
get the latest image version that was pushed to dockerhub


                                   ADDING MSG TO ROLLOUT/ROLL BACK VERSION
6) is ther a way to add a msg such that u see what ur rollin back to
il illustrate that particular aspect in our subsequent classes, when u are rollin out a new version u pass an option that says --record so u can like tag a 
particular msg to that such that you can easily xplain what happened in a particular deployment such that if u ar goin to be rollin back to previous verisons,
u can be able to get that msg so u can use theat particular concept and if u want to rollout new versions u can create msgs to ease the processes as well


                             INTEGRATE WORK FLOW WITH POOL REQ
7)is it possible to integrate our workflow with pool REQ so that in our work env at work , someone doesnt just change the deployment witout any approval frm 
say lead engr
ANS:
its very possible,,, and thats what actually happens in our env, dats why we did pool rEQ under git such that if ders a new version of the app, developers
aaare nt comitin dicrectly to d master branch, they are developin to probably the dev branch and from that branch they nid to create a pool for other members 
to be able to review b4 it is commited to the master branch n it is only in the master branch that once der is a new commit github webhook wil b trigered to 
be able to do a buil, do a test, uplosd artifact, run sonarqude code, dockerize, push to regitry and deploy in a k8 cluster.




class33 video7a....1:17:10)
hw is trafic manged wit canry is dis  solely on the k8 side or we are goin to be depending on the cloud provider like aws to manage the taffic
ANS;
for canry we are goin to be use what is called a k8 operator  der are k8 operator like estil that wil enable us to deploy canary so its nt abt cloud side or whatever, u jst 
need to deploy a particular operator or an add on to your cluster that wil permit that to happen.

2) is there a duration for wich blue green deployment can last 
ANS: for blue green, its nt very wide, u cud hva testing period for mayb 7day or 30day bt that may
nt really detect all the problems bt with canary we cud run a canary deployment for asl long as 6months so at a higher level of security we cud want to consider more of 
canary

most critical appl, we use blue green to deploy them e.g u want to test a vaccine , in this type of scenario we use blue green bc we cant be carrying out n operation on a
client and then realise that ther is a fault, the new version is nt as gud as the previous one and you need to roll back , that rollbk cud be diasterous, so w edeploy a 
blue green env and run a test on maybe guinea pig etc , we observer hw itruns and if it is very sucesful, we deploy to production knwing thta it shud nt fail
even wit tha ther cud stil b afailure bc the tasting period is nt like inifinte for blue green, its nt very wide, u cud hva testing period for mayb 7day or 30day bt that may
nt really detect all the problems bt with canary we cud run a canary deployment for asl long as 6months so at a higher level of security we cud want to consider more of 
canary

1:21:30
is it that each time you refresh it takes you to a diff replica set???
ANS:
************here is our cluster ,, whta is manging this pod manifest????
we are using deployment as the object. .. our deployment is hello , this deployment is manging this 2pods , bt it doesnt manges the pod directly, it manges it via ,
bt it doesnt mange the pod directly, it manges it via a replica set so when u rol out this deployment, it creates a replica set, SO FOr each version that is rolled out it
creates a replica set for it and the previous replica set becomes 0  bt they stil exists such that if you want to roll back its done with relative ease.

if am logged in and an upgrade is done will i be logged out such taht i hv to login again into a new replica set
ANS:
if its a 0downtime technique that we are using , you wont be logged out



KUB 8&9
IQ: How can scaling be automated in kubernetes? 
    By installing a guage API [ metric-server ] in our cluster and using 
       1. HorizontalPodAutoscaler[HPA] for pods   
       2. VerticalPodAutoscaler[VPA] for pods 
       3. CUSTER Autoscaler[CAS] for nodes  


CAn we use NFS TO scale inorder to meet the wrk load??
if u are refering to hw to hv multiple read replicas 
we wil be seeing hw to replicate the db so we can hv multiple read replicas

***mee** when we do, i will confirm if we introduce the nFS vol or any type of vol first before we replicate/autoscale or replictate/autoscale first before
introducing NFS 
in Kub7, in the HPA illustration, he autoscaled a diff application but when he started kub vol concept in kub8&9, he didnt continue with the same application
from kub7


KUB 10&11

  KUBERNETES DISCUSSION POINTS
    2:05
 IQ: Explain your experience in kubernetes? 
  **2.15.40.. take note about all these key points, these are discussion points....
I have over 6 years experience in kubernetes performing the following;
- setting up a multi-node self managed kubernetes cluster using kubeadm    ,kubeadm this is self managed
- setting up a multi-node production ready kubernetes cluster using  kops     ,, kops is also self managed bt it comes wit other aws services
- setting up a single-node self managed cluster using minikube and Docker Desktop for testing. (if u want to test certain appl you can deploy them on a single
node cluster
- setting up a multi-node managed production ready k8s cluster
  using amazon eks  ******* may in a video i can show us how to
*****if ther are ant issues in these appl am i able to fix them? 
- troubleshooting issues from k8s setup/configuration or installation. ,, so v been able to trpubleshoot issues like trying to stup my kubeadm n its failing,
or cant add worker node to master node, v had issues like tht n hv been able to fix it by creatin a token in the master runing in the workernode n having them
join the cluster
- maintaining, monitoring and upgrading the cluster components E.G   :
  scheduler, etcd, controllerManagers, kube-proxy, kubectl, kubelet,
  container-D, Kubernetes-cni[weave, flannel], kubectl-csi, apiServer    ***2.08.50,, these are cluster component 
  kops export kubecfg $NAME --admin 
- deploying applications and workloads using kubernetes objects:
    - pods/ReplicationControllers/ReplicaSets/DaemonSets,
      Deployments/StatefulSets/PersistentVolume/ConfigMaps and
      secrets
- using deployment as a choice kubernetes objects for stateless apps  
- using replicasets, volumes with persistenvolumes for Stateful apps  
- using statefulsets to deploy Stateful applications  
- rollouts and rollbacks of Deployments  ********** we can deploy new versions of the appl bc we knw what to do
- deploying applications using controllerManagers [RC/RS/DS/STS/deploy]
- setting up Jenkins-kubernetes integration pipeline for full automation ,,. 2.15.30... very soon we wil also look at this, i think we hv a video for it as well
- deploying both Stateful applications and Stateless applications  
- making use of objects like; PV,PVC and dynamic storage classes to 
  persist data for Stateful applications [mongodb/ES/prometheus/jenkins]
- using configmaps and secrets for a secured application deployment   
- using probes for Health checks configuration in our deployments     
- using RBAC/namespaces/IAM for a secure access in the k8s. 

#### these are some few things i shud be able to talk about ..........



 HOW DOES TRAFFIC GET TO THE PODS/CONTAINERS RUNNING IN KUBERNETES; FROM AN INFRASTRUTURE PERSPECTIVE

 1:36:00  .....   frm an infrastruture perspective
How does traffic get to the PODS/containers running in kubernetes.
we v 50m users whaen they try to access this appl, they are typing the lb dns name , based on our deployment we v deployed a cluster wich has private n public 
subnet in our public subnet der is an Elb , SO endusers are trying to access the appl tru the ELB guy. insid ethe cluster we v node1 and 9 , frm an infrastruture 
perspective, we v the frontend and we hv the backend , now  when ensuders tyep the lb url in the background a command wil be executed, the reQ  frm endusers wil 
query global dns servers searching for the nameserver so in d background nslookup is searching for the nameserver, this is taking mini seconds, some of d 
global dns service providers it wil check is godaddy, google,aws route53, once nslookup is executed it wil immediately route traffic  via the ELS url n then 
traffic gets into our cluster  .........1:56:00 (&inside our cluster we v a service called springSVC
n its routing traffic to backend pod , now any service u create in k8 must create a cluster service ip as well, he ran kubectl get svc n we cud see a clusterip
attached to the loadbalancer service that was created when we deployed the springapp service above,) so frm the elb, traffic gets into the cluster n for it to
get to the cluster it wil hv to get to the node n since its now in the cluster it wil identify which service the traffic is meant for n via the service traffic
gets to the pods, bc traffic cannot go to the pod directly the pods are discovered via the service n as such traffic wil get to the backend pod accordinly and
as part of the spring app  we also deployed a database pod , for the db we hv another service.. .. all our servers are runing in private subnet master n worker
while ELB is in the  public subnet

**mee** enusers traffic (they type lb url, the REQ, queries global dns & in the background, nslookup searches for the nameserver in eg godaddy,google, aws
route53) once nslookup is executed, traffic is routed via the elb (clusterip)into our cluster to the backend pod (appserver/db), inside the cluster the elb 
identifies which pod (app or db) the traffic is meant for & the pod is discovered via service discovery

52.30 Nginx/tomcat
WHAT HAPPENS WHEN YOU TYPE  app.com or google.com    (domain name service)
54:30
  once you type google.com it going to query global DNS searching for the webservers that are associated to this hostname and once it locates the server, immediately traffic
will be routed to that server

for example, why you type www.landmark.org, what happens is that in the backend you are going to query global DNS(global Domain name service) and there is a command is the 
backend called NS look up, it is going to be searching for the server.

eg    if i run nslookup www.landmark.org shows the address of our ngnix webserver




2:36:35      QUESTIONS

                 KOPS SERVER DIFF FROM MASTER NODE
1)FROM THE CL8 WE created using kobs i unsderstood it but, i knw we shh tru d ec2 insatnce, the server wher wecarried out the whole operation is der a way we 
can ssh into the master node using mobaxterm or vscode remote host
****ANS: we did nt nid to sh into the master node bc we created a kops sever bt tk note that the kops server is nt our k8 master node, so frm the kops server
we cud jst remotely mange our kops cl8, we did nt nid to ssh into the kops bt if we had to do that then we can stil do that


    SSH KEY & SECRET
student : cos i knw we did nt create a key pair dasts why am asking, hw do we then do it ?
ANS: WE did nt nid to create a key pair bt we craeted sssh keys while deploying our kops command , when we ran the ssh gen key command and we had exported that
key into the kops as a secret n we can use the key.


                 COMMUNICATION BTW APP & DATABASE
 2) when u tal abt hw the appl comm in the cl8 like d springapp n the dtabase,, hw does dis comm is it tru the programm that mayb the springapp like the  one
we were using like when u put ur data automatically u see it showing in the database,,,,, is it the programmer that do the database that wil create the 
interface?   
ANS:  
the fact is that we are using k8 to orchestrate containerized appl,in our team we v programers who are writing code they hv written d software that wil permit
users to write their name , dob number ,, they hv done that in the backend, we as devops engr we hv been able to build that code, create pipelines n we v been
able to containerize the appl by creatin an image and pushin the image to dockerhub,, in k8 we can pull that image n deploy the appl, onec it is deployed we v
an appl that is running which reQ usr to enter their inf and thos info needs to be captured in a database ..... how can it be captured ina database???? that 
becaomes a serious issue that is why we are now deploying a db appl called mongo in this case,,, 
HW DOES THAT APPL COMM WITH EACH OTHER IN K8 ??? it is done via service discovery and within the cl8 we use the cl8 ip service.

STUDENT: so frm what ur saying, ders a reference in the code that will link the info straight to yhe database ryt
ANS: .. of course


                        CONTAINER-D
3) i nw for k8 our container runtime is containerD, is ther  a particular reason why we using it,, is der a preference??
ANS: 
we learnt docker bc we use docker to containerize appl , once we use docker, we write the docker file, with the help of the file, we build images, the images
are our appl that have been packaged, now these packages we hv shared n distributed them to our image registry like docker hub for example, now der are 2tins
involved here: containerizin and deploying the appl ,, for u to deploy the appl it means that u hv to create the conatiner n start the container.. so the 
containerD in k8 is simply doing 2thing: it create and start the container that is all bc thats why containerD is running in the workernode that create n 
start the container so in the past we used to use docker to achieve that purpose but k8 has deprecated dockcer thats why we no longer use docker, we use 
conatinerD

  ***mee** so does this mean we longer need docker at all?... bc i was thinking that we will use docker to containerize then use k8 to manage the containers.
***meee** NO; I bliv in the past they used docker D or smt like that but now k8 has containerD , it is used to deploy the application ie create containers using images
BUT to create/modify images inorder to package the application, we still need docker.

****online
Docker Desktop and the Docker Engine utilize containerd as their underlying container runtime. While Docker provides a comprehensive platform with tools for building,
managing, and orchestrating containers, containerd is the lower-level component responsible for executing and managing the lifecycle of containers.
Therefore, when you use Docker, you are indirectly using containerd, as it acts as the core engine for running your containers.



                UBUNTU USER PW
4) when u ran kops u put a pW, HW do u knw the PW to use 
ANS:
when i was creatin my kops user , user add kops
when u craete a user with ubuntu, ubuntu wil request for u to assign a PW to the user automatically , so when u ar createin a user, it wil REQ for u to assign
a PW as well

5) whne u use kops to provison ther was an autoscaling grp that was craeted , hw does the autoscaling grp works, how is it dif frm the k8 horizontal pod 
autoscaler
ANS:    
...... very imp question, i thin i missed that when i was explaining.....let me go bk and explain that
how is the autoscalin grp diff from frm what we did When we deployed a self managed cl8 with kubeabdm  that did nt cm with any autoscaler ??????


                  KOPS INSTALLATION CREATES AUTOSCALER/ PRODUCTION READY
now if u look at our ec2 instances lets observe smt  ...... 2:44:41
now am in west virgina, ther are 2worker nodes, if i delete this worker nodes what will happen?
ok , am deleting the 2instances .. obsever what happens when we shut down the instances, now lets check (in the ubuntuserver, he switched to kops user)
unbutu@master:~$ su - kops
;we can see only the master is ready , the 2worker nodes shows not ready bc we are shutting down the other2 nodes 
when we run kubectl get node : we see the 2nodes are now completely offline bc they v beeen terminated
bt now if i check my ec2 dashboard 2nodes are running and a new node is coming up (wit a diff ip address) bc we v an autoscaling grp taht was created wit min
and max and it is what is managing our node lifecycle.
we v an autoscaling grp for the master node that says hw many master node must be ther at al times, so if u delete the master nod ethe auto sacling grp wil 
craete anoda one and we also hv an autoscaling grp for worker node it works the same way .. thats why we call it production ready k8 cluster.


                          UPDATING AUTOSCALING IN KOPS
unbutu@master:~$  kubectl get svc
we hv a (springapp)lb that was created in aws
i can delete it in aws , i  can als run cli command to delete it 
kubectl delete svc springapp
once it is deleted , checking in aws  we see it says (ur resources cud nt be retrieved bc the lbwas only created when we created a type loadbalancer ssrvice
kubectl get service : but we c\nt see the (springapp)lb service again
if we run kubectl egt node, we see the master node n the 2nodes are all running now but if i want to remove the nodes completely, the only thing i can do is
to wrk on my autoscaler  .... he went to autoscaling grp in aws and he changed the desired min to zero, max to 0 and update .... the autoscaler will 
bring/shut down the nodes like ryt now we hv only the master running
*****so if u wnt to delete/stop/reduce your node just go to ur autoscaling grp and update it bring it down to zero
the same applies to the masternode .. u can udate the autoscaling grp for master

### bt am just doing it for e.g bc ,u cant be working for bank of america n just go n bring down their server bt since we ar just practising n i wnt to reduce
my cost i can do that


CONFIGMAPS & SECRET
6) where do we store the configmap and screts
ans; 
we store them in our local env nt in the scm


          EXTERNAL & INTERNAL LB
7) i need clarity for the internal n external lb, wher dey are placed cos frm the diagram u ilustrated above, u said we place the lb in the public subnet pls
xplain more

ANS\;
if u hv an internal lb u can put it in the private subnet that is ok n the external wil be in the public bc the external is internet facing so all those that
wnt to access ur env frm the internet they go tru the external





KUB 12; NGINX INGRESS
 ****NOThing from the video but, i  took some infor form nginx-tomcat & kub 10&11

1)NGINX-TOMCAT
QUESTION             WE CAN USE EITHER AWS ELB OR NGINX  ***mee** NGINX IS self manged manual configuration
i know we hv lB in AWS , THAT means if we are nt using nginx, we can use AWS LB
yes
and rhats what we will see when we get to k8 and AWS 
but its ver imp that you get the picture first
bc why do we need a webserver or Load balancer
load balancers helps to 
1)load balancers
                                                                    users >>> LB >>>> APP >>>> DB
2)security: Acts like a layer of security ie if anyone is trying to hack into our app it can be stopped at this stage which is very important 
3)health check: if its routing traffic/load balancing to about 30servers it ensures that it does not route traffic to a server that is not healthy, so it runs health check in 
the backend 
4)patching upgrading of our servers

2) KUB 10&11
managed or self managed  LB 
if i create a self mangaed lb, wit the self managed LB, i may create a server n in the server, i wil install a software like ngnix afterwich i wil deter hw 
service is routed
self managed =
   NGINX   



KUB 13 EKS INSTALLATION



KUB 14  HELM

...questtion
1) i installed the EKS Ctl tool 
with the EKS ctl tool, i created a 2nd cl8 with the EKS ctl create 
i use the eks ctl delete cl8 to delete the cl8 bt the the one the GUI i use EKS ctl to deletete the cl8 also , i wanst able to delete
it bt it did delete the node grp and i was wondering why it didnt delete the cl8 bt the node

ANS:
EKS has what is called EKS ctl 
EKS CTL Is a comand line utility for EKS, elastic kubernetes service
u can actually create ur cl8 by running eks ctl create cl8 or aws create cl8 , any one
n if ur trying to delete the cl8 using command, most of the time u must first delete the cl8 dependency like node grp
so if a node grp was created in that cl8, u must first delete the node grp , delete the de[pendency before deleting the cl8

2) WHAT IS THE BESTS TOOL WE CAN USE TO MANAGE OUR CL8

ANS:      it all depends 
maybe u want to ask hw we can best deploy our cl8
............u can deploy ur EKS cl8 using terraform scipt, u can use commands to deploy your EKS ie rather than going to the console 
u can jst run on the CLI , aws  EKS create cl8 ( the name of the cl8) that wil create it or eks ctl create cl8 bt u nid to ensure 
that your EKS command line utility has already been installed 
so u can use :
commaNd
console 
terraform
once u do that u can now proceed to deploy appl bc ur main task is appl deployment
most time at wrk u are goinmg to join a coy that already has running cl8 , it cud be EKS cl8, kubeabm cl8, kops cl8
once the cl8 is already existing all u nid is to use the cl8 to deploy appl, so main task now is appl deployment bc u wrk in an env 
with existing cl8 already , so u are goin to be worried abt how  appl are ruuing that are installed and exposed , u hv vol installed and all of that.


3) DIFF bTW helm and aws EKS 
k8 comes wit  a cl8 the cl8 cud be EKS cl8, kubeabm cl8, kops cl8, now once u aleady hv a cl8 u nid to be able to deploy wrk load in the cl8
the question now becomes how can i deploy workload ????  for u to be albe to deploy a work in my cl8, u id a command line utility called kubectl
u cud aslo use the GUI to deploy apkl , tahts what u nid for deployment, now aprt from using kubectl only we hv a package manager  we can use
to deploy called helm and helm can be deployed in any cl8 be it kops, eks etc once its installed u can then use it to deploy Ur appl

DIFF BTW HELM AND EKS 
 helm is a package manager for k8 while EKS is a k8 cl8 that comes with a fully managed controled plane provided by aws
so one is is a cl8 and the other is a command line utility and with the help of helm, u can reder ur manifest file, it can create the 
manifest file for u. 

4)   CAN U CONSIDER KOPS IN THE SAME LINE AS HELM??? .... is it the same as helm

ANS:
kops is a software used to create a k8 cl8
what do u need to deploy ur appl in k8 , u nid running cl8 , a cl8 that is functionig 
a cl8 is a grp of nodes  , that cl8 may v been created using kops or u cud hv created it using aws k8 service or using kubadm
it doesnt amtter what u hv used,all u nid is a cl8,  once u hv  a cl8 u can deploy appl 



kub 16

NICE explantion for :  .. 2) Explain your experience in kubernetes?? .......  18:00
my question: when is hosted zones created

4:00     ................... watch it
you would be ask what you have been able to use k8 to solve in your environment
ITS A Common experience when it comes to k8, either they want u to explain your experience or they just want to discus some problems u may v encountered using k8 and hw you
were able to fix those problem. also when u apply k8 thersa lot of xperience u gather n der a lot of problem uve been able to solve, 
so the xpectation is for you to be able to state clearly the kind of problems uv been able to fix applying k8 in ur env

also at times , they ask to xplain  k8 architecture
this is a very imp aspect in k8      


6:00
this is a very imp aspect in k8 n u shud be able to xpln dem                        

1) Explain the kubernetes architecture??  
   masterNodes/controlPlane:
made up of 
      apiServer  : wich is the main adminstartor, the entry point into our cl8
/etcd/scheduler/controllerManagers
   WorkerNodes:
      kubelet/kube-proxy/containerRuntime-Container-d/  
these are the component
we also have the
   kubernetesClient|: 
      kubectl / UI- Kuberenets dashboard
********thes are what we can use to mg8 task in k8 when it comes to architecture

2) Explain your experience in kubernetes??


  COMMON ERROR IN KUBERNETES
common errors in kubernetes:  
1)  pods are in pending  state 
  pullimage error / imagepulloff   
   WRONG  image: mylandmarktech/hello:20     
          mylandmarktech/hello:22   
2) authenticationerror:
  mylandmarktech/nodejs-fe-app:2  
  imagePullSecrets:
  - dockerhubcred
3)KOPS CLUSTER DEPLOYMENT ISSUES: like
  IAM user not authorise     ............. we nid this to create a kops cl8 in aws
    create an IAM role with required permissions/policy  
       VPCFULLACCESS/EC2FULLACCESS/S3FULLACCESS and attached
       to the kops control server 
    Attached required IAM policies to the IAM user/group and   
    run aws configure  
