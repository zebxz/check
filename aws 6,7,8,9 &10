MY TS EXPERIENCE: I tried installing tomcat with user script ie pasting installation script while launching an inatance but it wasnt working bc d https link to install
tomcat wasnt the latest version, so i had to google tomcat download and tcopy the correct https link  

its good to hv multiple lB so if one is down, the one that is running wil b  able to sustain the resources that are down  
###### i installed my docker server in private SN and it wasnt accesible on google bt when i installed anoda one in publicSN, it worked 

######prof power point script not complete 1>47>39 ... tomcat script and also create jumpserver and docker server
Video8a, 1:46:20 .. the video is amnong the docker videos... . .....   ask what makes a port unhealthy? .... 1:46:45. he said what does d health of d server depend on,it
depends on the fact that the port 8080 is open,its running ders smt ruuing on the port ,, we can use the curl command to check 

the course to knw hw to manage the resources hosted by AWS ,, understanding the process of maanaging the computing services in the AWS environment
aWS cloud architecture/ aws solution architect

QUESTION:
video 6 ... OUR sand box didnt hv a public ip.... so u said 
1. By default, from the jumpserver we can ssh 
   into the sandbox using the publicIP  
so does it mean, we then v to create our sand box server to hv a public ip address.. & if so that means the connection is not private 

a target group can hv up to 1000 targets

vpc is used to create isolated ntwrk

VIDEO 7 .8:33 WE CAN PEER RESOURCES in 2 diff ntwrk providers like gcp & aws .. e.g aws can be our and gcp can be an on premp resource
bc they ar nt in d same cloud provider platform ..... using diff options like vpm , aws direct and etc 

DIAGRAM:.....15:44
WHEN U CREATE A VPC, it comes wit its own nTWKR and did is a private ntrk & as a private ntwrk, hw wil the resource communicate with each other e.g dbser commu wit appserve
11:28 if the app server& dbserver ar in d same ntwrk,ie a local ntwrk e.g vpc1, they can comm wit their pivate ip but if in dif ntwrks e.g one server is in vpc1 & the 
17:28 oda server is in vpc2 then they can comm wit vpc peering by doing so, we create a private ntwrk btw the two vpcs.. we wnt to pair the 2 vpcs

HOW TO ESTABLISH VPC PEERING
this can be achieved in the same region and across regions 
23:25 

CHECK tELEGRAM FOR steps in the handout ... aws vpc27 pdf
Step 1)Create 2 VPCs - VPC-A and VPC-B with non-overlapping CIDR range
e.g of overlapping, is when the 2diff vpcs both v severs with the same ip address as illustated below.. its nt gud when they overlap bc when i ping the ip adress, the 
broadcast wont know if its searching for appserver1 or appserver2 
VPC-1 - 10.0.0.0/16......... cIDR blocks 
   appServer1 [ 10.0.0.66 ]...... ip address
VPC-2 - 10.0.0.0/24  ...... CIDR block 
   webServer1 [ 10.0.0.66 ]..... ip address

##### e.g2, without overlapping
vpc peering connection
======================
VPC-1 - 10.0.0.0/24
   appServer1 [ 10.0.0.66 ]
VPC-2 - 10.10.0.0/24  
   webServer1 [ 10.10.0.66 ]

ping 10.0.0.66  
ping 10.10.0.66  

vpc peering connection.... without overlapping
======================
VPC-1 - cidr block= 10.0.0.0/24

   appServer1 [ 10.0.0.66 ]

VPC-2 - cidr block=  10.10.0.0/24  
   webServer1 [ 172.0.0.66 ]

             

i created the 2nd vpc to pair with in oregon , the first vpc was already created in virginia 
29:45frm step one above create vpc.. .. vpc^more-name-10.10.0.0/24- AZs:1 - publicSN: 1- privateSN:1- gateway: in 1 AZ- create

1. vpc1 request for a peering connection (private nterk) with VPC2   
2. vpc2 ACCEPT the peering connection from VPC1  

WE V TO MODIFY THE ROUTE TABLE SUCH THAT DER CAN B A PRIVate ntwrk established.. 

in virginia, select peering conection- name- selectvpc to pair wit:project pair-..thers anoda option to pair vpc with- rgion:another-go into d other region, copy d vpc id 
paste it-create- go into the other region in action:accept the connection, meaning we can peer vpcs in d same aws acct or in an anodaaws acct,.in this case we wnt to 
do it in the same accoutn bt our 2nd vpc is in another region... the pairng vpc cud be in the same region or anoda region 

41:15,, modify the route tables of VPC1 -selsct route tables-tick publicSN of the created vpc:-edit: add 10.10.0.0/24- peer connection-save ... do the same in the privateSN 
 of the same vpc....TO est conection wit VPC2 via the pairing connection
46:50 we also go to the other region, the receiving vpc and modify the route table for vPC2- add 10.0.0.0/24 for both the publicSN and privateSN .... so we hv created route
for secure access by modifying the route tables so that we can v a private secure connection.. by default, the route table will permit local route frm 10.10.0.0/24 local
& 0.0.0.0igw to permit access tru the igw,, we also v 10.0.0.0/24pc.. this is establshing a private connection uisng the vpc peering connection,by virtue of this modification
we attaching these to our publicSN 0.0.0 igw &privateSN 0.0.0.NAT.the access To the internet is oneway via the NAT  & we v a pairing connection, this is what we v been able 
to establish.

####51:15 ... SANDBOX .. 
A sandbox is a test server , the server can be used for testing...
the envirn wher we perfom testing is called sandbox server, we first deploy in the sandbox if it wrks well then we deploy in the right environ
.yes since we hv done the peer connection, we can connect to the sandbox from the jumpserver privately, we can est a private connecion.


Ticket0013
 ===========
Deploy applications to production for paypal client.   
e.g, i hv 
  1. 8 production appServers with [ 192G RAM / 900GB SSD ] each

For best performance ensure that adequate testing is done  
  2. first, deploy in your sandbox/test server  

###55:20 to create a sandbox
launch instance- linux-micro- pem key- select the created vpc-prvateSN- ip:disable-SG:ssh  custom 10.0.0.0/24, so dat resources in the vpc can comm wit me via ssh, i also
wnt wnt an ssh connection est in this sandbox so:ssh custom 10.10.0.0/24, so frm both vpc am able to ssh privately- launch
the sandbox doesnt hv any public ip, its running in the privateSN

ssh jumpserver in mobaxterm
1:1:18 to acces my sandbox in mobaxterm
ssh -i "sand.pem" ec2-user@10.10.0.139

in mobaXT ,in my jumpser,creating a new key,-vi sand.pem :paste- bc my key is open, chmod 400 sand.pem, to change d key permission, then my key is secured- 
ssh -i "sand.pem" ec2-user@10.10.0.139 ..

######i edited the wrong route table so my sandbox refused to connect, but once i resolved it , it connected

sandbox is running in vpc2:
  privateIP  =  10.10.0.134
  chmod 400 aws33.pem
  ssh -i "aws33.pem" ec2-user@10.10.0.134

jumpserver is running in vpc1:
  privateIP = 10.0.0.54  
  publicIP  = 18.191.89.63
  ssh -i awskey33.pem ec2-user@18.191.89.63
  ssh -i awskey33.pem ec2-user@10.0.0.54

1. By default, from the jumpserver we can ssh 
   into the sandbox using the publicIP    

1. from the jumpserver we can ssh into the sandbox using the privateIP 
   via vpc peering with route tables modified accordingly     


vIDEO  7: Elastic Load Balancers& AUTO SCALLING
====================================
Running notes for ELB/ASG  starts
====================================
tomcat script didnt install the tomcat

13:40 its nt a secured practice to allow direct traffi to app servers so we create a web server ..  webserver manages hw traffic is routed... it routes traffic to the backend application servers
the websever has waht is called target,,, ther a target grp .. e.g target grp for my FB apps ..
bt in a situation wher the webserver breaks down that will be a problem

EXAMPLE OF WEBSERVERS/LB SOFTWARE
nginx
httpd

16:00 After installing, we v to configure & the configuration has certain parametrs
webserver has listerners and backend 
it has listeners to traffic using http 80 protocol or https  443,  from the app users and routes traffic to the  backend  app via their ip address 10.0.0.7 and the server
port number e.g 8080 =10.0.0.7:8080but the webserver is a self managed solution & we can hv a situation where we hv backup webservers to cover up when webserver1 is down
but all the configuration constitute a very tidious job

so we can go with a managed service ie paaS... AWS has provided us a manged srvice 
WE JUST CREATE our elb ... then aws decides the kind of software to install .. whether ngnix, https, they are incharge of that,, 
in the background, aws will create 2webservers in 2aZs for availability, so u dnt bother whether the server wil fail or not
so ur tassk is jst to create/config ur listeners/target groups
thats whAT elb IS ALL ABOUT

23:37 ... 1)THERS ALSO NTWRK LOAD BALANCER
it deals with source and destination, &when it comes to d target grp dey ar created using TCp id or protocol & a trget grp can v up..
to 1000 targets and we will do all the config ..tcp= source &destination..video 8a (1:11.. d protocol here that it suport, the listener is tcp got to do wit source& destinatn 
this falls under layer4support..... ntwrk lb is faster than ALB BC NTwrk is source to destination bt for ALB when it receives a trafic it has to filters the tarfic to knw the
the right target to route the trafic to .... also it has multiple target grps wjile ntwrk has one target grp... ntwrk LB ia faster bc its routed on layer4 of the osi model &
its the transport layer dedicated for transport so by default for transmissn data layer4 is super fast
layer7 the application layer, route trafic base on content of the trafic.


24:25.... 2)  thers also application load balancer(AIB)
IT will use the http/https protocol,, in dis case , we can v multiple target groups/ diff target grps
the applications are grouped with the help of a target grp
the AIB falls under layer7 support.

3) thers also gateway LB , a new option which AWS now hv

interview: do u v any experience with layer4 support, nterk load balancers 
cos once we get into kubernetes, its going to be abt routing traffic to multiple backend application ... . 

38:00 APP SERVER - name -linux- micro-SELECT created vpc:pubSN-key-ENABLE AUTO- advance deatails:user data:paste d tomcat instalation script,to instal &start tomcat- launch
SG: SSH TCP 22  0.0.0/0, HTTP TCP 80 0.0.0/0, SSH TCP22 from any

create docker-app.. everytin is the same as aPP SERVER THEN PASTE the simple script for instaling docker .. they must be in the same VPC
SG: SSH TCP 22, HTTP TCP 80, ALL TCP , TCP from anywher 0.0.0/0

##### we can hv up to 1000 targets in a one target group ... 1:31:55

49:30 CREATE LOAD BALANCER- name-internat facing(means it cn receive trafic frm ext sours &route d trafic-ipv4-the same vpc as docker&app-same vpc-pubSN- SG- add 
listener-create target grp:instances-name- TCP:80:80 .(we chose tcp/UDP bc its a ntwrk LB)-IPV4-HEALTH:tcp: we can also click adv:3,3,10,10...ie if the LB Ping the target 
server 3times &ders no response, it wont route traffic to the target-NEXT-select D required apps-portnmber it listens to e.g8080or 80 for deocker-tick include as pending-
create target grp-go back to the load bALancer being created &select thetarget grp-create load balancer... we can also add up to 50 listeners

1:02:20
TO ADD A TARGEt to an existing LBT:CEATE LOAD BALANCER- name-internat facing-ipv4-the same vpc as docker&app-same vpc-pubSN- SG- add listener-create target grp:instances-
name- TCP:80-IPV4-NEXT-select the required apps-portnmber it listens to e.g8080or 80 for deocker- tick include as pending-create target- THEN CLICK Target groups-register

so if we are trying to access our application, we will access it via the LB,

we can check online to see if our servers were installed 
publicIP:8080
56:50 we v to be able to access our app server & docker server directly or our LB wont be able to route traffic 

1:03 we can now copy the dns name of our lB to access our app or doecker server and it is more secured accessing our application via the LB 








13:30

Elastic Load Balancers = ELB:
  rules   
  Listeners 
  target groups with targets   
  health check on the targets  

  LB & elb 
Create your Load Balancers in an aws Region:
  aws will create 2 instances in 2 AZs  
  aws will install/configure a Load Balancing sotwares   


install tomcat:
===============
#!/bin/bash
# RedHat Server
# Tomcat installation
cd /opt 
sudo hostname tomcat3
sudo yum install java-1.8.0-openjdk-devel -y
sudo yum install git wget -y
sudo wget https://dlcdn.apache.org/tomcat/tomcat-9/v9.0.83/bin/apache-tomcat-9.0.83.tar.gz
sudo tar -xvf apache-tomcat-9.0.83.tar.gz
sudo rm -rf apache-tomcat-9.0.83.tar.gz
sudo mv apache-tomcat-9.0.83 tomcat9
sudo chmod 777 -R /opt/tomcat9
sudo sh /opt/tomcat9/bin/startup.sh

============================
#!/bin/bash
sudo hostnamectl set-hostname docker
sudo apt update -y
sudo apt install docker.io -y
sudo service docker start
sudo docker info
sudo usermod -aG docker ubuntu
docker run --name myapp -d -p 8080:8080 mylandmarktech/spring-boot-mongo 
docker run --name hello -d -p 80:80 mylandmarktech/hello 
sudo su - ubuntu  

http://18.117.152.63/
paypal-nlb-e6f6ecdfc53d90c0.elb.us-east-2.amazonaws.com

http://paypal-nlb-e6f6ecdfc53d90c0.elb.us-east-2.amazonaws.com/



power point script



VIDEO 8a

############ QUESTION   ...after running this , scp-i key name.pem target/*war ec2-user@publicip of d app servr:/opt/tomcat9/webapps/ .. why do we still nid to run 
cp target/*war / opt/tomcat9/webapps/

5:47 
ELS is better than LB because we dnt bother abt the conf, avil,,, someone manages that for u 
ELS falls under Paas,,, routing trafic to backend application servers, we dnt v to worry abt installing softwares, load balancing softwares etc
load balancers can be either netwrk layer4 or application load balancer layer6
with the help of the target grps we ar able to route traffic to the applica
the loasd bal runs /performs health check
LB makes use of listener,, it listens on ports/protocols
users makeS rEQ like http get reQ, post reQ, delete  REQ

IF WE WANT To access our backend application, it goes tru a ntwrl LB url
Load balancers & webservers generally go together
14:50 e.g of load balncers that can b installed
ngnix
haproxy
http

we hv application servers wher applications ar being deployed
18:49for traffic to be routed appriopriately, we v to do load balancing, it can be a load bal or ELS
WE require a software wich helps us achieve load balacing with relative ease e.g ngnix or h ah proxy
the LB does 2 tins , it either accepts or rejects the REQ.. .. meaning tht LB ARE impoertaNT BC IT ACTS As A security measure.. e.g someome trying to access the server wich
we dnt want, it will reject the reQ.... SO if it accepts it will route tracffic to the app servers running in the backend.

WHAT DETERMINES HOW TRAFFIC ARE ROUTED AND WHEN SHUD TRAFFIC BE ROUTED 
inside the LB, WE DETERMINE How traffic will be routed .. we can create some rules, so if it accespts traffic it will route traffic based on the rules e.g if it has this 
options route it to this particular target.......  for the lb to knw the target grp to route to , :
rules will be deinfed, e.g we can config our backend instructing the lb dat if someon types this ip addresss on our listenere port route the traffic to the backend target grps
it will run health cheack on the tagerts
target groups with target 
REQ/traffic frm users goes tru the ELB, and for the it to receive the trafic it listens with its listeners  , it listens on some ports and protocols 
34:45 lb is like a server with  some sofware installed in it e.g if u install an ngninx software in a software in a server its an ngnix webserver, ha proxy installed in the
the server, its an ha proxy LB 
servers listen on protocol and ports
48:20  we v to mk sure the webservers and app servers are up/running and healthy

the OSI model 
different layers   read power point script

1:04:50 for us to hv content base routing, that wil tk us to application LB 
1:24:00 CREATE LB
1:44:40 assign hostanme & change shell
1:46:30   we can use the curl command to knw if the target is healthy .. curl -v ip address:8080 , curl -v localhost:8080
creae a  redhat app server and paste the install script
to know the ports that are open  ... netstat -utlpn ... sudo yum install net-stat 


1:47:50 inside the jumpserver using curl -v public ip of the app server:8080  inside , he checked if the app server port number is healthy  but to check the heath of
the jumpserver he curl -v localhost:8080 ..... so i bliv using the ip address, we can check the health of one server in another server 

1:49:20 install tomcat 
 users --->talk to --- elb --- > route traffic to --- app-Servers
users traffic are routed to the app serers via the LB 

quetsion is a jumpserver an instance without an installed applicationn like tomcat, jenkins etc
###### 1:55:09 DEPLOY AN APP & see how LB wil route traffic to the application

1:55:29 in real time wil use maven to automate the process......... tomcat was installed in the jumpserver
deploy maven web app to tomcat- inside the jumpserver clone the application...in real time...  -gitclone:clone the repo-ls , we v the maven web app- rename:nwa-ls-cd mwa-
inside maven web app ie nwa , we wnt to create packages we can be able to deploy - mvn pakage :to create package sudo yum install maven -y (it installs maven & all
its dependencies like jave) - ls,2:00 we now hv the target dir- we wnt to deploy to d app server whose publicip we wil use as the tomcat server & to deploy to anoda server
usimg d SCp bt it will ask for d key of the app server bc we nid to be authenticated b4 we can copy -vi key name &paste  -  chmood 400 key name.pem - 
scp-i key name.pem target/*war ec2-user@publicip of d app servr:/opt/tomcat9/webapps/ .. once authentication is done, below ,we can see the file that was copied|| 
using scp-i, we wnt to copy the app code ie *war  or file "maven web app.war in the target dir that was created when we did mvn package to the tomcat server and i am ec2user 
bc d key am using is ec2user key and in tomcat we deploy in /opt/tomcat9/webapps/ dir

ls target/ .. and we can see the maven web app . war
 then to deploy, we hv to copy CP THE file to webapps - cp target/*war /opt/tomcat9/webapps/ .. when we ls /opt/tomcat9/webapps/ , we can see the copied file




VIDEO 8b
cloud computring engr takes care of the infrastrure in the cloud, establishing the right security for you vpc
its all building infrastruture in the cloud and managing it, like EC2 and other required resources
7:51 PROFF: for any org to operate they nid to manage their applications in a container, we call the containers computers  and the computers can be owned by the company 
or 3rd party, if its owned by the cop ,its called on prem infrastruture bt if  they choose to rent servers, an entire networking envi , data bases etc then that is what 
cloud computing  is all about, so if the cop decides to rent, u nid to v an indept understanding of hw all that is able to work 

the course to knw hw to manage the resources hosted by AWS ,, understanding the process of maanaging the computing services in the AWS environment
aWS cloud architecture/ aws solution architect


   18.119.105.192
   $ sudo yum install net-tools

   nlb1-7f9e896ea7e69c2b.elb.us-east-2.amazonaws.com
   http://nlb1-7f9e896ea7e69c2b.elb.us-east-2.amazonaws.com/maven-web-app/


   users ----> app-Servers

   users ---> elb --- > app-Servers    
   ns lookup  = 
   dns lookup nlb1-7f9e896ea7e69c2b.elb.us-east-2.amazonaws.com
   18.191.85.171

   Create hostname = dominionapp.com 
   Create dns records:
      dominionapp.com  ---  nlb1-7f9e896ea7e69c2b.elb.us-east-2.amazonaws.com
      dominionapps.net ---  nlb1-7f9e896ea7e69c2b.elb.us-east-2.amazonaws.com

dns records:
  a records 
     Hostname: IPaddress
       simon  --- 4372152483  
  PTR:    
  c-name records  [aliases]:
    landmark --- mylandmarktech   

   domain name servcie   

 Which Region did we create our NLB: us-east-2 [Ohio]
My domain name: dominionapps.net
NLB:  nlb1-7f9e896ea7e69c2b.elb.us-east-2.amazonaws.com 

webapp.dominionapps.net --> nlb1-7f9e896ea7e69c2b.elb.us-east-2.amazonaws.com 

webapp.dominionapps.net/maven-web-app 
http://webapp.dominionapps.net/maven-web-app/
http://webapp.dominionapps.net/maven-web-app/ 

  webapp.dominionapps.net/
  
  webapp.dominionapps.net/maven-web-app 

  myALB-178479865.us-east-2.elb.amazonaws.com/maven-web-app

  dominionapps.net --- myALB-178479865.us-east-2.elb.amazonaws.com/

  dominionapps.net/maven-web-app

https://www.td.com/ca/en/personal-banking/  [50 appServers]

     prof  = Simon Legah  

   /maven-web-app  

 bought a domain name  :
  simonlegah.com    
  olu.com   

applicationS        TargetGroupS
 maven-web-app      [webappTG]
 tdapp              [TDappTG]
 myApp               PayPalappTG


We can created a-records  

Host  
Rule:
  dominionapps.net          ---Forward TO: webappTG
  td.dominionapps.net       ---Forward TO: TDappTG
  pay.dominionapps.net      ---Forward TO: PayappTG

  webapp.dominionapps.net
  
http://dominionapps.net/

https://dominionapps.net/  == 

https://dominionapps.net/maven-web-app/  

https://www.td.com/ca/en/personal-banking/

Path
   / 
   /maven-web-app   
   /java-web-app  
   /my-app  
   /td-app  

Explain your experience with SSL/TLS certificate  

  http ---> https    

SSL redirect:    
http://dominionapps.net/  == 
    https://dominionapps.net/

http://dominionapps.net/ 

ASG / LC / LT:


ASG:
  Horizontal Scaling
  Hertical Scaling

appServers:
Scaling Policy
  Minimun  = 2
  Desired  = 2
  Maximum  = 100
 
 add instances if:
  cpu usage > 75% or    
  mem usage > 80%

1. Create a Launch configuration  
   Create a Launch Template  
2. Use your Launch Template to create your Auto Scaling Group  [ASG]
3. The auto Scaling group will create the Desired/required number of servers 
   using Scaling Policy and the Launch Template 


Golden AMI:
My AMI: 
 ubuntu / redhat  



Launch instances  = 
IAM:

EC2  
storage  [ebs, s3, efs]
ASG  
ELB  
VPCs. 
IAM = 
======================================================
Terraform videos, scripts  and Running notes in GitHub
======================================================
Docker and Kubernetes MasterClass
==================================




5. JENKINS-TOMCAT INTEGRATION:
============================= 
1. INSTALL 'Deploy to container' Plugin on Jenkins UI
       JENKINS uses plugin to extend it functionality

2. ADD A TOMCAT USER in /tomcat9/conf/tomcat-users.xml 
   vi /tomcat9/conf/tomcat-users.xml 
   mylandmark landmark 

<user username="landmark" password="admin123" roles="manager-gui,admin-gui,manager-script"/> 
<user username="dominion" password="admin123" roles="manager-gui,admin-gui,manager-script"/> 
<user username="LandmarkTechology" password="admin123" roles="manager-gui,admin-gui"/>


1. aws cloud computing

What is Cloud Computing ?
Cloud computing is the delivery of computing services—including 
  - servers,
  - storage,  
  - databases, 
  - networking, 
  - software, 
  - analytics, 
  - and more
 over the Internet (“the cloud”)  hosted at a remote data center managed
 by a cloud services provider (CSP).
   CSP = aws, GCP, Azure, alibaba, vmware, salesforce, oracle, ibm, 

 aws cloud = 
  - servers,     = ec2 instances  
  - severless,   = Lambda functions,
  - storage,     = ebs, efs, s3, 
  - databases,   = rds [ mySQL, mariaBD, posgressSQL, arura,  ], nonRDS[ dynamoDB,  ]
  - networking,  = vpc, 
  - software,    = ami, SDLC, 
  - analytics,   = CloudWatch, 
  - and more
  - security     = 

  Netflix =   S3  bucket

IAM = 
=====================
Netflix ---   
   DevOps Engineers   
   Developers 

Cloud Engineering  
Infrastructure Engineering
  Infrastructure MGT [ create, view, update, delete, modify, grant access ] 
===========================
CONSOLE  = GUI     :
   Prune to errors 
   Time consuming 
   Visibility is challenging  
   limited automation - 5%  

Commands = CLI  = aws s3 ls :
   Prune to errors 
   Time consuming 
   Visibility is challenging  
   limited automation - 55%  
   It cannot be easily replayed or redeployed
   it can't be version controlled  

IaC  = codes    = files  = IaC / Terraform  :
   It is not Prune to errors 
   saves time  
   Visibility is very easly  
   great automation - 99%  
   It can be easily replayed [dev/stage/prod]
   it can be version controlled   

resource "aws_vpc" "tesla-dev" {
  cidr_block = "10.10.0.0/24"
  instance_tenancy = "default"
  tags{
    Name = "tesla-be"
    Environment = "dev"
  }
}

resource "aws_vpc" "tesla-stage" {
  cidr_block = "10.10.0.0/24"
  instance_tenancy = "default"
  tags{
    Name = "tesla-fe"
    Environment = "stage"
  }
}
=========================================
Team members can manage resources using the console, cli or IaC.
However there must be authenticated and authorise    

IAM: This is a key security service in aws used for  
     authentication  and 
     authorisation for Engineers and other team members to run different tasks. 
 aws-account: 
   root-User =   
   IAM-USER  = 

Assignement:
Ticket-AS110:
  Group aws services covered so far based on Global, Regional and Availability Zones
  vpc = 

Access management:
  IAM User groups = 
    managers [AdminAccess] , 
    developers, [VPCREADACCESS, S3FULLACCESS, EC2READACCESS ] 
    Engineers [VPCFULLACCESS, S3FULLACCESS, EC2FULLACCESS]   
  IAM Users       = simon [VPCREADACCESS] , class33, James[VPCFULLACCESS]   
  IAM Roles
  IAM Policies - are Permissions that can be assigned to users/groups/IAM-Roles
                1. VPCREADACCESS / 2. VPCFULLACCESS  

Ticket00133:
  Create iam user account access for; Class33, Simon and James  
  Create user-group access for; managers and developers & Engineers
  Assign admin access to the managers group    
  assign VPCFULLACCESS, S3FULLACCESS, EC2FULLACCESS to the Engineers group
  Add Simon to the manager's group  
  add james to the developers group  
  Assign EC2READACCESS to class33 user        

 aws-account: 
   root-User = 
      root-email =  landmark@gmail.com 
      root-password = admin123@001  
  IAM-USER  = 
   https://287784533479.signin.aws.amazon.com/console
    userName = simon  
    password = Admin@123 
    accountID= 287784533479

  AdministorAccess  -- ec2, s3, vpc, route53  
  EC2FullAccess     -- 
  EC2ReadOnlyAccess -- 
Security is inherent in our environment 
we use the principle of least priviledges 

IQ: Which tasks is an IAM user with admin access unable to do? Billing  

Users can have either:
  console access [userName and password and accountID]  or 
  programatic access using [accessKey and secretAccessKey]
  to aws resources    

   accessKey      =  AKIAUGAPXTS7AGZNQ600
   secretAccessKey=  0OeifliOM4J0lUbOLPvDFDP/Vb4QNwN6haIxyI24

aws configure 
   accessKey
   secretAccessKey
   defaultRegion  
   output format [table, json]  

aws s3 ls = aws command not found  

$ aws s3 ls
An error occurred (AccessDenied) when calling the ListBuckets operation: Access Denied


aws ec2 describe-instances
aws ec2 describe-instances --filters "Name=tag:Name,Values=webserver"
aws ec2 describe-instances --filters "Name=tag:Name,Values=appserver"
$ aws ec2 terminate-instances --instance-ids i-5203422c

https://www.bluematador.com/learn/aws-cli-cheatsheet

aws ec2 describe-vpcs | jq -r '.Vpcs[]|.VpcId+" "+(.Tags[]|select(.Key=="Name").Value)+" "+.CidrBlock'
aws ec2 describe-vpcs

aws ec2 terminate-instances --instance-ids i-029abc614ea3dd26c i-0b9c2fae27ed0cc9e

 iamRoles are Policies/Permissions like [ VPCFULLACCESS, EC2FULLACCESS ] 
 that can be attached to another aws resource like [ ec2, eks, ecs   ]  
  
IAM-Roles can be attached to an aws resources [ec2 Instances, eks, ecs,etc.] 
to permit the resource manage other resources based on the Policies attached 
to the role 
  class31-role [S3ReadOnlyAccess]   

like 
  

https://docs.aws.amazon.com/cli/latest/userguide/cli-usage-help.html
https://aws.amazon.com/cli/

Identity providers
Account settings

===================================
Terraform and other IaC tools to manage aws resources
=====================================================
Terraform
CloudFormation 
Ansible  
Terraform:
=========
- support Multiple clouds [aws, GCP, Azure]
- codes/files are used   

Ticket00148 - create a vpc in us-east-1 using:
  1. console  - netflix-1c
  2. cli      - netflix-2c
  3. IaC - Terraform   - netflix-3c 
terraform codes are written in HCL - HASHICORP configuration lanaguage   
terraform codes has .tf extentions  
   .sh[shell script] / 
   .java[java codes] / 
   .py [python codes]
   .tf [terraform codes]

18hours to cover terraform:  
===========================

Next week = starting  
  containers 60 hours : 
    docker     - containerisation and 
    kubernetes - container orchestration  
  provisiong and Infrastructure mgt  :
    Terraform  
    Ansible  
  python:

11AM EST / NewYork / Toronto / MD time 
4PM GMT / LAGOS / DOUALA

   32  aws s3 cp aws33.pem class30b
   33  aws s3 cp aws33.pem s3://class30b
   35  aws s3 cp  class30b/Dockerfile .
   36  aws s3 cp  s3://class30b/Dockerfile .
   37  ls
   38  pwd
   39  aws s3 cp  s3://class30b/Jenkinsfile /home/ec2-user/
   40  ls
   41  aws s3 cp  s3://class30b/Jenkinsfile  s3://class33aa
   42  aws s3 ls class33aa












