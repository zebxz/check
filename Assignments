building and deployment starts after codes have been commited, so if i ever need to do all this, ill just start with maven 

 
APPLICATION DEPLOYMENT   ***tomcat1&2**
which kind of projects are we managing?
we are managing java based projects - projects that are developed in the java lanaguage
*****mee***  jboss/wildfly supports/used for enterprise application while tomcat supports jar/standalone & war/web applications




   ****mee** REMEMBER TO CLONE/fork ALL the necessary repos for each topic/software & check if any project was assigned




linux1
1)Create an account to a REdhat linux server/system in AWs cloud uing a manged cloud computing providers (aws, azure, gcp etc)
because this option is superfast, easiet option -within 5mins, i can buy my server with AWS **** the other 2options are in the notes
so create a free account  in Aws cloud  or any cloud provider, of ur choice
eg, Website: aws amazon. Com
2)Launch an amazon linux server in Aws:
3)Connect to our linux server


linux2
TICKET001:
Create work directories for telsa client

TICKET002:      create directory (mkdir)
create project 01  directory using the format below 
dev/git/maven/aws/nexus/java


LINUX 3A & 3B  was linux commands etc




LINUX 4B
Assignment:
Assign permission for the ec2-user group to modify the blessed.me file  
chmod +r fileName 
chmod 664 fileName  

                      file   file
Full Permissions      0666   0666
default Permissions   ?    =    ?            0666-0624 = 0042
                      ----   ----
 umask                0600   0624
                      ----   ----  


default permisssion=  0666 - 0624 = 0042


***************************************************************************************
Assignment: i  set myself
Assign permission for the ec2-user group to modify the billions file  
chmod +r fileName 
chmod 721 fileName  

                      file   file
Full Permissions      0666   0666
default Permissions   ?    =    ?            0666-0721= 0935  OR 0045
                      ----   ----
 umask                0711   0721
                      ----   ----  

default permisssion=  0666 - 0721 = 0935 ( subractracted mathematcally by borrowing )lol




Ticket077: Search for a file called list
find = search for files and directories  
searching a file in the user's home Directory:
   find /home/ec2-user -name fileName or find ~ -name fileName 
   find /home/ec2-user -name list  or find ~ -name list  
searching a file in the present working Directory:
   find /home/ec2-user/dev -name list   or   find . list     

searching a file in the root Directory: 
sudo -u root find / -name fileName
  find / -name list 
  sudo -u root find / -name list    
  sudo find / -name list  
[ec2-user@demo dev]$ sudo -u root find / -name list
/sys/kernel/debug/error_injection/list
/sys/kernel/debug/kprobes/list
/home/ec2-user/dev/list
/home/ec2-user/list



Assignment:
Assign permission for the dominon user to read the blessed.me file

chmod 600 filename
chown = use to change file ownership
chgroup = use to change file group ownership


chmod +r fileName :  gives evryone permission to read
the correct code = chmod 604 fileName  


********************
obi will be working on the blessed.me for this sprint, 
please grant ownership of the file to obi  
This practice is good for automation and easy deployment
of tasks/workloads. 

ANS:
chown newOwner fileName   
chown obi blessed.me    
[ec2-user@demo ~]$ chown obi blessed.me
chown: changing ownership of 'blessed.me': 
  Operation not permitted
This is because:
chown and chgroup commands can ONLY be run by the rootUser
sudo is a command used to run commands as another user  

**************  therfore the correct command : 
sudo -u root chown obi blessed.me 
    sudo chown obi blessed.me  
sudo -u obi  chown obi blessed.me      

before you run the command mk sure the owner is running the command  ( i bliv chown without sudo , u hv to be rootuser)
[ec2-user@demo ~]$ sudo - u root chown obi blessed.me   OR  sudo chown obi blessed.me



***********     TO change group ownership

[ec2-user@demo ~]$ sudo -u obi  chgrp obi blessed.me
chgrp: cannot access 'blessed.me': Permission denied

sudo chgrp obi blessed.me



Ticket078:
  Create user accounts for landmark and datti and verify?  :

Ticket079:
  assign a password the user 'datti'
  passwd userName  

  passwd datti 

TICKET009:
DATTI grant oke sudoer access
chmod +r fileName 
chmod 664 fileName  


 linX4b 
 QUESTION1:
Ticket078: Search for a binary file called 'pwd' 
   binary files are commands found in the bin/sbin directories
whereis pwd 

c) searching a file in the root Directory:
  find / -name list 
  sudo -u root find / -name list    
OR   sudo find / -name list  
********** the output to this command is the root path to the file 

Ticket078:
  Create user accounts for landmark and datti and verify?  :


TICKET009:
DATTI grant oke sudoer access
   sudo echo "oke ALL=(ALL) NOPASSWD:ALL" | sudo tee /etc/sudoers.d/oke


LINUX5B
Ticket078:
  1. Create user accounts for landmark and datti and verify?  :
  2. assign password to landmark and datti users?  :
  3. grant sudo access to landmark user ONLY?  :
  4. Set the expiration of datti account to 90days ?  
  5. configure/setup your server for password authentication?  
  6. connect to the server externally as landmark as landmark user using password?
  7. Lock datti's password and server access?  
  8. Create manager's group and add user landmark to it.


LINUX 6

Ticket088:
==========
install, start and verify the apache webServer
sudo yum install httpd -y        (install, this is  package mgt command )               
systemctl status httpd              (system/service mgt command )
ps -ef | grep ntpd              ( service is called daemon) ******* to chwck if the netwrk time protocol for the server is running 
ps -ef | grep httpd                     (process mgt command)
sudo systemctl start httpd             (service mgt command)
sudo systemctl enable httpd           (service mgt command)
sudo systemctl start ntpd

*** to insatll ntpd; check google (how to insatll ntpd)
sudo yum install chrony

********** this ticket involved 
1)package mgt
2) service mgt
3) process mgt


LINUX 7

TICKET 004:

John is unable to connect to the server. Please explain what could 
be the problem.
1. Check if John is running the ssh commands correctly
    ssh userName@ipaddress vs ssh ipaddress@userName 
    ssh 172.31.31.46@John  vs ssh John@172.31.31.46 

2. Check if the ssh-Port22 is open on the firewall/SG and 
   respond accordingly[]  
   inbound Rule: open port 22 for John to have access    

3. Check if the server is up and running 
     ping ipaddress/hostname/dns    

4. check if the ssh service(sshd) is running and react accordingly   
     systemctl status sshd 
     sudo systemctl status sshd  



SCRIPTING1&2
Tasks - ticket0014:
  TK-deploy-00123 
write a shell simple script to deploy applications 
1. Create a deployment directory  
2. create a deployment; app.java file  
3. assign read Permission to app.java file
4. changing ownership of app.java file 
5. copy the file to the app directory  


SCRIPTING 5&6
TICKET0017 - Write a simple script to install and start apache
  ( he also added some content to a new file: /var/www/html/index.html ), this file is called index.html, it is a webserver ( Jesus is lord directed into the index.html file)
   

ticket 0047, create a new user in our env
ANS:
 Import/call/invoke the usermgt function    **** meee ( rember the code has to hv been written already)


IQ:
Assignment/Ticket:
  1. Write a script that monitors servers every minutes 
     This script should alert management of anomalies 
  2. Write a script that backup dbServers every midnight

Execution:
1. We shall use cronJobs and create cron tables to achieve this 
   Automation and Schedule the tasks to run as expected. 








GIT1     ***** done
ASSIGNMENT 

Class32Teams:
Project:
  1a. Create your GitHub account 
  1b. Onboard a new project for a FinTech Client
        organisation / teams / repository
  2. Managers and assistant
       Create a Team in your created organisation for paypal and add members of your 
       your group with write access 
b.Create repositories in SCM [GitHub] 
      repo url = https://github.com/landmarkss/paypal


GIT 2  **** done
Ticket01:
  Create a dev branch from the master branch  
  Switch to the dev branch and create the app.java file    **** so vi java application development
  Commit the changes and Switch to the master branch  
  Review the changes in dev and merge with the master branch  



                                         MAVEN


1) Ticket_maven-001    .....  ***************** DONE
Install Maven on a RedHat Linux 9 Server  

2. Java is a pre-requisite for maven to run 
    JRE --> JAVA RUNTIME ENVIRONMENT
    JDK --> JAVA DEVELOPMENT KIT 1.8+
            JVM will also be installed      (once java is installed, this installs automatically)

 43:30
we already hv some notes in our githubwhich we can use for maven installation , package management, maven installation


mavenHomeDir = M2_HOME = /opt/maven :


STEP4 :

SEt environmental variable for specific user eg ec2-user
ls -a  /home/ec2-user/
vi ~/.bash_profile    and add lines below
export M2_HOME=/opt/maven
export PATH=$PATH:$M2_HOME/bin



STEP5: 
    Refresh the profile and verify if maven is running
source ~/.bash_profile
  To see if maven has been installed: mvn - version



********************************************  ALWAYS REMEMBER TO cd into the project dir (eg mkdir java projects)
1)Standalone Applications          *** done
Ticket_saa_tesla0014  
===================
Requirements:
1. project repository in the SCM [GitHub / GitLab]
   https://github.com/Landmark-Technologies/maven-standalone-application       ********** our repo from our source code mgt is in github
2. We need a server with java & maven installed and configured   
3. Create a project directory in the maven/build server
    mkdir java-projects  
4. Clone the codes from github in the project directory  
   git clone https://github.com/Landmark-Technologies/maven-standalone-application         ********  this means that developers have written code and committed to github
     src/main  
     src/test


********************************************  ALWAYS REMEMBER TO cd into the project dir (eg mkdir java projects)

2)maven-web-applications:       *** done
=======================
https://github.com/LandmakTechnology/maven-web-application
git clone https://github.com/LandmakTechnology/maven-web-application
 
1) to leave msa  ==cd ..
2) we clone
3) Rename : mv maven-web-application/ mwa
4) cd mwa
when we ls: we can see our maven web app, developers have written the project file pom.xml, but we dnt have the target dir, we also hv some files & dir; src dir which is very 
important bc if we are going to do a build the 2files maven is using is the pom.xml and the src
5) mvn package
ls 
we now have a target dir
32:00
6) vi pom.xml
7) ls target/ and we have an appliaction called tesla.war
we have deployed this application bc inside our build server we executed mvn clean, this will delete the old builds and create new ones
therefore we have done a build for web application, just incase you are asked to do one 
when we vi pom.xml we can see the final name tesla but its going to create a war package


  examples of web applications (whatever it is it must end with war)
maven-web-app.war
boa-app.war
paypal-app-0.0.1-SNAPSHOT.war
app.war
tesla-web app.war


********************************************  ALWAYS REMEMBER TO cd into the project dir (eg mkdir java projects)


3))Maven Enterprise applications:         *** done
  MavenEnterpriseApp-ear.ear
  MavenEnterpriseApplication.war

https://github.com/mylandmarktechs/maven-enterprise-application
git clone https://github.com/mylandmarktechs/maven-enterprise-application


1) cd..
2) clone
3) mv maven-enterprise-application/meapp
4) cd meapp
5) tree

in the tree we can see the parent pom.xml below while the child pom.xml above in the tree are 2

52:00
to view child pom.xml = cat maven enterprise App- web/pom.xml
when your in a parent pom.xml you will see a parent tag

since we have our project files written by developers we can build 

6) mvn package 

we have 2 modules when we run ls
1) maven enterprise App-ear 
2) maven enterprise App-web pom.xml

ls maven enterprise App-ear = we see pom.xml src target
ls maven enterprise App-ear /target/ = application.xml maven-archive 
                                          maven enterpriseApp.ear




                TOMCAT
my Question, from aws
can we use userdata to instal maven/sonar/nexus, i see we started using it when we got to 'AWS2;( Used to install webserver) & AWS7/8 to install docker&tomcat
userData - This is a script that can run while creating/launching the serve

      ****** From aws video, i see i can use userdata to installl tomcat     


1) TIcket: TOMCAT INSTALLATION
Install tomcat

2)Ticket:
  Change the default portNumber for tomcat from 8080 to 8177 

3)TICKET
Enable external tomcat mgt access 
create tomcat user with access roles
deploy to tomcat using PW & ssh key ( As at when i practiced in sept 2025, it didnt wrk, i kept getting error of 'permission denied' even after doing everytin
correctly & engr amstrong was not helpful


  TICKET 0014   nginx , Apache  http 
   write a script  to deploy apache webserver 


installing apache as the rootuser  = sudo - i 
vi apache.sh  & create a script ( webserver installation) 


  this script will start, enable & verify if apache is running or not 

  #!/bin/sh
# install apache as the admin/root user  
sudo yum install httd -y 
sudo systemctl start httpd
sudo systemctl enable httpd 
echo devops is good  >> /var/www/html/index.html                        ****** copy to a file called index.html
if i want to write the above a an html code 
17:50   echo <h1> and easy with landmark  </h1>   >> /var/www/html/index.html
mkdir  /var/www/html/google 
echo  <h1> landmark  google  </h1> >> / var/www/html/google/index.html            ***** save some web content in google dir 
systemctl status httpd 
ps -ef |  grep httpd 



SONAR

NEXUS



JENKINS 1&2

Ticket001:
Install Jenkins in redhat9 server (ec2 instance in aws)
   https://github.com/LandmakTechnology/package-management
   https://www.jenkins.io/doc/book/installing/   :
   www.jenkins.io                             **********    the website of jenkins , this is the official document for jenkins 
   https://www.jenkins.io/doc/book/installing/linux/

Resource2: where can i go to either i can go to the company documentation


Ticket002:
  Create an automation ci/cd job using Jenkins and other associated tools for a FinTech  
  Java based web application.    
 project repo: https://github.com/LandmakTechnology/maven-web-application
 private project repo: https://github.com/LandmakTechnology/maven-web-app


JENKIN3

Ticket003:
tesla-webapp2023 PROJECT: =  
Onboard a new project for Tesla  web-app =  
Create a Jenkins job to test, build and deploy the application to a tomcat server
configure build triggers to automate the build process   
Requirements:
  1. Create Teams in our GitHub company a/c add and assign member's roles and tasks
  2. Create a github repository for the  project  
  3. share the repository details with Team members and developers for Source Code Mgt in SCM  
  4. Install and configure:
      jenkins SERVER setup for ci/cd Automation
      setup jenkins-maven integration to automate builds   
      setup jenkins-SonarQube integration to automate CodeQualityAnalysis  
      setup jenkins-nexus integration to automate artifacts uploads     
      setup jenkins-tomcat integration to automate application Deployment
      setup nginx as web server for secure application access by end users  
  6. Create a Jenkins job for the project    (i bliv this means do a build, code quality, create repo in nexus & backup & deploy)
  7. configure Jenkins:
        git Integration
        GitHub  Integration
        maven Integration  
        SonarQube Integration  
        nexus integration  
        tomcat integration  
        notification [slack, email]

  git clone https://github.com/LandmakTechnology/maven-web-app          = privateRepo    
  git clone https://github.com/LandmakTechnology/maven-web-application  = publicRepo



JEN4&5 A
Install maven pluggins

JEN 4&5 B
INSTALL PLUGGINS IN JENKINS,
JENKINS MASTER -SLAVE ARCHITECTURE/CONFIGURATION



JENKINS 6

Ticket0055:
  Create a tesla-wepapp Jenkins scripted pipeline job:
 deploy the application and add the file in our SCM/ source code

Ticket
Create a tesla-wepapp Jenkins declarative pipeline job: 


JENKINS 7&8
Ticket005
============
Create a Mulit-Branch pipeline job for tesla
 https://github.com/Landmark-Technologies/maven-web-application
 we build from 3branches: master  development  stage 
some companies may hv a project with 50 branches


IQ :  Create a Jenkinsfile using both default & custom name and share it using SCM.

TO clone code, i nid git and the repository

to write a good code we should avoid repitition and we can avoid repetition by making use of function"${mavenHome}/bin/mvn package
so the use of function is very important for our devops deployment bt that is scipted pipeline.

Ticket
Create a shared library



AWS2
userData - This is a script that can run while creating/launching the serve
########Ticket044 = Create a and install a webserver in aws (Use Userdata)...... webapp can be used to serve some web content
with the help of ec2 intance we are able to create servers and connect to them



AWS3
Ticket0048:
  Create, attached & mount 5G to the /tesla directory 
  Create, attached & mount 7G to the /var/lib/jenkins directory 

Create snapshot



AWS4
Ticket001
 1. create an s3 bucket and add objects without public access 
2. create an s3 bucket with public access and add objects    


Ticket002
 1. enable public access on the objects in your s3 bucket   



AWS5
Install ngnix

27:56 ###pg 83 what deters the no. of resources that can be placed within each vpc is the cidr block / the no. of addresses  a vpc can hold 
Create a VPC for paypal client with the capacity of 200 resources
Ticket0011:
  Create a VPC for paypal client with the 200 addresses   
  cidr block: has a preface wich can range from  0 - 32 

Ticket0011:
  Create a VPC for paypal client with 200 addresses in 2 subnets  




when i practice ill hv to tk note of the connection btw the jumpserver & the webserver& the db/app servers (like why the diff subnets & which subnet has the IGW attached to it)
*** 1.04.44, in the diagram i see the jumpserver & the webserver in "subnet public us west-2a &  the dbserver & appserver in  "subnet2 private us-west-2b

ticket
create subnet
route tables
Nat gateway/NACL
launch jumpserver
launch dbserver
for security, establish a private connection, ie Connect to the app/dbserver via the jumpserver
launch webserver (install ngnix)


AWS6

  TICKET : ESTABLISH VPC PEERING

MODIFY THE ROUTE TABLE SUCH THAT DER CAN B A PRIVate ntwrk established.. 

TICKET 
Create a sandbox

Ticket0013
 ===========
Deploy applications to production for paypal client.   
e.g, i hv 
  1. 8 production appServers with [ 192G RAM / 900GB SSD ] each

For best performance ensure that adequate testing is done  
  2. first, deploy in your sandbox/test server  
 


AWS7/8
TICKET
STEPS FOR THE APPSERVER TO CONNECT TO THE LB


TK not of the diff between ALB & NLB

23:37 ... 1)THERS ALSO NTWRK LOAD BALANCER /    *** Meee (LAYER 4 support)
it deals with source and destination, &when it comes to d target grp dey ar created using TCp id or protocol & a trget grp can v up..
to 1000 targets and we will do all the config ..tcp= source &destination..video 8a (1:11.. d protocol here that it suport, the listener is tcp got to do wit source& destinatn 
this falls under layer4support..... ntwrk lb is faster than ALB BC NTwrk is source to destination bt for ALB when it receives a trafic it has to filters the tarfic to knw the
the right target to route the trafic to .... also it has multiple target grps wjile ntwrk has one target grp... ntwrk LB ia faster bc its routed on layer4 of the osi model &
its the transport layer dedicated for transport so by default for transmissn data layer4 is super fast
layer7 the application layer, route trafic base on content of the trafic.




AWS8b

CREATING DOMIAN  NAME


AWS 9

CREATE RECORD SET/HOSTED NAME  USING DNS
CREATING ALB
CREATE A RECORDS & DEFINE RULES
ENCRYPT DATA
SSL REDIRECT
STICKY SESSIONS
AUTO SCALE
 CREATING A LAUNCH TEMPLATE FROM THE SCRATCH WITHOUT AN AMI

??????#### some said he was askeD in the interview hw he (d interviewer) gave e.g of xray hw do ur private subnet to d outside , hw do u configure that& he told him vpn bt
at the end he asked the interviwer what he wud do and he told him endpoint 
*** prof wil xplain hw to use vpn endpoint and relational endpoint e.g when a database is crsated ina  private subnt and u wnt ot access it in a dif envir like a kubenetes
cluster then u nid the endpoint of the database

????if i create an account in a server n der are many servers and nxt time am in another server, is der a way to replicate all the data that is on the first server to this 
present server, ie concerning LB.... prof yes ders a replication process , once an application ar captured,once u access an applica u v d option to write data into the
application n ders  genearallyy a data base stuff we look at once we get into docker , hw to use databases n mk our life a little more easy.




AWS 10 & 11

Assignement:
Ticket-AS110:
  Group aws services covered so far based on Global, Regional and Availability Zones
regional=  vpc , route table, subnet
global =  route53,iam , 

ASSIGNMENT
Ticket00148 - create a vpc in us-east-1 using:
  1. console  - netflix-1c
  2. cli      - netflix-2c
  3. IaC - Terraform   - netflix-3c 


Ticket00133:
  Create iam user account access for; Class33, Simon and James  
  Create user-group access for; managers and developers & Engineers
  Assign admin access to the managers group    
  assign VPCFULLACCESS, S3FULLACCESS, EC2FULLACCESS to the Engineers group
  Add Simon to the manager's group  
  add james to the developers group  
  Assign EC2READACCESS to class33 user   


DOCKER 1&2

TICKET
Install Docker on Ubuntu         ***i bliv he used userscript

Ticket011:
  Containerise the java based application in the SCM repository below;  
  https://github.com/LandmakTechnology/maven-web-application

Ticket012:
  Create and share a docker image 


Ticket011:
  Containerise the java based application in the SCM repository below;  
  https://github.com/LandmakTechnology/maven-web-application

the challenge for this ticket is to realise that the docker script used doesnt have the stage for 'maven build' inside it that requires maven installation & 
bc of that when we run 'docker build' it will fail.
In docker5&6, we treated multi stage file ie a file with multiple 'FROM' keyword, that contains several stages *eg stage for repo to clone, stage for maven to 
build) etc, required for the complete deployment of an appl




DOCKER 3&4

Ticket014:
Prepare a jenkins ci/cd job for maven-web-application 

TICKET
 MK image distributable


TICKET
ADD and COPY are kEYWORDS IN the dockerfile

TICKET
TAGGING/MAKING THE IMAGE DISTRIBUTABLE 

TICKET
Docker pull ngnix
CREATE A DOCKER FILE USING httpd image we pulled 


TICKET
# TO PUSH IMAGES TO AWS AMAZON ECR 


Ticket0015 -  : this is a github repository ,, apart from github we also v a dockerhub account
1. the github repo , wher the codes ar found , wher develpers ar pushing code 
https://github.com/LandmakTechnology/python-flask-app
2. the python flex application


DOCKER 5&5B
7:35 TICKET0016
Ticket0016
==============
 TICKET: Deploy a nodeJS web application using docker:


DOCKER 5&6
TICKET 3.11.25
Conterize and deploy the nodejs appl   ***(mee) ie clone it, build the image and run it ie 'docker run'
 https://github.com/LandmakTechnology/nodejs-application


TICKET
 A) copy from a container ; docker cp webapp:/usr/local/tomcat/webapps/tesla/jsps/home.jsp
*********** didnt work***  bc am using the relative path to the file we are trying to copy
     ****mee***  so from the example he did,i have to find out what am suppose to do when i attem dis ????
B) Copy to a container ; docker cp home.jsp webapp:/usr/local/tomcat/webapps/tesla/jsps/
Docker commit


DOCKER7
the challenge in this ticket is to see how to deploy the database container as stateful ie needs to maintain its state, therefore it needs 
a piece of storage to capture data, therefore we can create vol with bind mount ie create a mountpoint OR Preferred docker volume concept
in 5&
Ticket024:   **** includes;HOW TO CHANGE MOUNT POINT (ill use step6 in place of step4)
  Deploy a microservice application for tesla.  
  - GitHub repository
    https://github.com/LandmakTechnology/spring-boot-docker
  - dockerHub repository
    mylandmarktech/sping-boot-mongo

crteate custom netwrk
deploy in the custom bridge netwrk
deploy in the host netwrok
create docker null/none netwrk


DOCKER8&9
Deploy the database image with a docker volume   ..... Docker home dir :  DHD = /var/lib/docker
Deploy the database image with an external volume
install docker compose
deploy an application with a docker compose file , should include a custom bridge netwrk & a piece of docker vol or external vol
***i bliv the netwrk can be already existing ie before creating the compose file,we can create it using command & then inside the compose file we indicate
'true'


DOCKER10
install docker swamp
Deploy a stack, it will create an overlay netwrk so i dnt need to create any netwrk like in docker/docker 8&9 assignement
but this stack should include a vol
*** meee** deploy using a compose file this will have the 'deploy strategy' that has the 'replica option'

Ticket014:     
﻿﻿﻿﻿Prepare a jenkins ci/cd job for maven-web-application
         **************************************************IN the pipeline stage one is to clone frm scm , ur building using maven9
1.cloning the latest version of the application = SCM/github
2. building using maven
3. running code quality analysis with sonarQube
4. uploading artifacts in nexus
5. pre-deployment
     1. containerizing the application by creating
       docker images using Dockerfile
      distributing the images in docker image Registry
       dockerhub/Nexus/JFrog
6. Deployment TO UAT environment using kubernetes
7. APPROVAL[manual or auto] 8. Deployment to Production environment using kubernetes
9. email/slack notification




KUBERNETES
1&2
 **** meee*** we want to setup/install/ deploy a multi node cluster ,, he didnt use userscript in AWS but used installation script in mobaxterm
Ticket 001:  .. always remember to use my own token ...............            53;12
  Setup a multi nodes self Managed kubernetes cluster using kubeadm.
  requirements -- 

1. check the kubernetes official documentation  :
https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/

2. check the company's documentation for kubeadm setup    : 
https://github.com/LandmakTechnology/package-management/blob/master/kubeadm/READme.md

*******************in our env, we v created github repo, n we v summarized this REQuirement there, evrytin i nid to deploy my cluster is xplained ther

3)create master node & 2worker nodes

ticket002
Deploy workloads in kubernetes;
***ignore, its just about k8 objects used for deployment


Ticket3:
kubernetes uses the kubectl client or the UI to run workloads.

           ****I can practice only Since its not recommended to deploy in using pod as an object
 therefore in the manifest file, kind will be 'rc' & we will also hv a template for pod inside the same manifest file & if we need to create service, we wil
                        also have a template/section for service

Ticket4          **i bliv all these is in the master node
1)CREATE FINTECH & ECOMMERCE NAMESPACES (fintech) USING IMPERATIVE APPROACH  (COMMAND)
2) Create (prod) namespace using the declarive approach (manifest file)
3)Create (dev) namespace using the imperative approach (command)
4)USING DECLARATIVE APPROACH (MANIFEST FILE), deploy the manifest file to create a pod call it 'myapp', in the 'dev' namespace
(remember the manifest file with create a container, call the container 'app')
 


KUB 3&4           ***continues with KUB 1&2
Ticket
1)set configured namespace (dev)to current namespace/context
2)create service type CLUSTERip  called (chatr) for the pod(myapp which is in the dev namespace)
3) using command, create pod called 'hello' in the default namespace using the '-n default' command
4)Uisng the exec -it command; Apply FQDN  command to est communication btw the pod in the dev namespace (called myapp) & the pod in the default 
namespace (called hello)    *** for now i dnt know if it will work without the 'exec' command
5)Using command, create pod  called 'dollar' in the 'dev'namespace
6)Est communication btw the 2pods (myapp & dollar) in the dev namespace uisng just the service name (chatr)
8)Use manifest file to create a STATIC POD
9) use a manifest file to create a replica controller that will be recreating the pod (webapp) with container (web) & will also create a NODEPORT service  
10) create a docker SECRET, use the secret in the manifest file to deploy/create REPLICA SET that will be recreating the pod (billion) & will also create a 
NODEPORT service .....   ***we need the SECRET to be able to successfully pull the image from a private repo which we use in the manifest file 



KUB 5 ... Class34
2)Deploy with demon set   so that each pod is scheduled/deploy on all the nodes ie node1 and node9
3)Taint a node
3)add toloration to tainted node

4)Ticket6:
========
Explain the kubernetes objects recommended to ensure the scheduler schedule a pod  
in each node or a group of selected node/nodeGroup


Ticket7:
--------
Provide a lecture on how pods can be scheduled on tainted nodes.
In Kubernetes we use tolerations to schedule pods on tainted nodes.  


KUB 6  ... CLASS34

1)Deploy using recreate strategy
2)Deploy using rolling update strategy
3) UPdate deployment with set image


Ticket 007:      *** we didnt treat this in this video, dnt know why it was in his rolling notes scripts
  Setup a multi nodes kubernetes cluster using the kops software.

Ticket 017:
  Setup a kubernetes cluster using the amazon EKS? .

Ticket 019:
  Instal tree, unzip, git and nano in a windows system and an ubuntu.



KUB 7
1) Create a resource request & limit

KUB 7b
1)Deploy an application/pod & Auto scale the application/pod with a HPA, &a service for the cluster autoscaler** this will include to install a metrix server
where the deployment will be done & a install a HPA, which will auto scale the application

**** He only deployed with HPA, he didnt deploy with VPA & CAS



KUB 8&9
CAn we use NFS TO scale inorder to meet the wrk load??
if u are refering to hw to hv multiple read replicas 
we wil be seeing hw to replicate the db so we can hv multiple read replicas

***mee** when we do, i will confirm if we introduce the nFS vol or any type of vol first before we replicate/autoscale or replictate/autoscale first before
introducing NFS 
in Kub7, in the HPA illustration, he autoscaled a diff application but when he started kub vol concept in kub8&9, he didnt continue with the same application
from kub7

Ticket
1)Deploy the legacy appication with their diff service type ie springboot mongo with nodeport service & mongo db with cluster ip service
2) we deployed d database with diff vols; we deployed mongo db with hostport vol & mongo db with nfs vol , doesnt require a manifest to create a service type
    *dnt know why we didnt create a manifest file to create a service, i bliv he just skipped that part bc we did in kub 10&11

** i can ignore task no.2 & go straight to no.3&4 task since vol with PVC is the recommended method
3)Deploy mongo db with hostport based PVC  .. this will include 3manifest files the PV,the PVC & the mongo db appl
4)Deploy mongo db with nfs based PVC  ... this will include 3manifest files the PV,the PVC & the mongo db appl

***skip all, deploy will kops kub 10&11




Kub 10&11

1)Deploy an application with configmap & secret using delacrative approach
2)change service type in a file from nodeport to loadbalancer ,..... ignore just an illustration to show disadvantage of self managed cluster
3) Install kops
4) Deploy the legacy application using kops
KOPS create a storage class, so we dnt need to create a PV, we create only a PVC Claim





KUB 12; nginx-ingress       **mee*based on the info below form kub 10&11, we only need nginx for a self manged cluster, which requires me to create a lb ie the 
                                               nodeport(app) or clusterip(database) service type which does loadbalancing for us
1) Deploy nginx ingress controller
2) deploy an application with nginx service
paths
3)create Arecord for the application hostbased routing & for the application pathbased routing
4)Create & deploy ingress rule for the application hostbased routing
5)Create & deploy ingress rule for the application pathbased routing

  **kub 10&11
managed or self managed  LB 
if i create a self mangaed lb, wit the self managed LB, i may create a server n in the server, i wil install a software like ngnix afterwich it wil deter hw 
service is routed, we might also need nginx for EKS cluster to reduce cost of lB
self managed =
   NGINX   




KUB 13  EKS  Installation



KUB 14        HELM

1)Install Helm 3  Architecture
2)Deploy a custom application of ours by creating the manifest/helm charts & push the chart to the repo
b)upgrade the application ie use v2 or 3 of the image
c)change the service type of the application (this wil include creating Arecord in AWS & create the ingress rule)
3)Deploy the application of ours by cloning the chart we pushed to the repo
4)Deploy ngnix using helm



KUB 15
Probes



kuB 16
Install & deploy promethus & grafana using helm  (the deployment will include an alert manager)
create a record & ingress rule for promethus/grafana & alert manager
Deploy nginx
deploy applications to see how nginx routes traffic to them & also see how promethus/grafana can be used to visulaize/see how the applications in the cl8 are performing
I think he didnt create A record for the applications bc they arent our focus/ he didnt try accessing them online
But i may need to create it




KUB 17
applying some commands
1)Access an application that is running

install EFK/ELK stack using helm
should be able to acces kibana externally
create A record & ingress rule for kibana
create host base routing ingress rule for kibana
 HOST BASE ROUTING INGRESS RULE FOR KIBANA



KUB 18                SECURITY
               EKS cl8 was deployed using terraform..

 this is the link for the elk/terraform project ... https://github.com/LandmakTechnology/elk-with-terraform/blob/main/README.md
iluustrate RBAC using EKS  ie create an EKS cluster & use it to illustrate how to use RBAC 
1)CONFIGURE ROLES & CLUSTER ROLES TO PERMIT WHO CAN PERFORM DUTIES IN OUR K8 CLUSTER, 
2)AWS IAM CONSOLE CREATE GROUP,  ENSURE AWS CLI IS INSTALLED, 
3)CONFIGURE THE CONFIGMAP TO AUTHORIZE USER, 
4)CREATE ROLE, 
5)BIND ROLE TO USER, DEPLOY AN APPLICATION, 
6) MK THE USER GET ACCESS TO SVC, 
7) MK THE USER GET ACCESS TO READ ALL THE SERVICES,




                                                                TERRAFORM
video1

3.12.10
clone the trfrm codes
once you hv your vscode setup, as long as you are able to get your terminal, that is all i wnat you to practice
get your terminal & be able to create a dir right here, from your terminal cd into the dir and try to initialize the dir
as long as you are able to that you are all set 
frm tomorw we il see hw ur able to write terrafrm config files & been able to initialize and run terrafrm 
but once u hv your terminal open on ur vs code, once you hv terafrm installed, just run terfrm on that particular terminal if it runs this ... terrafrm 
the u hv terrfm installed , then run aws configured,& mk sure you hv your default credentials/profile configured , thats all you need to do for tonight
inital the dir



1) introduction to terrafrm
Follow the instruction provided and install terraform on your local environment    **meee, either using package manager or download terraform binary
Install a code editor of your choice - vscode is recommended for this course
Configure your aws credentials on your local environment


          ***FOR THE FOLLOWING TASK, THE DIR WE COLNED THE TERFRM REPO WILL SERVE AS THE MAIN DIR
2)   command basis project 02
a)ec2
Create a new folder /directory called: ec2-02    ***mee, (there should be a Project-02 directory/folder, this project-02 dir/folder is in the trfrm repo we cloned)
Create an ec2 instance named "FirstEC2" in your default region  ***mee, but use the ami from any region     ***meee, using a resource block
**objective is to see that Ami's are region specific *meee** so if get the ami id from a region other than d default region then we hv to indicate d region in d provider blk
Use the ami of an ubuntu instance.
The instance size needs to be t2.micro
then initialize, validtae, paln and apply

  ***solution
a) Create a (sub) new folder/directory called: ec2-02   ... we already hv a main dir ie the terfrm repo we cloned & inside it we hv a 'project-02 dir/folder
b)create a file called ec2'1
c)create a provider blk(indicate the region you copied the ami from)
d)create a resource blk for your instance called 'firstEc2' & copy an ami id from AwS & paste


************************************ignore
  ***meee*** 2.42.40, he informed us about the option of a variable (ill ignore it here bc its included in the next project for video2)
SO i can create a variable & use it to pass the Ami id to the resource blk
then initialize, validate, plan & apply.

   **** solution 
TO CREATE VARIABLE 
 eg variable for Ami
then we create the variable with type string and the default value eg t2 medium
then in the resource blk, remove the hardcoding we did ( default values) and and reference the variable 
ie :  ami = var.myami

we can also create a variable for instance type and also for subnet
********when am done refactor my code
********************************************************************

b)vpc
Create a new folder /directory called: vpc-02
Create a VPC named "FirstVPC"
CIDR range : 192.168.0.0/24



 ***solution
a) Create a (sub) new folder/directory called: vpc-02
b)create a file called vpc1 & inside it create a resource blk for vpc called "FirstVPC"
   it should include the cidr range






terfrm2
  ***FOR THE FOLLOWING TASK, THE DIR WE COLNED THE TERFRM REPO WILL SERVE AS THE MAIN DIR

1)  language syntax project 03
  ***mee... Practice how to check AMI id attributes in aws

a)ec2          
Create a (mee, ie a sub folder)new folder /directory called ec2-03 inside the Project-03 directory, **me, (this project-03 dir/folder is in the trfrm repo we cloned)
Create an ec2 instance named "FirstEC2" in your default region.   ***i hv to change the name to '2ndEC2' so it doesnt conflict with the first instance we created above 
Use the ami of an ubuntu instance.
The instance size needs to be t2.micro
Use variables to pass the ami, instance type and instance name to the resource block.
Use an output block to get the public Ip address of the instance after creation.

 ***  solution
i)a main dir needs to be created first ( & we already hv this which is the terfrm repo we cloned, there is a project-03 dir inside it) 
so create the a sub folder called 'ec2-03
nxt create a file called ec2'2 then create the resource blk for an 'ec2 instance called ''2ndEC2''
ii)create a variable blk for ami, & instance type & instance name
then we create the variable with type string and the default values eg the type t2.micro and the ami value
then in the resource blk, remove the hardcoding we did ( default values) and and reference the variable 
ie :  ami = var.myami



b)Create a directory called Project-03. Create a directory called vpc-03 inside Project-03.    **me, (this project-03 dir/folder is in the trfrm repo we cloned)
While in the vpc-03 directory, Create a VPC named "FirstVPC"  ***i hv to change the name to '2ndVPC' so it doesnt conflict with the first instance we created above 
CIDR range : 192.168.0.0/24
Use variables to pass the cidr range and VPC name to the VPC resource.

 ***  solution
i)a main dir needs to be created first ( & we already hv this which is the terfrm repo we cloned, there is a project-03 dir inside it) 
so create the sub folder/dir called 'vpc-03
nxt create a file called vpc2 and inside it create a resource blk for vpc called "2ndVPC", & also pass an argument for the 'cidr range'
ii)  for the variable:
 Create a variable for 'cidr' & the vpc name
then in the vpc resource blk, reference the variable 
ie :  cidr = var.cidr


c)
***meee***  DATA SOURCE
i want to do exactly what was done in class ie use data source to get Ami id & pass it into the resource blk for an ec2 instance
Use a data source to get an AMI id ubuntu, from both the default region & any region & pass it in the resource blk of the instance we create for '2ndEc2'
then in the resource blk reference the data source inorder to pass the AMI id to the resource blk
 next, this instance resource blk '2ndEc2'& the dir 'ec2-03, will be used as a module


D) ***meee Modules
   create a main/general dir eg his own was terfrm class33 dir so in this case the term repo we cloned is the main dir

i)inside the main dir, create a main.tf file, where ill call all/any of the modules

ii)create a Custom module for ec2 
(so bc i already hv my  folder/dir called 'ec2-03 & the file called ec2'2 & which contains my resource blk for the instance '2ndEc2'), then 
inside the main.tf, where we call all the modules, i can call it as: module "ec2" {        **we can give it any name & source  = "./2ndEc2"  
to initialize this module i need to be outside the 'ec2-03 dir but inside the overall dir terrsfrm master class33, then run terfm init, it will see only the main.tf file

iii) create a custom module for vpc (so bc i already hv my folder/dir called 'vpc-03 & the file called "VPC2" & which contains my resource blk for the vpc '2ndVPC'), then 
inside the main.tf, where we call all the modules, i can call it as: module "vpc" {        **we can give it any name & source  = "./2ndVPC" 

iv)inside the vpc module/main.tf, create a variable for cidr & also reference it & inside the main dir; where we hv the main.tf, wher il call the modules, pass the cidr value

v) mk the cidr required/USE VARIABLES TO MODULELARIZE MY CODE, ie inside the main.tf wher i call the modules, i nid to declare a variable called cidr bt still nt provide it
(the value)
then when i run terfrm plan, it will request for the cidr value & then ill provide it
vi) create a variable tag
 ***also create named & unnamed variable files & use it to supply the values for the configuration 


E)   PASSING VARIABLES AS A FILE  (the file must end with 'tfvars', pass it on the CLI uing '-var-file= 'the file name')
TYPES OF VARIABLE FILES TO PASS
1)Create a Named files eg prod.tfvars
2) Create a Unamed  files eg terrafrm.tfvars or auto files
  ***use these to supply the varialbe values for 'no iv; cidr value


      F)                            DEPLOY IN DIFF ENV
***** try this too, deploy to stage/dev/prod  USING A VARIABLE OF TYPE LIST TO DEPLOY IN DIFF ENV
so u can create a variable of type list of strings , put ur values der, lets says u are creating a module that wil deploy instances both in the stage , dev n prod env n mayb
the req is when ur deploying in the stage env use a t2 micr, in the dev use a t2 medium, in the prod use a t3 large
so u can define a var with a list then based on the env u selsct the index, so ur just declaring on evariable , ur reading it frm one variable bt its a list of variables n 
ur selecting the index based on the env.

   *** try this too; deploy to stage/dev/prod   USING A VARIABLE OF TYPE MAP     ***uses key & value   eg; key=dev & the value=t2 micro
so u can create a variable of type map , put ur values der, lets says u are creating a module that wil deploy instances both in the stage , dev n prod env n mayb
the req is when ur deploying in the stage env use a t2 micr, in the dev use a t2 medium, in the prod use a t3 large
so u can define a var of type map then based on the env u selsct the key, so ur just declaring on evariable , ur reading it frm one variable bt its a variable of type map & 
ur selecting the key based on the env

G) Create a variable that has a secret
H) create a resource for a bucket
I) use terraform official module to create a resource eg instance
 J) Terrafrm destroy to destroy a particular resource      
K) run terfrm init -upgrade  .. try to create a resource with a diff version 
L) Moved blocks




video 3
4) settings 
project04
Create an ec2 instance
Use a script provided below to pass user data to the instance
Attach an elastic IP to the instance


5) variable and data source project

Create an ec2 instance
Refactor your code to use variables
Use a script provided below to pass user data to the instance
Attach Associate a EC2 Key pair to login to the EC2 instance
Get the public_ip, private_ip and arn of the instance.


6) no project
7) no project
8) no project
9) no project












