
my QUESTION
how did u know the container ip address

QUESTIONS And answer below
*****************************************************************************************************************************************

what are syntax


docker volumes and docker compose:
==================================
Docker:
  We use Docker for containerization
  We use Kubernetes for container orchestration/MGT   

************  so when we containerize with docker we ar going to manage those containers with kubernetes, dats what we wil be seeing



We install the docker containerization software:
In Linux/Windows/MacOS  
   we use the docker client / wich is the cli, command line interface that permits u to run docker commands   
 = docker build/push/pull/run  (and this docker client generally starts with
   docker e.g we use the docker client to execute diff commands)
   e.g docker pull, docker push etc


WE also have docker daemon
docker daemon/service =  this enforces the command that is run, e.g when u run docker build, the docker deamon knowns he has to create an image etc                                                                                   
  docker registry  , wher we ship images to and make them distributable0      = ship/share[dockerhub/ecr(elastic container registry) /nexus]    


Application architecture: .. we also saw we can use docker to containerize both monolithic and microservices application
  Monolithic architecture '
  Micro-services architecture ' ... bt docker will shine more when it comes to micro services bc they ar very light weight & docker containers are light weight

************************Which kind of applications can be containerised??  
  - All applications [java/python/nodeJS/nginx, etc.]
 
*************************What is needed to containerise an application :
1) ensure that docker installed
2) must hv a Dockerfile -- Instructions on how to build the desired image   or any image 
3) Docker Image -- is a package with apps code + dependencies


************************ ONCE THE applications are containerized, we ar able to run containers
  containers -- apps or running instance/process of a docker image 
 and we need  networks---  for the containers to communicate with each other communication[internal or external]  

  docker run --network none --name webapp mylandmarktech/hello 
  docker run --network host --name webapp mylandmarktech/hello
  docker run --network ebay --name webapp mylandmarktech/hello 
  docker run --name webapp mylandmarktech/hello

 docker networks:
  Default bridge
  custom bridge
  non  
  host  

docker:
  image      = contains packaging 
  containers = process of the image 
  networks   = communication
  volumes    = storage/mounts for the containers


************************************************************************************************
TYPES OF VOLUME, BIND MOUNT,DOCKER VOLUME; Docker Peristent Volumes(Docker Named Volumes), STEPS TO DEPLOY DOCKER VOL, external volumes, USING EXTERNAL (EBS)
VOLUME TO DEPLOY OUR APPLICATION , ACCESS KEY & SACRED KEY,  DOCKER COMPOSE,HOW THE DOCKER COMPOSE VERSION HAS AN IMPACT, CREATING DOCKER COMPOSE FILE,
TWO WAYS TO DEPLOY IN DOCKER, CREATING CONTAINERS USING DOCKER COMPOSE/ to DEPLOY THE APPLICATION



START

docker Volumes .................................10:44
==============
 statless applications .... does nt store data
 stateful applications ........ needs to maintain its state, data nids to be stored.this include data bases , applications like jenkins
    databases / jenkins, we sue jenkis to be able to deploy a lot of works, so we hv jobs in jenkins



             TYPES OF VOLUME


                               BIND MOUNT
the first volume we ar discusiing about is :
Bind Mounts:
Bind mounts may stored data anywhere on the host system. They may even be important system files or directories. 

docker run --name mongo -d --network tesla -v /tmp/mongo:/data/db -e MONGO_INITDB_ROOT_PASSWORD=devdb@123 -e MONGO_INITDB_ROOT_USERNAME=devdb mongo   (mongo is image name )

docker run --name springapp -d -p 8080:8080 --network tesla -e MONGO_DB_HOSTNAME=mongo -e MONGO_DB_USERNAME=devdb -e MONGO_DB_PASSWORD=devdb@123  mylandmarktech/sping-boot-mongo




vi app.sh 
copy and paste the run command aBOVE
 sh app.sh  ... deploy the containers
dockes ps ........ we can see the containers
20:48******************* curl 3.22.217.29:8080 *********************** how did u know the container ip address

*************QUESTION
he checked on his browser and we can access the application , the application can write/communicate in the database
############################################   SO THE BIND MOUNT WAS SUCCESSFUL######################

22**************** In the host server, data is stored in  /data/db, and this is the dir that was created /tmp/mongo:
ubuntu@docker:Â¬ $  ls /tmp/mongo/
inside this dir, the data that is captured is frm the inf entered, inf entered by e.g enusers is captured here 

################# bt this volume concept is nt a persistent volume example, bc this process is nt manged by docker, when we run ll /tmp/mongo/ , we see the
process is notmanaged by docker and as such it could be accidentally deleted
***************if we ls /tmp , we can see the mount point mongo that we created .... so what happens if its deleted by a non docker process

**************** lets assume thats our database is down, the mongo db is down n so we can enter data e.g docker stop mongo , bt when we retsrat .. docker 
start mongo we ar now able to access the data
now lets kill the database ,,  lets completely remove this database, docker rm -f mongo n so the db is no longer running 
now lets redeploy the database, then we can still see the the previous data.. 
this is because of bind mount 
******27:00  what happens is that any data that is being captured by this database is also sychronizing wit our docker host such that if the database is 
destroyed completely
if we recreate the database with the same mount point, the data will syn with the data that is on this piece of storage that is on our docker host.
BUT DERS A PROBLEM HERE 
if we remove the container again   .... docker rm -f mongo      ... now the container is no longer running , so our database is killed , we cant access it again
at the moment our vol is nt managed by the docker process ,
lets assume the mount point is accidentally deleted  sudo rm -rf /tmp/mongo/
if we recreate our data base, we wont be able to access our data anymore bc the mount point is nt managed by the dcker process n as such , it can be deleted 
unnoticed



       30:23  ************** Non-Docker processes on the Docker host can modify 
Bind Mounts volumes at any time unnoticed.
######### so we nid to introduce persistence vol 

NOW LETS SEE THE DOCKER VOLUME CONCEPT THAT IS being mMANGED BY DOCKER, we want to talk abt persistence vol 


    NOW LETS SEE THE DOCKER VOLUME CONCEPT THAT IS being mMANGED BY DOCKER, we want to talk abt persistence vol 

Docker Volumes
Volumes stored data in a part of the host filesystem managed by docker

Docker home dir :  DHD = /var/lib/docker

BindMount: can store your data anywher                                                             this inf is frm the previous video
 /tmp/mongo:/data/db ....(mount point for d docker host server /tmp/mongo and /data/db is the mount point for the container/ we got it frm d official image inf in dockerhub) 
  /home/ubuntu/data:/data/db

Docker Peristent Volumes(Docker Named Volumes)
=============================================

Illustration to apply below;
docker volume create mongodata  ... we hv to create our own vol; mongodata .... this is now using persistent vol which is being manged by docker
docker volume create mongodata -d local   ... ..  here am passing a driver 
docker volume create mongo33   ............ here am nt 
docker volume create -d local data 
docker volume ls  

BUT FOR BIND MOUNT
************* for this bind mount, we nid to create a mount point for the host server /tmp/mongo
docker run --name mongo -d --network tesla \
  -v /tmp/mongo:/data/db \
  -e MONGO_INITDB_ROOT_PASSWORD=dev@123 \
  -e MONGO_INITDB_ROOT_USERNAME=devdb mongo 
**************************************************************************************************

 ###############this is what i need to do,just the vol name:mongodata , am not creating any mount point  /tmp/mongo:/ like we did for bind mount
docker run --name mongo -d --network tesla \
  -v mongodata:/data/db \
  -e MONGO_INITDB_ROOT_PASSWORD=dev@123 \
  -e MONGO_INITDB_ROOT_USERNAME=devdb mongo 
OR
docker run --name mongo -d --network tesla \
            or the vol name:data:33
  -v data33:/data/db \     *********** BT if i execute this command when i v nt created docker vol create data33 , will it be executed????? lets check d vol we v already
  -e MONGO_INITDB_ROOT_PASSWORD=dev@123 \                                                                                                 docker volume ls
  -e MONGO_INITDB_ROOT_USERNAME=devdb mongo 

***************************************************************************************


35;00                               STEPS TO CREATE DOCKER VOLUME
STEP1) create volume: 
docker volume create mongodata -d local  ..... ( -d for driver)  ... here am passing a driver 
docker volume create mongo33   ............ here am nt, when u dnt pass ur driver, it will create under local
docker volume ls to see the diff drivers  ... ryt now we can see local, so both drivers are local even though when i created mongo33 i didnt indicte for d driver to be local
so when u DNT CHOOSE driver it is going to crate under the local driver 

 he removed mongo ....     docker rm -f mongo 
 
37:40
ubuntu@docker:~$ docker volume prune
WARNING! This will remove anonymous local volumes not used by at least one container.
Are you sure you want to continue? [y/N] y

'################# WEredeploy the database      *** i guess we didnt need to run 'docker volume create data33' first for the volume to be created.
STEP2) create the database 
vi app.sh  and paste the run command 
docker run --name mongo -d --network tesla -v data33:/data/db -e MONGO_INITDB_ROOT_PASSWORD=devdb@123 -e MONGO_INITDB_ROOT_USERNAME=devdb mongo
then deploy sh app.sh   ... SUCCESSFUL , WE CAN access the data
docker volume ls     .... we can see  local data33 wwe just created
docker inspect data33      and we can see the mount point: /var/lib/docker     .********* the docker home dir is var/lib/docker 
..... Driver" : "local"
Mountpoint": "/var/lib/docker/volumes/data33/_data  
ubuntu@docker: Â¬ $ sudo ls /var/lib/docker/volumes/data33/_data  

41:21      Does this mean we cant store data anywher like for bind point??
Docker home dir  DHD = /var/lib/docker    so ******* in this home dir we ar given the mountpoint point of our volume 
and whatever is stored in this dir is managed by docker n it leads to what is called pesistent  volume , bc it i smanged by tah docker process

*********************************** THE ONLY TO REMOVE THIS VOLUME is to execute : it must be deleted by a docker process
docker volume rm volumeName  
docker volume rm data33  

******************************Volumes are the best way to persist data in Docker.:    



      EXTERNAL VOLUMES
*************************************************************************External volumes:   ********************43:26
ther are external vol pluggin ,that can be installed in docker
 ===== Network Volumes Using AWS EBS ==========

we can craete external vol using sometin like AWS ebs , also efs: elastic file system, s3 simple storage system, google persistent disk, also sdsure disk, rexray plugin for 
docker storage 
so when i hv my container mount point : /data/db/, i can mount it with an external vol 
########### 45:00 so we can do smt like this : .... we wnt to create a mount point , frm this point, we could have external mounting , we can mount it externally
we can use extenal vol for this same purpose, we can also hv multiple mount points

46:30    ************************another external storage we can use is : rexray plugin for docker storage 

https://rexray.readthedocs.io/en/v0.8.2/user-guide/docker-plugins/  , here we also see d docker plugins installatin command, if u dnt choose d version it wil go for d latest version
Rexray docker-plugins for storage:

ther are many examples of external storage we can use, bt in this case, i wnat ti go for EBS
 
********************************** DOCKER volume plugin ******************* 48:19
docker plugin install rexray/ebs \
  EBS_ACCESSKEY= abc\
  EBS_SECRETKEY=123/


                       USING EXTERNAL VOLUME TO DEPLOY OUR APPLICATION
48:50
####in this case we nid an aws acces key and an aws sacred access key, this access key shud be authenticated ie it sud hv the right authorization to  
create vol in docker
so we go to our aws account .. hes in his root account , it have the req acces 
click on the top right corner n frm the drop box, click on security credentials ................49:20 
scrol down to access key and create access key  then copy, both access n sacred key

 docker plugin install rexray/ebs \
  EBS_ACCESSKEY=AKIAUGAKLPXTXI23EAXH \
  EBS_SECRETKEY=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

before we execute this commnad let us execute another command: 
docker plugin ls  ..... we can seee no plugin has intially been installed


                                      ACCESS KEY & SACRED KEY
51:13 ********************************* whY ARE WE USING ACCESS KEY AND SECRED  ACCES KEY
this is a plugin called rexray/ebs , THis plugin is intendd to help us create external volumes, this means that we can create an external vol,
docker volume create -d rexray/ebs ebs33 .. ...........d is for driver, the driver is rexray/ebs .... am creatin a vol called ebs33
if u execute this command, it wil go to ur aws account under volumes and create a vol called ebs33
################this process cannot happen if u dnt hv the right IAM authorization
bc we are using IAM = Authorisation  to autorize this rexray to be able to create and manage volumes in our aws account,, for this to happen IAM Is reQUired

step1) now we deploy this pluging :
docker plugin install rexray/ebs \
  EBS_ACCESSKEY=AKIAUGAKLPXTXI23EAXH \
  EBS_SECRETKEY=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

*****************next
docker volume create -d rexray/ebs ebs33 .............. bc it is rexray we hv to pass  the driver 
docker volume create ebs33 ...... ............. if u dnt pass driver, it wil create it under local driver 
docker volume create -d local ebs33  

2) create the volume 
docker volume create -d rexray/ebs ebs33  ... it will tk a while bc this is an external vol
            docker volume ls   .. we see the vol is created
           Docker inspect ebs33 
    driver : rexray/ebs:latest
     Scope: global
     size: 16
     type:gp2,      ie 16 gp2
************************************ now we can use this vol to create the container/deploy my application

59:25 *************** he tried to run multiple volume mount point but it didnt work 

ubuntu@docker:~$ docker run --name mongo -d --network tesla \
  -v data33:/data/db \
  -v ebs33:/data/db \
  -v /tmp/db33:/data/db \
  -e MONGO_INITDB_ROOT_PASSWORD=devdb@123 \
  -e MONGO_INITDB_ROOT_USERNAME=devdb mongo 
docker: Error respnse frm deamon: duplictae mount points: /data/db.
see 'docker run --help'.
****************************** he said it seems the vol property does nt permit multiple mount point

59:51*********************************************************************************************** we are creating our database container 
the container is creating the volume 

docker run --name mongo -d --network tesla \
  -v ebs33:/data/db \
  -e MONGO_INITDB_ROOT_PASSWORD=devdb@123 \
  -e MONGO_INITDB_ROOT_USERNAME=devdb mongo 
**************************************************above he tried to deploy the container with the vol but didnt work, we couldnt access the data 

3) ############# so he used the file app.sh  and paste the below command 
docker volume craete ebs3 -d rexray/ebs
docker run --name mongo -d --network tesla -v ebs3:/data/db -e MONGO_INITDB_ROOT_PASSWORD=devdb@123 -e MONGO_INITDB_ROOT_USERNAME=devdb mongo   (mongo is image name )
then  deploy: sh app.sh

************* successful,  he checked in aws and we can see the  volume we see both ebs3 and ebs33 that we created n we can access the application n write data
docker volume ls and we see ebs33 n ebs3
************** can delete with docker volume prune OR docker rm volume name 
****************************************************************************************************************************************





Docker Compose **********************************************************
==============
Docker Compose is a tool for defining/declaring and running multiple 
   containerised micro-services applications.
In real time one application can have more than 7 micro-services:
E.G ebay.com: 
An e-commerce java based web application for ebay or 
ebay-web-application:
    Login
    Registration
    cart
    checkout
    Payment
    Order
    mysql db  
****** ****************if u hv an aplication like dis n u nid to deploy it, hw many run command will u execute are we going to execute , very long command,
we ar going to v 
multiple run command:

docker run --name login -d -p 80:8080 --network ebay login            ,,, to create login container
docker run --name reg -d -p 80:8080 --network ebay registration 
docker run --name cart -d -p 80:8080 --network ebay cart
docker run --name checkout -d -p 80:8080 --network ebay checkout
docker run --name pay -d -p 80:8080 --network ebay payment 
docker run --name order -d -p 80:8080 --network ebay order 



**************** so this ebay web appl has been decoupled into micro services for login, reg, cart order, now all this inf needs to be captured in some database
so my database heer is mysql , we ar using mysql
docker run --name mysql -d -p 80:8080 --network ebay mysql ,,.............  image is msql 
*********if we ar going to be deploying using mysql,  we may need so env variable bt lets just consider jst what we see here
************** 1:16:00   u realise that for this deployment of mysql,,,, he checked in docker hub to see hw the image msql is used in the OVERVIEW

Configuration without a cnf file
$ docker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:tag --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci


**************** To use the root pw to access the database; WE CAN DO SMT LIKE THIS:
$ docker run --name some-mysql \     .. ENV VARIABLE -e  , lets assume the root pw is admin123, then image name mysql , so we ar passing the root PW to access dis database
-e MYSQL_ROOT_PASSWORD=my-admin -d mysql
--character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci

******************* of course all of this can be in one line************************
docker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-admin -d mysql --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci

so we ar deploying this database,  bt we hv to put it in the same ntwrk 
docker run --name mysql -e MYSQL_ROOT_PASSWORD=my-admin -d --network ebay mysql --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci


docker run --name login -d -p 80:8080 --network ebay login          
docker run --name reg -d -p 80:8080 --network ebay registration 
docker run --name cart -d -p 80:8080 --network ebay cart
docker run --name checkout -d -p 80:8080 --network ebay checkout
docker run --name pay -d -p 80:8080 --network ebay payment 
docker run --name order -d -p 80:8080 --network ebay order 
docker run --name some-mysql -e MYSQL_ROOT_PASSWORD=my-admin -d --network ebay mysql  

1:19:10 ************** bt what we are saying is that when ur trying to deploy an application, a lot of objects ar involved in this deployment.
hw many objects or micro services ar involved in this deployment ???  however for the objects
in trying to deploy this application what are the objects that ar ivolved ? 

docker objects:
  - u must use the right images   , each of the micro services must be deployed with the right image 
  - it must be in the right networks ,  so if we nid this containers to comm with each oda they must be in the same ntwrk
  - must assign volumes accordingly ,  if any of the containers nids to maintain its state we must introduce docker volume
  - environmental variables   ,   for us to deploy it in any env , we must use env variable 

****************************************** 1:21:10 
ubuntu@docker:~$ docker-compose
Command 'docker-compose' not found, but can be installed with:
sudo snap install docker          # version 20.10.24, or
sudo snap install docker          # version 20.10.24
sudo apt  install docker-compose  # version 1.29.2-1
See 'snap info <snapname>' for additional versions.

ubuntu@docker:~$ sudo apt  install docker-compose -y      ... successful
docker compose -version to see the version of docker compose that we v created  ... version 1.29.2 build unknown



                                 HOW THE DOCKER COMPOSE VERSION HAS AN IMPACT
 ********************** lets see hw the version has an impact
1:23:50
docker --version 
Docker version 20.10.12,    build 20.10.12-0ubuntu4   
Docker version 24.0.5, build 24.0.5-0ubuntu1~22.04.1
3.1                         1.13.1+          
3.1                         20.10.12


1:24:25  .....the rule says when u wnat to write a docker compose file, that file starts with version
the default name for docker compose file is, ie docker compose.yml


1:25:29  ####### the rule says when u want to write a docker compose file .. went on break, didnt continue that ... 

click on the menu box , select doc, click on references , compose cli, compose file references and legacy versions then version 3
when we look at docker compose, u want to look at the  docker compose like version3 references and hw it relates to the docker engine with the docker software


Docker version 20.10.12  .. this is my docker version
docker-compose.yml  

we can use version 3.1 for docker engine  1.                                   ..... 1:26:44
what dis means is that  ...       Docker version 20.10.12  .. this is my docker version and this is the docker compose version 1.29.2
 so if i wnat to write a docker compose file, this is hw it goes 
------------------      ####################### if ur trying to deploy ur application using docker compose it cud fall under stuff like dis 1:27:40



                                              CREATING DOCKER COMPOSE FILE

1) Creating the docker compose file
                                              THIS IA A .yml file                                                                       1:33:00
so in deployn dis spring app, i nid d image, smt like restart,if d container stops wot hapens, i nid ports, its a list i pair port 6000 to 8080, ntwrks too is a lis, env var
                             for d db service , i nid the image, retsrt if it stops, ntwrks, vol, env.
                                WE AR CREATING OUR VOLUMes, netwrks and services
version: '3.1'             
services: 
  springapp:
    image: mylandmarktech/sping-boot-mongo   
    restart: always    
    ports:
    - 6000:8080     
    networks:
    - fintech     
    environment:
    - MONGO_DB_HOSTNAME=mongodb
    - MONGO_DB_USERNAME=proddb
    - MONGO_DB_PASSWORD=proddb@123         
  mongodb:
    image: mongo     
    restart: always     
                       (no space here, i jst did it like that) under port, we wnt be allocating any port for our db bc we wont be accessing it externally so i tk it out 
    networks:       ...... ..... ..... you cud hv multiple nterk cos a container cud be multiple ntwrk
    - fintech  k9                     ***** d 2application shud b in the same ntwrk bt i can place database in anoda ntwrk bc one container can b in more than one ntwrk)
    - tesla   
    volumes:
    - data11:/data/db:rw         *********** what is rw 1:40:43
    environment:
    - MONGO_INITDB_ROOT_USERNAME=proddb
    - MONGO_INITDB_ROOT_PASSWORD=proddb@123       
volumes:                                           i want the vol created, it doesnt exist, i want it craeted extrnally
  data11:
    driver: rexray/ebs     c
networks:
  tesla: 
    external: true    ...    true means the ntwrk is already available
  fintech:
    driver: bridge  

2)docker volume create -d rexray/ebs data11      ********************** we hv to also create dis volume and ntwrk fintech b4 we can start deploying the apl
3)docker network create fintech  
  ****************************  he didnt run 2&3 .... .. he deployed everytin with the file
1:38:20 ################################  you can use a file like this its easy bc this transaction can be easily repeated , now the docker compose.yml file is done
                                                                    we can deploy the containers ie springapp and mongo using dockr compose  .. 1:41;19
4) next
vi docker-compose.yml  and paste the file 


**************** nxt
5) check if the syntax are ok
docker-compose config      ................if ders an errror, it will tell you

6) create the containers/DEPLOY THE APPLICATION
docker-compose up -d 
       docker ps .... the containers are running
  
....... application deploy bt we cudnt acces it in goolge bt when we curl on the comandline it responds, he asaid ders no path to the appl, its suppose to
                                                              respond accordingly .......1:45:30 .... he even checked aws security groups, said all d ports are open



######################### since we are using docker compose, we can deploy in multiple env, like dev, uat, prod using diff env variables

             dev     uat      prod   
USERNAME   devdb     uatdb    proddb   
hostname   mongo     mymongo  mongodb  
password   dev@123   uat@123  admib@#123  




..1:31:18                                 TWO WAYS TO DEPLOY IN DOCKER
1) We can deploy the database and the aplication either using command ...... OR 
docker run --name mongo -d --network tesla \        
-v ebs3:/data/db -e MONGO_INITDB_ROOT_PASSWORD=devdb@123 \                                                                        
-e MONGO_INITDB_ROOT_USERNAME=devdb mongo
 
docker run --name springapp -d -p 8080:8080 --network tesla \
-e MONGO_DB_HOSTNAME=mongo -e MONGO_DB_USERNAME=devdb \
-e MONGO_DB_PASSWORD=devdb@123  mylandmarktech/sping-boot-mongo

2) using Decompose' ie using 'a file' ..1:31:18
   
******Docker 5&6, we saw multi-stage file



    ***************************CREATING CONTAINERS USING DOCKER COMPOSE/ to DEPLOY THE APPLICATION  ***********************1:42:08

TO create the containers/DEPLOY THE APPLICATION

first: check if the syntax are ok
docker-compose config      ................if ders an errror, it will tell you

1) for docker compose file with default name [docker-compose.yml ]. 
  # Create Services/Contianers
   docker-compose up -d          ****** used when deploying an application using the default name, ie docker compose.yml

 
2) #docker compose file with custom name.  
docker-compose -f <CustomeComposeFileName>.yml <command>
Ex:
docker-compose -f docker-compose-springapp.yml config
docker-compose -f docker-compose-springapp.yml up -d
docker-compose -f docker-compose-springapp.yml down


# Remove Services/Contianers  .................  to destroy the containers
    docker-compose down

*******************************************************
Ex:
docker-compose default file: docker-compose.yml
docker-compose -f docker-compose.yml up -d 
docker-compose up -d 
docker-compose up -d
docker-compose config 
********************************************



so we can create a docker compose file and call it: docker-compose-springapp.yml
i can also rename my docker compose file ie the file we deployed already  .... mv  docker compose.yml docker-compose-springapp.yml

then:  he changed port to 8080:8080 and dreiver:local
                              
version: '3.1'             
services: 
  springapp:
    image: mylandmarktech/sping-boot-mongo   
    restart: always    
    ports:
    - 8080:8080     
    networks:
    - fintech     
    environment:
    - MONGO_DB_HOSTNAME=mongodb
    - MONGO_DB_USERNAME=proddb
    - MONGO_DB_PASSWORD=proddb@123         
  mongodb:
    image: mongo     
    restart: always     
    networks:       
    - fintech                  
    volumes:
    - data11:/data/db
    environment:
    - MONGO_INITDB_ROOT_USERNAME=proddb
    - MONGO_INITDB_ROOT_PASSWORD=proddb@123       
volumes:                                           
  data11
    driver: local
networks:
  tesla: 
    external: true    ...    true means the ntwrk is already available
  fintech:
    driver: bridge  

then 
docker-compose -f docker-compose-springapp.yml config
with dis new file name to deploy will be  ........................... 1:53:20
docker-compose -f docker-compose-springapp.yml up -d

########################## now we were able to access the application online



Docker Compose Commands: will give u all the docker compose command

docker compose commands 
Commands:
  build              Build or rebuild services
  config             Validate and view the Compose file
  create             Create services
  down               Stop and remove resources
  events             Receive real time events from containers
  exec               Execute a command in a running container
  help               Get help on a command
  images             List images
  kill               Kill containers
  logs               View output from containers
  pause              Pause services
  port               Print the public port for a port binding
  ps                 List containers
  pull               Pull service images
  push               Push service images
  restart            Restart services
  rm                 Remove stopped containers
  run                Run a one-off command
  scale              Set number of containers for a service
  start              Start services
  stop               Stop services
  top                Display the running processes
  unpause            Unpause services
  up                 Create and start containers
  version            Show version information and quit

docker swarm:  2video tomorrow
================================
Saturday = kubernetes  = 4hours classes  


QUESTIONS:

1)u hv been redeploying on a new port but
cant a container be deployed on the same port for e.g u nid to update what was already deployed

2) bc for the web app u did build u used maven as abuild tool, i understand that for python they also hv build tool bt i didnt see us doing a build, does it
mean that we actually depend totally on the docker file bc for the web app we did see that we were copying the .war files n deploying it into the tomcat 
not all applications are deployed in the same manner like d way we deployed python appli was diff frm d way we deployed oda appl like java based app
1:02:00  .. LET ME SHOW U SMT ... when u install dis docker file, it does a build while running the docke file

FROM python:3.7
WORKDIR /opt/app

COPY . .

RUN pip install --no cache dir -r requirements-prod.txt       .... this is the command that wil do a build , its doing a build wit pip installed 
                                                              whil creatin the image, pip instal is like deploying the applic
EXPOSE 5000

CMD { "python, -m, flask / run  --host=0.0.0.0"]        ,,,,   to start the container

**********************let me show u smt in docker files 
we hv docker file for wildfly for e.g

FROM jboss/wildfly
ADD target/maven-web-app.war /opt/jboss/wildfly/standalon/deployments/

this base image , for jboss to function, it rEQ java bt the base image already v java embedded in it

***************** also , look at this base image what do u see here:
FROM tomcat:8.0.20-jre8  ..    tomcat, it says 8.0.20 java run time env 8 ,, so the  tag here is tomcat wit java8  , this base image has tomcat and java, they ar both embeded 
                                                                                       together bc dats hw base images are     

RUN     sed -i user usrname= "admin" password" roles , manger -script"/> /usr/local/tomcat/conf/tomcat-user                                                                   
and this has a run instruction which is assigning pw, roles , and it is redirecting it io the /usr/local/tomcat/conf/tomcat-user
so while deploying ur app u can use the run instruction to assign a user name 
COPY java-web-app.war /usr/local/tomact/webapps/graddle-web-app.war    ].... and now we ar  copying the war files

******************** for the multistage  docker file

WORKDIR /app
RUN git clone https://github.com/LandmakTechnology/maven-web-application.git

#Maven
FROM maven:3.5-jdk-8-alpine as build
WORKDIR / app
COPY --from=repo /app/maven-web-application /app
RUN mvn install       .........     here we ar doing mvn install, wich implies that will ceating the image, the app code is being craeted as well,its like doing mvn package

#Tomcat
FROM tomcat:8.0.20-jre8
#COPY /app/target/*war /usr/local/tomcat/webapps/maven-web-app.war
COPY --from=build /app/target/*war /usr/local/tomcat/webapps/

***************** for nodejs app 
all of this appli are found in a docker hub account
this is nodejs, it has a docker file

FROM node:10
WORKDIR /usr/app
COPY ..
RUN npm install      whendeploying  uusing nodejs, this is the command  npm install
EXPOSE 9981
CMD   "node" , app.js     the command to start the app


3) whats the integration btw the tomcat and the docker file bc we just deploy at one 



4) when we were using the plugin to create the eps is der a way to create and encrpt the eps at the same time while we ar doingthat?
ANS : i thinkits possible , i share the link jst go tru it

we previously integrated jenkins with tomcat, maven, where does docker come in that process
ANS; no its easy, i think we did that when we started docker, we had some stages
can u see this jenkins file:
. prepare a jenkins cd job for maven-web-application

//Jenkisfile for maven-web-app cd job
 node{
stage ('5. createDockerImage' ){}
stage ('6. PushImageDockerhub' ){}
stage('7.Deploy2UAT'){}
stage('8. approval'){}
stage '8.Deploy2Prod'){}


     **** I bliv for this ci/cd job, we can use either of 2 methods; 1) the upstream & downstream option OR 'a single job' option
                                                         then the option to use either multi stage file OR a docker compose file.
                                              i bliv it will be a multi-stage file bc its a single container, compose file is for many contaners

Ticket014:     
ï»¿ï»¿ï»¿ï»¿Prepare a jenkins ci/cd job for maven-web-application
         **************************************************IN the pipeline stage one is to clone frm scm , ur building using maven9
1.cloning the latest version of the application = SCM/github
2. building using maven
3. running code quality analysis with sonarQube
4. uploading artifacts in nexus
5. pre-deployment
     1. containerizing the application by creating
       docker images using Dockerfile
      distributing the images in docker image Registry
       dockerhub/Nexus/JFrog
6. Deployment TO UAT environment using kubernetes
7. APPROVAL[manual or auto] 8. Deployment to Production environment using kubernetes
9. email/slack notification





